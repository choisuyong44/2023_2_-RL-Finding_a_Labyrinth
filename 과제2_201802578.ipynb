{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1240a819",
   "metadata": {},
   "source": [
    "# 강화학습_미로찾기(Temporal Difference learning)\n",
    "\n",
    "## 목차\n",
    "#### 1) 강화 학습에 대해\n",
    "#### 2) 강화 학습 중 Temporal Difference learning을 이용한 미로찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d777f8",
   "metadata": {},
   "source": [
    "# 1) 강화학습\n",
    "\n",
    "1) 정의 :<br> 강화학습은 supervisor(정답을 알려주는 사람)이 없이, 에이전트(Agent)가 주어진 환경(State)에서 어떤 행동(Action)을 취하고 이에 대한 보상(Reward)를 얻고, reward를 극대화하도록 정책을 학습하는 방법.<br><br>\n",
    "\n",
    "2) 장점과 단점 :<br> 강화학습은 supervisor가 없기 때문에, 소요 시간이 오래 걸리지만, 때때로 supervisor(사람)가 제시한 방법보다 훨씬 더 효과적으로 문제를 해결할 수 있다.<br><br>\n",
    "\n",
    "3) 사용된 용어 및 관련된 개념 정리:<br>\n",
    "    1.St = 시간 t의 상태<br>\n",
    "    2.At = 시간 t의 행동<br>\n",
    "    3.Vπ(s) = 상태가치함수(어떤 상태의 좋고/나쁨을 평가함)<br>\n",
    "    4.Qπ(s,a) = 행동가치함수(시간 s에 대하여 행동 a를 했을 때 행동의 좋고, 나쁨에 대해 나타내는 가치함수)<br>\n",
    "    5.Reward = 에이전트가 특정한 상태에서 특정한 행동을 했을 때의 보상을 나타냄<br>\n",
    "    6.Discount Factor gamma = 미래의 보상에 대한 가중치를 나타냄, gamma값이 크면 미래의 보상에 대해서만 중요하게 생각하고, gamma값이 작으면 현재의 이익만을 고려하여 행동<br>\n",
    "    7.Epsilon Greedy epsilon = 탐험(exploration)과 활용(exploitation) 사이의 균형을 조절하는 데 사용, 다시 말해 지금까지 보상이 컸던 행동을 할 것이냐 아니면 새로운 탐험을 할 것이냐에 대한 비율을 나타냄<br><br>\n",
    "\n",
    "4) Temporal Diffenrent<br>\n",
    "4-1) Dynamic Programming : 동적계획법이란 전체 문제를 여러개의 하위 문제로 나누어 풀고, 하위 문제들의 해결방법들을 결합하여 최종 문제를 해결하는 방식으로, 강화학습의 TD에서는 하나의 문제를 2개 이상의 하위 문제로 쪼개고 각각을 최적화하게 되면 원래 문제도 최적화를 할 수 있고, 서브 문제들이 여러번 반복적으로 나타나기 떄문에 하나의 서브 문제를 저장했다가 다시 사용하는 것이 가능하는 원리를 이용하여 MDP 상황에서 step 별로 연산을 할 수 있고, 각 step의 가치 함수는 저장 되었다가 연산할 때 다시 사용할 수 있다.<br>\n",
    "4-2) MC(Monte carlo) : MC는 정확한 수학 수식에 의해 계산하거나 측정하는 게 아니라 확률적인 방법에 의해 값을 통계적으로 계산하는 방법이고, 에이전트가 동작하는 환경은 시작과 끝이 있는 에피소드 단위의 환경에서 사용하여, 몬테카를로 방법은 에피소드 단위로 직접 실행을 하고, 결과를 관찰하고 무한히 반복하여 평균을 내면, 진짜상태가치함수에 수렴한다.<br>\n",
    "4-3) Temporal Different : MC에서 에피소드가 끝나면 반환값(가치함수)을 주지만, 조금 더 빨리 반환값(가치함수)을 계산하고 싶어서 나온 방법으로 하나의 step에 하나의 action을 통해 상태가치함수를 update함.업데이트는 greedy한 방식으로 상태가치함수가 가장 큰 방식으로 업데이트를 진행한다. Temporal Difference (TD) 학습은 강화 학습에서 사용되는 학습 알고리즘 중 하나로, 현재 상태에서의 가치를 현재의 보상과 다음 상태의 가치의 추정치를 조합하여 업데이트하는 방식이다. \n",
    "<br><br>\n",
    "Q(s,a)←Q(s,a)+α⋅[R+γ⋅max a ′Q(s ′,a ′)−Q(s,a)]<br><br>\n",
    "\n",
    "5) 미로찾기<br>\n",
    "현재 상태에서 현재 행동을 선택하고, 다음 상태에서의 최적 행동에 대한 최대 가치를 고려하여 현재 상태-행동 쌍에 대한 가치를 업데이트함,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8544f55",
   "metadata": {},
   "source": [
    "# 2) 강화 학습 중 Temporal Difference learning을 이용한 미로찾기\n",
    "## 2-1) Agent Class 정의\n",
    "## 2-2) Environment Class 정의\n",
    "## 2-3) main 정의\n",
    "## 2-4) Report : hyperparameter(episode, alpha, gamma, epsilon)에 따른 Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c52ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# 미로 csv 파일 불러오기 예시 지도 3개정도만 생성 해보기\n",
    "LABYRINTH_FILE = \"labyrinth.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f5888",
   "metadata": {},
   "source": [
    "## 2-1) Agent Class정의\n",
    "#### class에 사용된 property 정의\n",
    "- ACTIONS : agent의 행동을 4가지로 나타냄.\n",
    "#### class에 사용된 method 정의\n",
    "- \\_\\_init\\_\\_ : Agent class 생성자(객체 생성, 초기화)<br>\n",
    "- get_action_eps_greedy: 탐욕적 정책을 사용하여 행동을 수행하고, (1-epsilon)의 확률로 무작위 행동을 수행. random한 값을 생성하고, 그값이 (1- epsilon)보다 작으면 현재까지 학습된 policy에서 가장 가치 있는 행동을 선택, 크면 무작위 행동을 선택하여 새로운 experiment를 획득<br>\n",
    "- get_action_greedy: 지금까지 update해왔던(학습해왔던) Q 함수를 기준으로 가장 Q함수 값이 큰(가장 가치 있는 행동을 의미) 행동을 선택<br>\n",
    "- get_action_symb: 행동 기호를 반환. (출력을 위한 목적으로 up, left,down,right 등 4가지 방향을 반환)<br>\n",
    "- update_Q_function: 에피소드 내에서 정책을 실시간으로 업데이트하는 TD 단계를 수행,현재 상태에서의 행동 가치를 현재의 가치에 현재 행동으로 얻은 보상과 다음 상태에서의 최적 행동의 가치를 고려하여 업데이트하고,미래의 최적 행동 가치에 미래의 보상을 할인 계수(discount gamma)로 곱해 더한 값이 현재 행동 가치를 업데이트함. 또한 학습률(alpha)은 이 업데이트를 얼마나 강하게 적용할지를 결정 높은 학습률은 새로운 정보를 빠르게 받아들이고, 낮은 학습률은 이전의 정보를 보다 더 가중치를 두어 반영\n",
    "- \\_\\_repr\\_\\_: 가능한 모든 동작-상태에 대한 Q 함수(행렬)를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7e3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    # 에이전트의 Action을 4가지로 정의\n",
    "    ACTIONS = {\"UP\": 0, \"LEFT\": 1, \"DOWN\": 2, \"RIGHT\": 3}\n",
    "    \n",
    "    # Agent 클래스 생성자 : class의 property로 alpha,gamma,epsilon, lab_matrix_shape를 넘겨줌\n",
    "    def __init__(self, alpha: int, gamma: int, epsilon: float, lab_matrix_shape: tuple):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.num_actions = len(self.ACTIONS)\n",
    "        self.rows, self.columns = lab_matrix_shape\n",
    "        # Q 행렬을 무작위로 초기화하는 작업\n",
    "        self.Q = np.random.rand(self.rows, self.columns, self.num_actions)\n",
    "\n",
    "    # 가능한 모든 동작-상태에 대한 Q 함수(행렬)를 출력하는 함수(메서드)\n",
    "    def __repr__(self):\n",
    "        for action in range(self.num_actions):\n",
    "            print(f\"Q(y,x) for action: {action}\\n\")\n",
    "            print(str(np.round(self.Q[:, :, action], 2)) + \"\\n\")\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    # epsilon-greedy 정책을 사용하여 행동을 선택하는 함수(메서드)\n",
    "    def get_action_eps_greedy(self, state: tuple):\n",
    "        # 현재 agent의 상태를 state 라는 tuple에 저장\n",
    "        y_cor, x_cor = state\n",
    "        # 임임의 eps라는 값을 생성 추후에 self.epsilon값과 비교해 탐색을 할것인지 지금까지 가장 greedy 상태를 선택할 것인지 선택함.\n",
    "        eps = random.random()\n",
    "        \n",
    "        # eps와 self.epsilon을 비교하여 행동을 선택하고 return 값으로 ACTIONS = {\"UP\": 0, \"LEFT\": 1, \"DOWN\": 2, \"RIGHT\": 3}을 줌.\n",
    "        # up인 경우 숫자 0을 반환\n",
    "        \n",
    "        # eps보다 self.epsilon이 큰 경우에는 무작위적인 탐색을 진행함.\n",
    "        if eps < self.epsilon:\n",
    "            return random.randint(0, self.num_actions-1)\n",
    "        # eps가 큰 경우에는 지금까지 가장 greedy(상태가치함수가 가장 컸던)한 state를 선택함\n",
    "        else:\n",
    "            return np.argmax(self.Q[y_cor, x_cor])\n",
    "\n",
    "    def get_action_greedy(self, state: tuple):\n",
    "        # 학습이 끝난 후(정해두었던 episode가 끝난 후) 현재의 state를 입력으로 받고, 가장 greedy한 값을 찾음\n",
    "        # 반환 값은 ACTIONS = {\"UP\": 0, \"LEFT\": 1, \"DOWN\": 2, \"RIGHT\": 3}으로 표현됨.\n",
    "        # up인 경우 숫자 0을 반환\n",
    "        y_cor, x_cor = state\n",
    "\n",
    "        return np.argmax(self.Q[y_cor, x_cor])\n",
    "\n",
    "    def get_action_symb(self, state):\n",
    "        # 에이전트의 행동을 시각적으로 보여주기 위한 메서드임\n",
    "        # 위의 함수에서 반환값으로 ACTIONS = {\"UP\": 0, \"LEFT\": 1, \"DOWN\": 2, \"RIGHT\": 3}을 줌\n",
    "        # 반환값(0,1,2,3)과 agent class의 property의 값과 같다면 해당하는 방향에 알맞는 기호를 출력\n",
    "\n",
    "        # get_action_greedy이라는 함수에 state라는 tuple 입력을 넣고, 가장 greedy한 action을 선택\n",
    "        action = self.get_action_greedy(state)\n",
    "        \n",
    "        if action == self.ACTIONS[\"UP\"]:\n",
    "            return \"^\"\n",
    "        if action == self.ACTIONS[\"LEFT\"]:\n",
    "            return \"<\"\n",
    "        if action == self.ACTIONS[\"DOWN\"]:\n",
    "            return \"v\"\n",
    "        if action == self.ACTIONS[\"RIGHT\"]:\n",
    "            return \">\"\n",
    "\n",
    "    def update_Q_function(self, prev_state, new_state, reward, action):\n",
    "        # Q(s,a)←Q(s,a)+α⋅[R+γ⋅max a ′Q(s ′,a ′)−Q(s,a)]\n",
    "        # prev_state : 현재 상태를 의미 tuple (y_row, x_col)\n",
    "        # new_state : 새로운 상태를 의미 tuple (y_row, x_col)\n",
    "        # reward : 해당 해동에 대한 action에 대한 보상, int 형\n",
    "        # action : 현재 상태에서 새로운 상태로 전환을 의미 ACTIONS = {\"UP\": 0, \"LEFT\": 1, \"DOWN\": 2, \"RIGHT\": 3}\n",
    "\n",
    "        # \\는 다음 줄에 이어서 적겠다는 뜻\n",
    "        # Q1(s,a)←Q0(s,a)+α⋅[R+γ⋅max a ′Q(s ′,a ′)−Q(s,a)]\n",
    "        # Q1(s,a)는 새로운 상태를 나타냄,\n",
    "        # Q0(s,a)는 이전의 상태를 의미하고, alpha값(학습률)\n",
    "        # [R+γ⋅max a ′Q(s ′,a ′)−Q(s,a)] 다음 상태 s에서 가능한 모든 행동중 최대의 Q값을 찾기,\n",
    "        # 다음 상태에서의 최적 행동 가치를 나타냄\n",
    "        \n",
    "        #현재 상태에서의 행동 가치를 현재의 가치에 현재 행동으로 얻은 보상과 다음 상태에서의 최적 행동의 가치를 고려하여 업데이트\n",
    "        #미래의 최적 행동 가치에 미래의 보상을 할인 계수로 곱해 더한 값이 현재 행동 가치를 업데이트\n",
    "        #학습률은 이 업데이트를 얼마나 강하게 적용할지를 결정 높은 학습률은 새로운 정보를 빠르게 받아들이고, 낮은 학습률은 이전의 정보를 보다 더 가중치를 두어 반영\n",
    "        self.Q[prev_state[0], prev_state[1], action] =\\\n",
    "            self.Q[prev_state[0], prev_state[1], action] +\\\n",
    "            self.alpha * (reward + self.gamma * self.Q[new_state[0], new_state[1]].max() -\n",
    "                          self.Q[prev_state[0], prev_state[1], action])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268250c",
   "metadata": {},
   "source": [
    "## 2-2)Environment class 정의\n",
    "#### class의 property 정의 :\n",
    "지도의 구조를 0,1,2,3으로 정의하고, 보상과 벽으로 갔을 때 보상을 정의함.\n",
    "\n",
    "\n",
    "#### class의 property 정의 :\n",
    "- \\_\\_init\\_\\_ : Environment class 생성자(객체 생성, 초기화), 따로 준비한 지도가 있다면 True로 바꾸고, 지도파일(csv)를 넣어주면 됨.<br>\n",
    "- init_default_labyrinth : 미로 파일이 없는 경우 임의로 파일을 생성하는 메서드\n",
    "- \\_\\_repr\\_\\_ 와 policy_str : 학습된 policy를 화면에 표시하는 메서드\n",
    "- new_episode : episode가 한 번 끝나고, 새로운 episode를 위해 agent의 위치를 시작점으로 재설정하는 메서드\n",
    "- perform_action : agent가 선택한 행동에 따라 현재 상태를 업데이트하고, 현재 까지의 보상 및 목표에 도달 여부를 반환하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2118187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    LAB = 0\n",
    "    WALL = 1\n",
    "    START = 2\n",
    "    FINISH = 3\n",
    "\n",
    "    REWARD = -1\n",
    "    WALL_REWARD = -30\n",
    "\n",
    "    \n",
    "    def __init__(self, import_maze_csv=False):\n",
    "        # csv 파일이 있는 지 없는지 판별\n",
    "        # 있다면 추후에 조건문을 통해 csv를 받아드림.\n",
    "        self.from_csv = import_maze_csv  \n",
    "        self.lab_matrix = None\n",
    "        \n",
    "        # 시작점 위치, tuple\n",
    "        self.start_pos = tuple()\n",
    "        # 끝나는 지점의 위치, tuple \n",
    "        self.finish_pos = tuple()\n",
    "        # 현재 agent의 위치, tuple\n",
    "        self.agent_pos = tuple()\n",
    "\n",
    "        # 파일이 있으면 csv 파일을 읽어드림\n",
    "        if self.from_csv:\n",
    "            self.init_labyrinth_from_csv()\n",
    "        # 파일이 없으면 아래에 설정한 default 파일을 읽어드림\n",
    "        else:\n",
    "            self.init_default_labyrinth()\n",
    "\n",
    "        # start와 finish와 현재 위치를 초기화하는 작업\n",
    "        # np.argwhere NumPy 라이브러리에서 제공되는 함수로, 조건을 만족하는 배열 요소의 인덱스를 찾아 반환.\n",
    "        # 해당 요소와 값이 같은 index를 반환해줌\n",
    "        self.start_pos = tuple(np.argwhere(self.lab_matrix == self.START)[0])\n",
    "        self.finish_pos = tuple(np.argwhere(self.lab_matrix == self.FINISH)[0])\n",
    "        self.agent_pos = self.start_pos\n",
    "\n",
    "        # 가로와 세로를 tuple 값으로 정해줌\n",
    "        self.rows, self.cols = self.lab_matrix.shape\n",
    "\n",
    "        \n",
    "    # 지도 파일(csv)가 없는 경우에 default하게 사용하기 위한 미로\n",
    "    def init_default_labyrinth(self):\n",
    "        self.lab_matrix = np.array([\n",
    "            [self.WALL, self.WALL, self.WALL, self.WALL,\n",
    "                self.WALL, self.WALL, self.WALL, self.WALL],\n",
    "            [self.WALL, self.LAB, self.LAB, self.LAB,\n",
    "                self.LAB, self.LAB, self.LAB, self.WALL],\n",
    "            [self.START, self.LAB, self.WALL, self.WALL,\n",
    "                self.LAB, self.WALL, self.LAB, self.WALL],\n",
    "            [self.WALL, self.LAB, self.LAB, self.WALL,\n",
    "                self.WALL, self.LAB, self.LAB, self.WALL],\n",
    "            [self.WALL, self.WALL, self.LAB, self.LAB,\n",
    "                self.WALL, self.LAB, self.WALL, self.WALL],\n",
    "            [self.WALL, self.LAB, self.WALL, self.LAB,\n",
    "                self.WALL, self.LAB, self.LAB, self.WALL],\n",
    "            [self.WALL, self.LAB, self.LAB, self.LAB,\n",
    "                self.LAB, self.WALL, self.LAB, self.FINISH],\n",
    "            [self.WALL, self.WALL, self.WALL, self.WALL,\n",
    "                self.WALL, self.WALL, self.WALL, self.WALL]\n",
    "        ])\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    # 지도 파일을 가져오기 위한 메서드\n",
    "    # 지도 파일을 가져오기 위해 제약조건을 검사하는 함수\n",
    "    def init_labyrinth_from_csv(self, path=LABYRINTH_FILE):\n",
    "        \n",
    "        # 주의 사항 1: 헤더가 없어야함\n",
    "        # 주의 사항 2: 오직 4가지 허용된 심볼만 사용해야함\n",
    "        # 주의 사항 3: 시작 지점은 하나만 존재하고, 목표 지점도 하나만 존재해야함.\n",
    "        \n",
    "        # pandas의 read_csv를 통해 csv파일을 읽어옴.\n",
    "        df_lab = pd.read_csv(path, header=None)\n",
    "        \n",
    "        # lab_matrix 생성 \n",
    "        self.lab_matrix = df_lab.to_numpy()\n",
    "\n",
    "        # np.unique함수를 이용해서 csv 파일에 이상이 없는 지 검사, 중복없이 4가지 symbol만 나옴\n",
    "        unique, counts = np.unique(self.lab_matrix, return_counts=True)\n",
    "        \n",
    "        # error를 감지하는 함수 \n",
    "        # unique의 길이가 4가 아니면 해당 string 출력\n",
    "        assert len(\n",
    "            unique) == 4, \"오직 4가지의 symbol만 사용이 가능합니다. \\nLAB = 0; WALL = 1; START = 2;FINISH = 3;\"\n",
    "\n",
    "        dict_values = dict(zip(unique, counts))\n",
    "        assert dict_values[self.START] == 1 and dict_values[self.FINISH] == 1, \"지도 파일에 출발과 도착은 반드시 하나씩 존재해야함\\n\"\n",
    "\n",
    "        return\n",
    "\n",
    "    ## agent와 state를 화면에 표시\n",
    "    def __repr__(self):\n",
    "        environment_description = ''\n",
    "\n",
    "        # for문을 통해서 agent\n",
    "        # row(가로)와 col(세로)를 통해서 미로를 2차원 list로 보고\n",
    "        # for문을 돌리면서 각각의 list를 symbol로 표시\n",
    "        for i in range(0, self.rows):\n",
    "            for j in range(0, self.cols):\n",
    "                if self.agent_pos == (i, j):\n",
    "                    # 도착했을 때 표시\n",
    "                    if self.lab_matrix[i, j] == self.FINISH:\n",
    "                        environment_description += '🏁'\n",
    "                    # agent를 다음과 같이 표시\n",
    "                    else:\n",
    "                        environment_description += '🤖'\n",
    "                        \n",
    "                    # 출발 지점에 대한 표시\n",
    "                elif self.lab_matrix[i, j] == self.LAB or self.lab_matrix[i, j] == self.START:\n",
    "                    environment_description += '. '\n",
    "                    # 벽에 대한 표현\n",
    "                elif self.lab_matrix[i, j] == self.WALL:\n",
    "                    environment_description += '█ '\n",
    "                    # 도착에 대한 표현\n",
    "                elif self.lab_matrix[i, j] == self.FINISH:\n",
    "                    environment_description += '✔ '\n",
    "\n",
    "            environment_description += '\\n'\n",
    "        return environment_description\n",
    "\n",
    "    \n",
    "    def policy_str(self, agent):\n",
    "        # agent라는 강화학습 에이전트 객체를 나타내고, \n",
    "        # return 값으로 에이전트가 학습한 정책을 텍스트 형태로 나타냄\n",
    "\n",
    "        policy_description = ''\n",
    "\n",
    "        for i in range(0, self.rows):\n",
    "            for j in range(0, self.cols):\n",
    "                ## 벽이면 █ \n",
    "                if self.lab_matrix[i, j] == self.WALL:\n",
    "                    policy_description += '█ '\n",
    "                ## 도착했으면 ✔\n",
    "                elif self.lab_matrix[i, j] == self.FINISH:\n",
    "                    policy_description += '✔ '\n",
    "                else:\n",
    "                    action_symb = agent.get_action_symb(state=(i, j))\n",
    "                    policy_description += action_symb + ' '\n",
    "            policy_description += '\\n'\n",
    "        return policy_description\n",
    "\n",
    "    \n",
    "    def new_episode(self):\n",
    "        # 새로운 episode를 시작할 때 agent의 위치를 초기 상태로 돌림\n",
    "        self.agent_pos = self.start_pos\n",
    "        return self.agent_pos\n",
    "\n",
    "    \n",
    "    def perform_action(self, action):\n",
    "        # parameter action은 agent가 수행할 행동을 나타내는 매개변수\n",
    "        (y, x) = self.agent_pos\n",
    "\n",
    "        ## parameter 값에 따라 agent의 position에 변화를 줌\n",
    "        ## up 일경우\n",
    "        if action == Agent.ACTIONS[\"UP\"]:\n",
    "            y -= 1\n",
    "        ## left일 경우\n",
    "        elif action == Agent.ACTIONS[\"LEFT\"]:\n",
    "            x -= 1\n",
    "        ## down 일경우\n",
    "        elif action == Agent.ACTIONS[\"DOWN\"]:\n",
    "            y += 1\n",
    "        ## right 일경우\n",
    "        elif action == Agent.ACTIONS[\"RIGHT\"]:\n",
    "            x += 1\n",
    "\n",
    "        ## agent의 위치가 미로 안에 있는지 확인 하는 조건문\n",
    "        if 0 < y < self.rows and 0 < x < self.cols:\n",
    "            self.agent_pos = (y, x)\n",
    "\n",
    "        # agnet의 위치와 agnet가 행동의 결과로 얻은 보상,\n",
    "        # self.get_reward와 self.is_over이 없지만, 아래에 @ 데코레이션을 통해 생성함. \n",
    "        return self.agent_pos, self.get_reward, self.is_over\n",
    "\n",
    "    \n",
    "    ## @ 데코레이션 : 파이썬에서 클래스의 속성(property)인것 처럼 변환하는 기능을 제공\n",
    "    @property\n",
    "    def is_over(self):\n",
    "        # agent가 finish 위치에 도착했는지를 boolean 값으로 나타냄\n",
    "        return self.agent_pos == self.finish_pos\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def get_reward(self):\n",
    "        ## reward의 기본값은 -1이고, 벽에 닿는다면 WALL_REWARD는 -30을 부여함\n",
    "        ## 벽에 최대한 닿지 않고, 빠른 길을 택하는 게 가장 높은 reward를 받음. \n",
    "        y, x = self.agent_pos\n",
    "\n",
    "        if self.lab_matrix[y, x] == self.WALL:\n",
    "            return self.WALL_REWARD\n",
    "        else:\n",
    "            return self.REWARD\n",
    "\n",
    "        \n",
    "    def get_maze_shape(self):\n",
    "        ## 미로 행렬의 행과 열의 개수로 계산하는 메서드\n",
    "        ## numpy의 shape를 이용해서 lab_matrix의 shape을 계산함.\n",
    "        return self.lab_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b681a",
   "metadata": {},
   "source": [
    "## 2-3) main 정의\n",
    "#### main 함수\n",
    "episode의 수와 alpha(학습률), gamma(미래에 보상에 대한 계수), epsilon(무작위 행동을 하는 확률 계수), import_maze_csv : csv 파일을 가져오는 지, trainning과정을 하나하나 보여주는 지에 대해 나타내는 파라미터를 가지고, agent와 envrionment의 객체를 생성해서 parameter에 따라 학습을 진행함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6bfb8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 108 Tot Reward: -1471\n",
      "Episode: 2 - Tot Steps: 167 Tot Reward: -863\n",
      "Episode: 3 - Tot Steps: 185 Tot Reward: -475\n",
      "Episode: 4 - Tot Steps: 104 Tot Reward: -162\n",
      "Episode: 5 - Tot Steps: 88 Tot Reward: -146\n",
      "Episode: 6 - Tot Steps: 141 Tot Reward: -315\n",
      "Episode: 7 - Tot Steps: 91 Tot Reward: -294\n",
      "Episode: 8 - Tot Steps: 97 Tot Reward: -155\n",
      "Episode: 9 - Tot Steps: 51 Tot Reward: -109\n",
      "Episode: 10 - Tot Steps: 50 Tot Reward: -79\n",
      "Episode: 11 - Tot Steps: 69 Tot Reward: -98\n",
      "Episode: 12 - Tot Steps: 51 Tot Reward: -80\n",
      "Episode: 13 - Tot Steps: 40 Tot Reward: -69\n",
      "Episode: 14 - Tot Steps: 59 Tot Reward: -88\n",
      "Episode: 15 - Tot Steps: 22 Tot Reward: -51\n",
      "Episode: 16 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 17 - Tot Steps: 22 Tot Reward: -51\n",
      "Episode: 18 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 19 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 20 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 21 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 22 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 23 - Tot Steps: 97 Tot Reward: -155\n",
      "Episode: 24 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 25 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 26 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 27 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 28 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 29 - Tot Steps: 79 Tot Reward: -195\n",
      "Episode: 30 - Tot Steps: 19 Tot Reward: -48\n",
      "Episode: 31 - Tot Steps: 15 Tot Reward: -44\n",
      "Episode: 32 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 33 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 34 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 35 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 36 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 37 - Tot Steps: 17 Tot Reward: -46\n",
      "Episode: 38 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 39 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 40 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 41 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 42 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 43 - Tot Steps: 19 Tot Reward: -48\n",
      "Episode: 44 - Tot Steps: 18 Tot Reward: -76\n",
      "Episode: 45 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 46 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 47 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 48 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 49 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 50 - Tot Steps: 16 Tot Reward: -16\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.63   0.73   0.03   0.36   0.2    0.82   0.57   0.73]\n",
      " [  0.64  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -20.81]\n",
      " [ -1.67  -1.67  -1.55  -1.21  -1.67  -0.35  -1.66 -20.74]\n",
      " [  0.09  -1.67 -20.53 -20.87  -0.42 -20.49  -1.66 -20.65]\n",
      " [  0.15  -1.58  -1.67 -20.91 -20.66  -1.66  -1.21   0.1 ]\n",
      " [  0.49 -29.45  -1.52  -1.67 -20.51  -1.54 -27.54   0.54]\n",
      " [  0.2   -1.67 -27.22  -1.67 -29.31  -1.23  -1.27   0.39]\n",
      " [  0.24  -1.31  -1.26  -1.52  -0.46 -20.83  -1.28  -0.28]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.04   0.09   0.82   0.66   0.35   0.07   0.91   0.9 ]\n",
      " [  0.21  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.56]\n",
      " [ -1.67  -1.67  -1.31 -20.83 -27.22  -1.22 -20.9   -1.29]\n",
      " [  0.28  -1.67  -1.67  -1.25 -20.47 -20.69  -1.66  -0.22]\n",
      " [  0.08 -20.8  -27.54  -1.67  -0.42 -27.26  -1.42 -20.66]\n",
      " [  0.78  -1.67  -1.36 -29.36  -1.36 -27.44  -1.49  -0.34]\n",
      " [  0.65  -1.67  -1.67  -1.67  -1.67  -0.36 -27.27   0.7 ]\n",
      " [  0.03 -20.85 -20.71 -20.83 -20.72 -20.79 -20.74   0.37]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 6.000e-01  1.000e-02  5.800e-01  5.000e-02  7.300e-01  9.000e-02\n",
      "   3.800e-01  3.800e-01]\n",
      " [ 1.000e-02 -1.670e+00 -2.732e+01 -2.730e+01 -1.670e+00 -2.729e+01\n",
      "  -1.670e+00 -2.052e+01]\n",
      " [-1.670e+00 -1.670e+00 -5.300e-01 -2.051e+01 -2.728e+01 -5.600e-01\n",
      "  -1.660e+00 -2.045e+01]\n",
      " [ 5.600e-01 -3.027e+01 -1.670e+00 -3.700e-01 -2.068e+01 -1.640e+00\n",
      "  -2.075e+01  2.100e-01]\n",
      " [ 8.300e-01 -1.580e+00 -3.017e+01 -1.670e+00 -2.060e+01 -1.610e+00\n",
      "  -1.190e+00  5.300e-01]\n",
      " [ 9.800e-01 -1.670e+00 -1.390e+00 -1.670e+00 -1.280e+00 -2.057e+01\n",
      "  -1.290e+00 -3.200e-01]\n",
      " [ 8.600e-01 -2.733e+01 -2.731e+01 -2.957e+01 -2.057e+01 -2.078e+01\n",
      "  -3.039e+01  1.000e-01]\n",
      " [ 5.100e-01 -2.083e+01 -2.082e+01 -2.754e+01 -2.045e+01  1.500e-01\n",
      "  -2.050e+01 -2.050e+01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.44   0.31   0.03   0.63   0.07   0.54   0.46   0.22]\n",
      " [  0.92  -1.67  -1.67  -1.67  -1.67  -1.67 -29.49 -20.98]\n",
      " [ -1.67 -29.36 -20.49  -1.31 -20.71  -0.65 -27.25 -20.98]\n",
      " [  0.87  -1.67 -27.3  -20.45  -1.25  -1.65 -20.75   0.44]\n",
      " [  0.63  -1.55  -1.67 -20.84  -1.26 -29.29 -20.52   0.38]\n",
      " [  0.14 -27.45  -1.46 -20.62  -1.22  -1.52 -27.01   0.36]\n",
      " [  0.19  -1.67  -1.67  -1.67 -20.63  -0.5   -0.72   0.63]\n",
      " [  0.29 -20.63 -20.87 -20.8  -20.51 -20.43 -20.47   0.05]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ ^ v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)을 가지고, 실행합니다.\n",
      "step 0\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 1\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". 🤖█ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 2\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ 🤖. . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 3\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . 🤖. . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 4\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . 🤖. . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 5\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . 🤖. . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 6\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . 🤖. █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 7\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . 🤖█ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 8\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ 🤖█ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 9\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . 🤖█ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 10\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ 🤖. █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 11\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ 🤖█ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 12\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ 🤖. █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 13\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . 🤖█ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 14\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ 🤖✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "# default argument 선언 \n",
    "def main(n_episodes, alpha, gamma, epsilon, import_maze_csv =False,show_training=False, result_screening = True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_episodes : 강화 학습 알고리즘을 위한 에피소드의 수\n",
    "\n",
    "    alpha: 정책 업데이트의 가중치에 대한 계수\n",
    "\n",
    "    gamma: 미래 상태 보상에 대한 TD(Q-learning) 알고리즘의 할인 계수, 미래 상태 보상에 대한 중요성을 조절\n",
    "\n",
    "    espilon: 에이전트를 훈련하는 동안 무작위 행동을 선택할 확률을 설정하는 계수입니다.\n",
    "            10%의 확률로 무작위 행동을 선택합니다.\n",
    "\n",
    "    import_maze_csv: Bool (default is False)\n",
    "        True로 설정하면 csv 파일에서 미로를 가져오고, 파일 경로는 처음 부분에 정의된 LABYRINT_FILE 상수에 의해 정의됩니다.\n",
    "        3가지 option\n",
    "        \n",
    "    show_training: Bool (default is False)\n",
    "         True로 설정하면 훈련 단계에서 에이전트 이동을 모든 에포크 동안 표시합니다.\n",
    "            n_episodes가 큰 수이거나 미로 공간이 큰 경우 시간이 소요될 수 있습니다.\n",
    "    \"\"\"\n",
    "    # 환경 객체를 생성함.\n",
    "    environment = Environment(import_maze_csv=import_maze_csv)\n",
    "\n",
    "    # 환격 객체의 get_maze_shape() 메서드를 이용해서 지도를 가져옴\n",
    "    maze_shape = environment.get_maze_shape()\n",
    "    \n",
    "    # agent 클래스의 객체를 생성하고, 생성자에 alpha와 gamma , epsilon, map_shape를 넘겨줌\n",
    "    agent = Agent(alpha=alpha, gamma=gamma, epsilon=epsilon,\n",
    "                    lab_matrix_shape=maze_shape)\n",
    "\n",
    "    # 시작합니다.\n",
    "    print(\"Maze to solve and Agent start position:\\n\\n\")\n",
    "    print(environment)\n",
    "\n",
    "    # 에피소드만큼 loop를 반복\n",
    "    for e in range(n_episodes):\n",
    "\n",
    "        # 강화학습 객체의 수행능력을 평가하기위해서 reward를 축척시킴\n",
    "        # reward의 초기화\n",
    "        tot_reward = 0\n",
    "        # episode step 초기화\n",
    "        steps = 0  # episode steps counter\n",
    "        # agent 위치 초기화\n",
    "        state = environment.new_episode()\n",
    "        # 도착 여부 False로 설정\n",
    "        is_over = False  # termination flag\n",
    "\n",
    "        \n",
    "        # is_over이 되기까지 계속 reward를 축척함.\n",
    "        while True:\n",
    "            ## show_trainning이라는 화면을 보여주는지에 대한 값을 받고, True면 과정을 다보여줌\n",
    "            if (show_training):\n",
    "                # 화면 clear하고 step과 envrionmenet의 상태를 출력\n",
    "                os.system('cls' if os.name == 'nt' else 'clear')\n",
    "                print(f\"Step: {steps}\")\n",
    "                print(environment)\n",
    "\n",
    "            # 에이전트는 epsilon-greedy 정책을 사용하여 탐험을 하거나\n",
    "            # 기존의 학습된 데이터를 가지고 가장 좋은 선택지를 선택\n",
    "            action = agent.get_action_eps_greedy(state=state)\n",
    "\n",
    "            # environment 객체의 perfomr_action이라는 메서드를 통해서, 다음 state에 대한 position과\n",
    "            # 보상, 그리고 도착여부에 대해 받는다.\n",
    "            new_state, reward, is_over = environment.perform_action(\n",
    "                action=action)\n",
    "\n",
    "            # agent는 TD 업데이트를 통해서 Q함수를 업데이트함.\n",
    "            agent.update_Q_function(\n",
    "                prev_state=state, new_state=new_state, reward=reward, action=action)\n",
    "\n",
    "            # 보상을 축척하는 과정\n",
    "            tot_reward += reward\n",
    "            # 다음 상태로의 전이를 의미\n",
    "            state = new_state  \n",
    "            # step을 하나씩 증가시킴\n",
    "            steps += 1  \n",
    "\n",
    "            # is_over 즉 episode가 끝나면 while문 탈출\n",
    "            if is_over:  \n",
    "                break\n",
    "\n",
    "        # 에피소드의 수와 step수, 토탈 보상을 출력함        \n",
    "        print(f'Episode: {e+1} - Tot Steps: {steps} Tot Reward: {tot_reward}')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # 학습된 Q 함수를 구분하기 위해 사용\n",
    "    print('\\nQ 함수 학습 과정:\\n')\n",
    "    # Q 배열을 출력함\n",
    "    print(agent)\n",
    "    \n",
    "    # 최종 적으로 학습된 저책\n",
    "    print('\\n\\n최종적으로 학습된 Policy:\\n')\n",
    "    # 최종적으로 학습된 정책을 출력\n",
    "    print(environment.policy_str(agent))\n",
    "\n",
    "\n",
    "    # 최종적으로 학습된 정책을 보고 실행과정을 출력\n",
    "    print('\\n\\n최종적으로 학습된 정책(방향키를)을 가지고, 실행합니다.')\n",
    "\n",
    "\n",
    "    # 최종적으로 완성된 정책에 따라서 episode 진행\n",
    "    # 화면상에 보이는 agent의 위치 초기화\n",
    "    state = environment.new_episode()\n",
    "    # 도착여부를 나타내는 flag\n",
    "    is_over = False \n",
    "    # step의 갯수를 count\n",
    "    counter = 0\n",
    "    while True:\n",
    "        \n",
    "        if(result_screening):\n",
    "            ## 화면을 깨끗히 clear\n",
    "            os.system('cls' if os.name == 'nt' else 'clear')  # clear screen\n",
    "            # agent가 화면에 도착하는 과정을 하나씩 출력함.\n",
    "            print(f\"step {counter}\\n\")\n",
    "            print(environment)\n",
    "\n",
    "        # 에이전트는 epsilon-greedy 정책을 사용하여 탐험을 하거나\n",
    "        # 기존의 학습된 데이터를 가지고 가장 좋은 선택지를 선택\n",
    "        action = agent.get_action_greedy(state=state)\n",
    "\n",
    "        # environment 객체의 perfomr_action이라는 메서드를 통해서, 다음 state에 대한 position과\n",
    "        # 보상, 그리고 도착여부에 대해 받는다.\n",
    "        new_state, reward, is_over = environment.perform_action(action=action)\n",
    "\n",
    "        # 상태를 업데이트하고 count를 추가함\n",
    "        state = new_state\n",
    "        counter += 1\n",
    "        \n",
    "        # 너무 오래 걸리는 것 방지 최대 100까지\n",
    "        if(counter == 20):\n",
    "            print(\"\\n======================================================\")\n",
    "            print(\"\\n입구를 찾을 수 없습니다.\")\n",
    "            print('\\n======================================================')\n",
    "            return tot_reward \n",
    "        \n",
    "    \n",
    "        # 도착했다면 함수를 종료함.\n",
    "        if is_over: \n",
    "            time.sleep(0.5)\n",
    "            os.system('cls' if os.name == 'nt' else 'clear') \n",
    "            print(f\"step {counter}\\n\")\n",
    "            print(environment)\n",
    "            print(\"\\nFinish!\")\n",
    "\n",
    "            return tot_reward\n",
    "        \n",
    "\n",
    "## 임의로 episode 30 alpha 0.7, gamma 0.4, epsilon =0.05 대입\n",
    "if __name__ == '__main__':\n",
    "    reward = main(n_episodes=50, alpha=0.7, gamma=0.4,\n",
    "         epsilon = 0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c9ec0b9",
   "metadata": {},
   "source": [
    "## 2-4) Report : hyperparameter(episode, alpha, gamma, epsilon)에 따른 Reward\n",
    "각 각의 과정은 아래에 별도로 첨부!\n",
    "\n",
    "#### a) 모든 파라미터가 동일하고, episode에 따른 Reward값 변화 결과 그래프\n",
    "![](./episode_reward.png)\n",
    "#### b) 모든 파라미터가 동일하고, alpha에 따른 Reward값 변화 결과 그래프\n",
    "![](./alpha_reward.png)\n",
    "#### c) 모든 파라미터가 동일하고, gamma에 따른 Reward값 변화 결과 그래프\n",
    "![](./gamma_reward.png)\n",
    "#### d) 모든 파라미터가 동일하고, epsilon에 따른 Reward값 변화 결과 그래프\n",
    "![](./epsilon_reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848d53c",
   "metadata": {},
   "source": [
    "#### a) 모든 파라미터가 동일하고, episode에 따른 Reward값 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a40f40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 190 Tot Reward: -2104\n",
      "Episode: 2 - Tot Steps: 51 Tot Reward: -138\n",
      "Episode: 3 - Tot Steps: 45 Tot Reward: -219\n",
      "Episode: 4 - Tot Steps: 316 Tot Reward: -577\n",
      "Episode: 5 - Tot Steps: 172 Tot Reward: -375\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.68   0.48   0.43   0.34   0.89   0.2    0.24   0.11]\n",
      " [  0.29  -1.63  -1.61  -1.62  -1.61  -1.59  -1.58 -14.31]\n",
      " [ -1.18  -1.63  -0.7   -0.49  -1.62  -0.6   -1.59   0.47]\n",
      " [  0.62  -1.63 -22.43 -14.43  -0.17 -22.4   -1.58 -14.52]\n",
      " [  0.25  -0.38  -1.63 -14.57 -14.57  -1.56  -0.89 -14.6 ]\n",
      " [  0.72 -14.74  -0.18  -1.62 -14.43  -1.46 -26.21 -14.6 ]\n",
      " [  0.07  -1.62 -14.86  -1.62 -14.78  -0.15  -1.05   0.31]\n",
      " [  0.1   -0.95  -0.32   0.04   0.51 -14.42  -0.67   0.2 ]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.54   0.93   0.81   0.82   0.18   0.24   0.69   0.69]\n",
      " [  0.53  -1.62  -1.62  -1.62  -1.62  -1.6   -1.59  -0.18]\n",
      " [ -1.21  -1.62  -0.37 -14.62 -14.65  -0.88 -22.33  -0.11]\n",
      " [  0.67  -1.62  -1.62  -0.34 -14.37 -14.85  -1.59  -0.36]\n",
      " [  0.26 -14.7  -14.43  -1.62  -0.8  -14.64  -0.37 -14.73]\n",
      " [  0.32  -1.62  -0.04 -14.35  -0.3  -14.69  -1.29   0.09]\n",
      " [  0.86  -1.61  -1.61  -1.61  -1.62  -0.56 -14.63   0.79]\n",
      " [  0.48 -14.38 -14.8  -14.48   0.1    0.3  -14.4  -14.49]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 1.200e-01  5.400e-01  5.000e-01  7.800e-01  6.000e-01  2.100e-01\n",
      "   7.500e-01  6.800e-01]\n",
      " [ 4.300e-01 -1.620e+00 -1.455e+01 -1.482e+01 -1.610e+00 -2.620e+01\n",
      "  -1.600e+00  1.900e-01]\n",
      " [-1.220e+00 -1.620e+00 -4.500e-01 -1.439e+01 -1.475e+01 -9.300e-01\n",
      "  -1.590e+00 -1.446e+01]\n",
      " [ 3.700e-01 -2.234e+01 -1.620e+00 -7.400e-01 -1.485e+01 -1.580e+00\n",
      "  -1.485e+01 -1.472e+01]\n",
      " [ 1.000e-01 -2.900e-01 -2.212e+01 -1.610e+00 -1.469e+01 -1.520e+00\n",
      "  -7.900e-01 -1.462e+01]\n",
      " [ 7.500e-01 -1.620e+00 -1.000e-02 -1.610e+00 -4.500e-01 -1.471e+01\n",
      "  -1.210e+00  3.000e-02]\n",
      " [ 1.000e-02 -2.238e+01 -1.451e+01 -1.433e+01 -1.460e+01 -1.438e+01\n",
      "  -1.463e+01  7.000e-01]\n",
      " [ 8.900e-01 -1.489e+01 -1.492e+01  4.000e-01  3.000e-01  3.200e-01\n",
      "  -1.467e+01  4.400e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.92   0.72   0.8    0.96   0.16   0.61   0.3    0.93]\n",
      " [  0.98  -1.63  -1.63  -1.63  -1.61  -1.6  -14.57   0.04]\n",
      " [ -1.38 -22.44 -14.54  -0.3  -14.42  -0.79 -14.63   0.13]\n",
      " [  0.85  -1.62 -22.36 -14.35  -0.03  -1.57 -14.71 -14.46]\n",
      " [  0.41  -0.84  -1.62 -22.46  -0.49 -14.53 -14.66 -14.71]\n",
      " [  0.86 -14.7   -0.48 -14.43  -0.25  -1.42 -14.38   0.26]\n",
      " [  0.74  -1.62  -1.62  -1.62 -14.94  -0.16  -0.66   0.31]\n",
      " [  0.72 -14.7  -14.63   0.15 -14.54 -22.13 -14.47   0.31]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ < ^ < ^ ^ ^ █ \n",
      "^ < █ █ ^ █ v █ \n",
      "█ > < █ █ > ^ █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 21 Tot Reward: -311\n",
      "Episode: 2 - Tot Steps: 129 Tot Reward: -1231\n",
      "Episode: 3 - Tot Steps: 118 Tot Reward: -872\n",
      "Episode: 4 - Tot Steps: 238 Tot Reward: -644\n",
      "Episode: 5 - Tot Steps: 145 Tot Reward: -232\n",
      "Episode: 6 - Tot Steps: 108 Tot Reward: -253\n",
      "Episode: 7 - Tot Steps: 95 Tot Reward: -124\n",
      "Episode: 8 - Tot Steps: 112 Tot Reward: -141\n",
      "Episode: 9 - Tot Steps: 209 Tot Reward: -238\n",
      "Episode: 10 - Tot Steps: 45 Tot Reward: -74\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 7.100e-01  5.300e-01  7.300e-01  5.100e-01  3.200e-01  3.700e-01\n",
      "   9.100e-01  8.000e-02]\n",
      " [ 9.400e-01 -1.660e+00 -1.660e+00 -1.660e+00 -1.660e+00 -1.660e+00\n",
      "  -1.650e+00 -1.443e+01]\n",
      " [-1.640e+00 -1.660e+00 -2.200e-01 -1.300e-01 -1.660e+00 -7.000e-02\n",
      "  -1.650e+00  2.500e-01]\n",
      " [ 2.100e-01 -1.660e+00 -1.452e+01 -1.457e+01 -8.000e-02 -1.485e+01\n",
      "  -1.640e+00  1.200e-01]\n",
      " [ 2.600e-01 -4.300e-01 -1.660e+00 -1.474e+01 -1.473e+01 -1.590e+00\n",
      "  -5.600e-01 -1.465e+01]\n",
      " [ 3.000e-01 -2.230e+01 -8.400e-01 -1.660e+00 -1.437e+01 -1.550e+00\n",
      "  -1.488e+01 -1.478e+01]\n",
      " [ 5.400e-01 -1.660e+00 -2.817e+01 -1.660e+00 -1.477e+01  1.000e-02\n",
      "  -1.170e+00  9.900e-01]\n",
      " [ 7.000e-02 -1.190e+00 -7.100e-01 -1.060e+00 -8.700e-01 -1.479e+01\n",
      "   1.700e-01  4.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 6.900e-01  5.500e-01  5.600e-01  4.200e-01  8.500e-01  5.000e-01\n",
      "   5.900e-01  2.100e-01]\n",
      " [ 6.400e-01 -1.660e+00 -1.660e+00 -1.660e+00 -1.660e+00 -1.660e+00\n",
      "  -1.660e+00 -1.400e-01]\n",
      " [-1.640e+00 -1.660e+00 -2.500e-01 -1.474e+01 -1.455e+01 -4.000e-02\n",
      "  -1.449e+01 -6.600e-01]\n",
      " [ 6.000e-02 -1.660e+00 -1.660e+00 -1.100e-01 -1.471e+01 -1.454e+01\n",
      "  -1.640e+00 -1.200e-01]\n",
      " [ 3.600e-01 -1.450e+01 -1.462e+01 -1.660e+00 -8.100e-01 -2.238e+01\n",
      "  -7.200e-01 -1.445e+01]\n",
      " [ 2.000e-02 -1.660e+00 -9.600e-01 -1.467e+01 -7.000e-02 -1.459e+01\n",
      "  -1.230e+00 -4.900e-01]\n",
      " [ 7.000e-01 -1.660e+00 -1.660e+00 -1.660e+00 -1.660e+00 -1.700e-01\n",
      "  -1.462e+01  9.400e-01]\n",
      " [ 8.300e-01 -1.451e+01 -1.489e+01 -1.434e+01 -1.493e+01 -1.500e+01\n",
      "  -1.438e+01  5.100e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 9.200e-01  0.000e+00  5.100e-01  9.300e-01  7.000e-01  3.400e-01\n",
      "   3.200e-01  2.000e-01]\n",
      " [ 9.200e-01 -1.660e+00 -1.455e+01 -1.487e+01 -1.660e+00 -1.435e+01\n",
      "  -1.660e+00  1.400e-01]\n",
      " [-1.640e+00 -1.660e+00  1.000e-02 -1.451e+01 -1.451e+01 -7.500e-01\n",
      "  -1.650e+00 -1.455e+01]\n",
      " [ 4.000e-02 -1.446e+01 -1.660e+00 -3.300e-01 -1.448e+01 -1.610e+00\n",
      "  -2.227e+01 -2.220e+01]\n",
      " [ 2.800e-01 -1.600e-01 -1.453e+01 -1.660e+00 -1.489e+01 -1.570e+00\n",
      "  -8.100e-01 -2.218e+01]\n",
      " [ 3.200e-01 -1.660e+00 -3.500e-01 -1.660e+00 -4.000e-02 -1.475e+01\n",
      "  -1.230e+00 -1.400e-01]\n",
      " [ 8.900e-01 -2.625e+01 -2.232e+01 -2.249e+01 -2.224e+01 -1.472e+01\n",
      "  -1.435e+01  6.200e-01]\n",
      " [ 2.300e-01 -1.486e+01 -1.443e+01 -1.495e+01 -1.430e+01 -1.447e+01\n",
      "  -1.435e+01  1.200e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.5    0.43   0.68   0.71   0.4    0.45   0.55   0.62]\n",
      " [  0.1   -1.66  -1.66  -1.66  -1.66  -1.66 -14.67   0.36]\n",
      " [ -1.65 -14.57 -14.78  -0.26 -22.26  -0.58 -22.22 -14.46]\n",
      " [  0.16  -1.66 -14.38 -14.41  -0.34  -1.62 -14.79   0.41]\n",
      " [  0.89  -0.89  -1.66 -22.25  -0.39 -22.43 -14.37 -14.67]\n",
      " [  0.48 -14.91  -0.91 -14.51  -0.28  -1.46 -14.75 -14.45]\n",
      " [  0.39  -1.66  -1.66  -1.66 -14.78  -0.38  -0.6    0.56]\n",
      " [  0.33 -14.88 -14.68 -14.66 -14.96 -14.49 -14.74 -14.45]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ v < < ^ < ^ █ \n",
      "< < █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > < █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 108 Tot Reward: -1442\n",
      "Episode: 2 - Tot Steps: 245 Tot Reward: -1144\n",
      "Episode: 3 - Tot Steps: 95 Tot Reward: -95\n",
      "Episode: 4 - Tot Steps: 240 Tot Reward: -385\n",
      "Episode: 5 - Tot Steps: 88 Tot Reward: -88\n",
      "Episode: 6 - Tot Steps: 34 Tot Reward: -63\n",
      "Episode: 7 - Tot Steps: 58 Tot Reward: -116\n",
      "Episode: 8 - Tot Steps: 35 Tot Reward: -93\n",
      "Episode: 9 - Tot Steps: 51 Tot Reward: -51\n",
      "Episode: 10 - Tot Steps: 60 Tot Reward: -89\n",
      "Episode: 11 - Tot Steps: 208 Tot Reward: -440\n",
      "Episode: 12 - Tot Steps: 47 Tot Reward: -47\n",
      "Episode: 13 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 14 - Tot Steps: 44 Tot Reward: -44\n",
      "Episode: 15 - Tot Steps: 261 Tot Reward: -406\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.27   0.68   0.1    0.15   0.04   0.6    0.94   0.29]\n",
      " [  0.1   -1.67  -1.67  -1.67  -1.67  -1.66  -1.66   0.91]\n",
      " [ -1.67  -1.67  -0.1   -0.18  -1.66   0.13  -1.66   0.12]\n",
      " [  0.28  -1.67 -22.42 -14.38  -0.39 -14.47  -1.66   0.13]\n",
      " [  0.09  -0.9   -1.67 -14.32 -14.66  -1.62  -0.2  -14.5 ]\n",
      " [  0.87 -26.17  -0.88  -1.67 -14.39  -1.57 -14.58 -14.44]\n",
      " [  0.42  -1.67 -22.38  -1.67 -14.52  -0.46  -1.13   0.48]\n",
      " [  0.28  -0.97  -0.89  -1.11  -0.76 -14.51  -0.05   0.97]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.83   0.23   0.19   0.96   0.08   0.45   0.62   0.07]\n",
      " [  0.27  -1.67  -1.67  -1.67  -1.67  -1.66  -1.66   0.13]\n",
      " [ -1.67  -1.67  -0.76 -14.65 -14.38  -0.37 -14.32   0.45]\n",
      " [  0.38  -1.67  -1.67   0.04 -14.74 -14.69  -1.66  -0.4 ]\n",
      " [  0.13 -14.87 -14.72  -1.67  -1.02 -22.51  -0.06 -14.69]\n",
      " [  0.77  -1.67  -1.05 -26.24  -0.43 -22.27  -1.46  -0.2 ]\n",
      " [  0.9   -1.67  -1.67  -1.67  -1.67  -0.83 -22.26   0.4 ]\n",
      " [  0.08 -14.68 -14.72 -14.7  -14.62 -14.6    0.54   0.11]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 2.600e-01  1.200e-01  4.200e-01  8.600e-01  8.400e-01  9.800e-01\n",
      "   2.600e-01  6.200e-01]\n",
      " [ 5.400e-01 -1.670e+00 -2.217e+01 -1.450e+01 -1.670e+00 -2.221e+01\n",
      "  -1.660e+00  1.000e-02]\n",
      " [-1.670e+00 -1.670e+00 -8.600e-01 -1.445e+01 -1.476e+01 -1.290e+00\n",
      "  -1.660e+00 -1.434e+01]\n",
      " [ 3.000e-02 -2.224e+01 -1.670e+00 -2.700e-01 -1.473e+01 -1.640e+00\n",
      "  -1.460e+01 -1.455e+01]\n",
      " [ 4.400e-01 -9.300e-01 -1.465e+01 -1.670e+00 -1.442e+01 -1.610e+00\n",
      "  -7.500e-01 -1.470e+01]\n",
      " [ 1.700e-01 -1.670e+00 -8.700e-01 -1.670e+00 -9.300e-01 -1.494e+01\n",
      "  -1.320e+00  2.200e-01]\n",
      " [ 9.900e-01 -2.229e+01 -2.223e+01 -2.626e+01 -2.232e+01 -1.457e+01\n",
      "  -1.483e+01  3.800e-01]\n",
      " [ 4.100e-01 -1.491e+01 -1.462e+01 -1.489e+01 -1.497e+01  4.000e-02\n",
      "   3.200e-01  3.100e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.84   0.16   0.83   0.68   0.16   0.17   0.32   0.91]\n",
      " [  0.92  -1.67  -1.67  -1.67  -1.67  -1.66 -14.41   0.55]\n",
      " [ -1.67 -14.42 -14.49   0.11 -22.35   0.13 -14.38   0.27]\n",
      " [  0.64  -1.67 -14.87 -14.83  -0.32  -1.65 -14.81 -14.44]\n",
      " [  0.33  -0.71  -1.67 -26.35  -1.25 -22.28 -14.7  -22.27]\n",
      " [  0.31 -22.5   -0.97 -22.3   -0.79  -1.53 -14.43 -14.47]\n",
      " [  0.91  -1.67  -1.67  -1.67 -22.39  -0.61  -0.81   0.21]\n",
      " [  0.26 -14.62 -14.47 -14.79 -14.42   0.27   0.59   0.95]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > ^ > > < < █ \n",
      "^ v █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > < █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 52 Tot Reward: -690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 360 Tot Reward: -2303\n",
      "Episode: 3 - Tot Steps: 202 Tot Reward: -434\n",
      "Episode: 4 - Tot Steps: 184 Tot Reward: -242\n",
      "Episode: 5 - Tot Steps: 89 Tot Reward: -147\n",
      "Episode: 6 - Tot Steps: 71 Tot Reward: -100\n",
      "Episode: 7 - Tot Steps: 126 Tot Reward: -300\n",
      "Episode: 8 - Tot Steps: 73 Tot Reward: -102\n",
      "Episode: 9 - Tot Steps: 46 Tot Reward: -75\n",
      "Episode: 10 - Tot Steps: 135 Tot Reward: -164\n",
      "Episode: 11 - Tot Steps: 65 Tot Reward: -65\n",
      "Episode: 12 - Tot Steps: 60 Tot Reward: -89\n",
      "Episode: 13 - Tot Steps: 128 Tot Reward: -215\n",
      "Episode: 14 - Tot Steps: 31 Tot Reward: -89\n",
      "Episode: 15 - Tot Steps: 45 Tot Reward: -74\n",
      "Episode: 16 - Tot Steps: 34 Tot Reward: -34\n",
      "Episode: 17 - Tot Steps: 63 Tot Reward: -63\n",
      "Episode: 18 - Tot Steps: 46 Tot Reward: -46\n",
      "Episode: 19 - Tot Steps: 67 Tot Reward: -67\n",
      "Episode: 20 - Tot Steps: 53 Tot Reward: -82\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.55   0.2    0.56   0.43   0.65   0.55   0.33   0.77]\n",
      " [  0.31  -1.67  -1.67  -1.67  -1.67  -1.67  -1.66 -14.82]\n",
      " [ -1.67  -1.67  -0.83  -1.29  -1.67  -0.41  -1.66 -14.71]\n",
      " [  0.69  -1.67 -22.28 -14.56  -0.35 -14.61  -1.66 -14.6 ]\n",
      " [  0.04  -0.81  -1.67 -14.5  -14.85  -1.61  -0.85 -14.84]\n",
      " [  0.76 -22.47  -0.88  -1.67 -14.69  -1.53 -14.83 -14.95]\n",
      " [  0.37  -1.67 -26.31  -1.67 -14.68  -0.81  -1.09   0.42]\n",
      " [  0.52  -1.22  -0.3   -1.28  -0.25 -14.52  -0.16   0.19]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.97   0.59   0.87   0.2    0.98   0.65   0.48   0.13]\n",
      " [  0.83  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -0.41]\n",
      " [ -1.67  -1.67  -0.48 -14.69 -26.38  -0.95 -26.26  -0.9 ]\n",
      " [  0.74  -1.67  -1.67  -0.73 -14.46 -22.41  -1.66  -1.08]\n",
      " [  0.18 -14.7  -28.2   -1.67   0.08 -14.74  -1.03 -14.9 ]\n",
      " [  0.66  -1.67  -1.01 -14.81  -0.38 -14.97  -1.33   0.05]\n",
      " [  0.4   -1.67  -1.67  -1.67  -1.67  -0.93 -22.48   0.69]\n",
      " [  0.21 -14.8  -14.46 -14.43 -14.86   0.07 -14.5  -14.45]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 6.200e-01  6.100e-01  1.000e-01  4.300e-01  2.000e-01  6.000e-02\n",
      "   8.400e-01  1.900e-01]\n",
      " [ 4.100e-01 -1.670e+00 -1.433e+01 -2.634e+01 -1.670e+00 -1.488e+01\n",
      "  -1.660e+00 -1.473e+01]\n",
      " [-1.670e+00 -1.670e+00 -8.800e-01 -1.441e+01 -1.454e+01 -3.600e-01\n",
      "  -1.660e+00 -1.437e+01]\n",
      " [ 3.500e-01 -1.452e+01 -1.670e+00 -9.400e-01 -1.491e+01 -1.640e+00\n",
      "  -2.229e+01 -1.455e+01]\n",
      " [ 6.700e-01 -9.000e-01 -1.439e+01 -1.670e+00 -1.460e+01 -1.600e+00\n",
      "  -9.200e-01 -1.470e+01]\n",
      " [ 1.700e-01 -1.670e+00 -6.900e-01 -1.670e+00 -9.200e-01 -2.230e+01\n",
      "  -1.280e+00 -2.000e-02]\n",
      " [ 5.400e-01 -2.632e+01 -1.476e+01 -2.633e+01 -1.461e+01 -1.459e+01\n",
      "  -1.435e+01  7.600e-01]\n",
      " [ 6.000e-02 -1.446e+01 -1.466e+01 -1.443e+01 -1.431e+01 -1.473e+01\n",
      "  -1.436e+01  3.100e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 6.900e-01  6.300e-01  6.700e-01  4.300e-01  4.800e-01  4.600e-01\n",
      "   4.000e-02  1.000e-02]\n",
      " [ 8.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.475e+01 -1.447e+01]\n",
      " [-1.670e+00 -2.236e+01 -1.440e+01 -1.250e+00 -1.443e+01 -8.500e-01\n",
      "  -2.227e+01 -1.475e+01]\n",
      " [ 2.500e-01 -1.670e+00 -2.622e+01 -1.453e+01 -5.900e-01 -1.650e+00\n",
      "  -2.232e+01 -1.484e+01]\n",
      " [ 1.600e-01 -1.110e+00 -1.670e+00 -1.440e+01 -2.700e-01 -2.625e+01\n",
      "  -1.450e+01 -1.464e+01]\n",
      " [ 6.000e-02 -2.629e+01 -9.500e-01 -2.241e+01 -2.800e-01 -1.510e+00\n",
      "  -1.465e+01 -1.469e+01]\n",
      " [ 5.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.245e+01 -9.600e-01\n",
      "  -7.000e-01  8.000e-02]\n",
      " [ 7.800e-01 -1.447e+01 -1.444e+01 -1.470e+01  6.000e-02 -1.479e+01\n",
      "  -1.457e+01 -1.430e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > ^ █ \n",
      "< v █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < > < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 142 Tot Reward: -1389\n",
      "Episode: 2 - Tot Steps: 316 Tot Reward: -1389\n",
      "Episode: 3 - Tot Steps: 124 Tot Reward: -124\n",
      "Episode: 4 - Tot Steps: 156 Tot Reward: -272\n",
      "Episode: 5 - Tot Steps: 20 Tot Reward: -49\n",
      "Episode: 6 - Tot Steps: 66 Tot Reward: -124\n",
      "Episode: 7 - Tot Steps: 214 Tot Reward: -388\n",
      "Episode: 8 - Tot Steps: 105 Tot Reward: -163\n",
      "Episode: 9 - Tot Steps: 46 Tot Reward: -75\n",
      "Episode: 10 - Tot Steps: 72 Tot Reward: -159\n",
      "Episode: 11 - Tot Steps: 53 Tot Reward: -53\n",
      "Episode: 12 - Tot Steps: 49 Tot Reward: -49\n",
      "Episode: 13 - Tot Steps: 46 Tot Reward: -75\n",
      "Episode: 14 - Tot Steps: 145 Tot Reward: -174\n",
      "Episode: 15 - Tot Steps: 51 Tot Reward: -80\n",
      "Episode: 16 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 17 - Tot Steps: 113 Tot Reward: -316\n",
      "Episode: 18 - Tot Steps: 49 Tot Reward: -49\n",
      "Episode: 19 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 20 - Tot Steps: 46 Tot Reward: -75\n",
      "Episode: 21 - Tot Steps: 50 Tot Reward: -50\n",
      "Episode: 22 - Tot Steps: 56 Tot Reward: -259\n",
      "Episode: 23 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 24 - Tot Steps: 16 Tot Reward: -132\n",
      "Episode: 25 - Tot Steps: 33 Tot Reward: -91\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.19   0.94   0.1    0.34   0.4    0.96   0.8    0.92]\n",
      " [  0.17  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.52]\n",
      " [ -1.67  -1.67  -0.71  -1.32  -1.67  -0.56  -1.66 -14.33]\n",
      " [  0.62  -1.67 -14.61 -14.59  -1.06 -14.73  -1.66 -14.79]\n",
      " [  0.61  -0.94  -1.67 -14.61 -14.4   -1.62  -0.8  -14.56]\n",
      " [  0.17 -14.88  -0.88  -1.67 -14.77  -1.57 -22.55 -17.74]\n",
      " [  0.04  -1.67 -26.24  -1.67 -22.34  -0.94  -1.08   0.47]\n",
      " [  0.45  -0.98  -0.82  -1.29  -0.2  -15.04  -0.64   0.09]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.88   0.88   0.45   0.06   0.88   0.34   0.34   0.46]\n",
      " [  0.85  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.15]\n",
      " [ -1.67  -1.67  -0.25 -14.79 -22.54  -0.88 -22.49  -0.86]\n",
      " [  0.26  -1.67  -1.67   0.09 -14.65 -22.52  -1.66  -0.04]\n",
      " [  0.21 -14.94 -22.43  -1.67  -0.89 -14.65  -0.9  -22.35]\n",
      " [  0.03  -1.67  -0.58 -22.49  -0.83 -14.91  -1.43  -0.09]\n",
      " [  0.9   -1.67  -1.67  -1.67  -1.67  -0.33 -22.43   0.36]\n",
      " [  0.48 -14.31 -14.62 -14.47 -14.49 -14.89 -14.63   0.25]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.71   0.07   0.8    0.53   0.61   0.95   0.42   0.34]\n",
      " [  0.83  -1.67 -22.28 -26.27  -1.67 -22.34  -1.67 -14.36]\n",
      " [ -1.67  -1.67  -0.93 -14.6  -22.26  -0.78  -1.66 -14.4 ]\n",
      " [  0.98 -22.25  -1.67  -0.39 -14.45  -1.64 -22.28 -14.44]\n",
      " [  0.44  -0.35 -22.26  -1.67 -14.36  -1.61  -0.97 -14.69]\n",
      " [  0.55  -1.67  -1.03  -1.67  -0.05 -14.63  -1.3   -0.3 ]\n",
      " [  0.11 -22.21 -22.16 -26.37 -14.73 -25.32 -22.14   0.42]\n",
      " [  0.86 -14.54 -14.78 -14.5    0.28 -14.61   0.08   0.24]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.96   0.1    0.61   0.65   0.24   0.38   0.47   0.22]\n",
      " [  0.28  -1.67  -1.67  -1.67  -1.67  -1.67 -26.27 -14.59]\n",
      " [ -1.67 -22.41 -14.71  -1.   -14.62  -0.13 -22.27 -14.74]\n",
      " [  0.53  -1.67 -14.51 -14.73  -0.75  -1.64 -14.79 -14.78]\n",
      " [  0.97  -0.54  -1.67 -26.2   -0.99 -22.41 -22.1  -25.15]\n",
      " [  0.99 -14.9   -0.99 -14.74  -0.13  -1.52 -22.2  -14.82]\n",
      " [  0.08  -1.67  -1.67  -1.67 -26.25  -0.59  -0.75   0.61]\n",
      " [  0.07 -14.57 -14.87 -14.64 -14.85 -22.22 -14.69   0.07]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ ^ ^ > ^ > v █ \n",
      "< v █ █ ^ █ v █ \n",
      "█ < < █ █ v < █ \n",
      "█ █ ^ < █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 232 Tot Reward: -2117\n",
      "Episode: 2 - Tot Steps: 234 Tot Reward: -843\n",
      "Episode: 3 - Tot Steps: 173 Tot Reward: -260\n",
      "Episode: 4 - Tot Steps: 92 Tot Reward: -92\n",
      "Episode: 5 - Tot Steps: 74 Tot Reward: -74\n",
      "Episode: 6 - Tot Steps: 149 Tot Reward: -149\n",
      "Episode: 7 - Tot Steps: 95 Tot Reward: -124\n",
      "Episode: 8 - Tot Steps: 125 Tot Reward: -212\n",
      "Episode: 9 - Tot Steps: 75 Tot Reward: -75\n",
      "Episode: 10 - Tot Steps: 76 Tot Reward: -76\n",
      "Episode: 11 - Tot Steps: 31 Tot Reward: -89\n",
      "Episode: 12 - Tot Steps: 37 Tot Reward: -66\n",
      "Episode: 13 - Tot Steps: 46 Tot Reward: -46\n",
      "Episode: 14 - Tot Steps: 35 Tot Reward: -64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 15 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 16 - Tot Steps: 44 Tot Reward: -44\n",
      "Episode: 17 - Tot Steps: 129 Tot Reward: -216\n",
      "Episode: 18 - Tot Steps: 56 Tot Reward: -56\n",
      "Episode: 19 - Tot Steps: 84 Tot Reward: -113\n",
      "Episode: 20 - Tot Steps: 34 Tot Reward: -63\n",
      "Episode: 21 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 22 - Tot Steps: 32 Tot Reward: -32\n",
      "Episode: 23 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 24 - Tot Steps: 144 Tot Reward: -260\n",
      "Episode: 25 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 26 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 27 - Tot Steps: 22 Tot Reward: -51\n",
      "Episode: 28 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 29 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 30 - Tot Steps: 14 Tot Reward: -43\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 8.900e-01  9.800e-01  6.300e-01  8.900e-01  8.000e-02  9.500e-01\n",
      "   5.800e-01  2.200e-01]\n",
      " [ 8.100e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00  2.000e-01]\n",
      " [-1.670e+00 -1.670e+00 -1.250e+00 -4.800e-01 -1.670e+00 -8.900e-01\n",
      "  -1.660e+00 -1.454e+01]\n",
      " [ 8.100e-01 -1.670e+00 -2.622e+01 -1.468e+01 -5.100e-01 -1.465e+01\n",
      "  -1.660e+00 -1.462e+01]\n",
      " [ 1.500e-01 -8.900e-01 -1.670e+00 -1.449e+01 -1.470e+01 -1.610e+00\n",
      "  -7.600e-01 -1.497e+01]\n",
      " [ 4.300e-01 -1.473e+01 -9.000e-01 -1.670e+00 -1.454e+01 -1.580e+00\n",
      "  -1.466e+01 -1.480e+01]\n",
      " [ 3.700e-01 -1.670e+00 -1.446e+01 -1.670e+00 -2.226e+01 -3.900e-01\n",
      "  -8.000e-01  6.200e-01]\n",
      " [ 1.000e-01 -2.000e-02 -9.200e-01 -2.000e-01 -2.200e-01 -1.492e+01\n",
      "   4.900e-01 -7.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.82   0.28   0.73   0.09   0.53   0.74   0.86   0.86]\n",
      " [  0.43  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -0.29]\n",
      " [ -1.67  -1.67  -1.31 -14.59 -14.65  -0.7  -22.38  -0.18]\n",
      " [  0.35  -1.67  -1.67   0.05 -14.8  -14.95  -1.66  -1.  ]\n",
      " [  0.71 -14.73 -22.41  -1.67  -0.82 -22.23  -0.06 -14.38]\n",
      " [  0.75  -1.67  -0.74 -22.38  -0.37 -14.38  -1.41  -0.17]\n",
      " [  0.66  -1.67  -1.67  -1.67  -1.67  -0.53 -14.98   0.2 ]\n",
      " [  0.06   0.71 -14.75 -14.5  -14.49 -14.59 -14.46   0.2 ]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 6.000e-01  1.700e-01  7.300e-01  5.900e-01  5.700e-01  7.100e-01\n",
      "   8.000e-01  2.500e-01]\n",
      " [ 1.000e+00 -1.670e+00 -2.941e+01 -2.250e+01 -1.670e+00 -2.611e+01\n",
      "  -1.670e+00 -1.462e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.460e+00 -1.477e+01 -2.218e+01 -6.500e-01\n",
      "  -1.660e+00 -1.493e+01]\n",
      " [ 6.800e-01 -1.438e+01 -1.670e+00 -7.800e-01 -1.476e+01 -1.640e+00\n",
      "  -2.613e+01 -1.477e+01]\n",
      " [ 2.900e-01 -3.900e-01 -2.243e+01 -1.670e+00 -1.449e+01 -1.610e+00\n",
      "  -7.900e-01 -1.455e+01]\n",
      " [ 8.900e-01 -1.670e+00 -2.300e-01 -1.670e+00 -8.600e-01 -1.478e+01\n",
      "  -1.300e+00  2.900e-01]\n",
      " [ 8.400e-01 -1.468e+01 -2.247e+01 -1.461e+01 -1.475e+01 -1.457e+01\n",
      "  -1.486e+01  5.100e-01]\n",
      " [ 6.700e-01  2.000e-02 -1.477e+01  1.000e-01 -1.491e+01 -1.460e+01\n",
      "   3.700e-01 -1.444e+01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 2.300e-01  1.900e-01  6.800e-01  8.500e-01  7.000e-01  3.600e-01\n",
      "   5.100e-01  2.000e-02]\n",
      " [ 8.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.468e+01 -1.443e+01]\n",
      " [-1.670e+00 -2.260e+01 -1.465e+01 -9.700e-01 -2.223e+01 -9.700e-01\n",
      "  -1.478e+01 -1.472e+01]\n",
      " [ 5.600e-01 -1.670e+00 -2.221e+01 -1.477e+01 -3.500e-01 -1.650e+00\n",
      "  -2.231e+01 -1.448e+01]\n",
      " [ 5.500e-01 -3.400e-01 -1.670e+00 -2.228e+01 -8.300e-01 -1.472e+01\n",
      "  -1.468e+01 -1.473e+01]\n",
      " [ 1.700e-01 -1.439e+01 -1.400e-01 -2.242e+01 -7.700e-01 -1.520e+00\n",
      "  -1.463e+01  1.400e-01]\n",
      " [ 6.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.239e+01 -6.500e-01\n",
      "  -7.500e-01  1.800e-01]\n",
      " [ 7.400e-01 -1.452e+01 -1.475e+01 -1.441e+01 -1.475e+01 -1.447e+01\n",
      "  -1.448e+01 -1.453e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ ^ < █ █ v < █ \n",
      "█ █ ^ v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 173 Tot Reward: -1594\n",
      "Episode: 2 - Tot Steps: 349 Tot Reward: -1219\n",
      "Episode: 3 - Tot Steps: 70 Tot Reward: -128\n",
      "Episode: 4 - Tot Steps: 109 Tot Reward: -138\n",
      "Episode: 5 - Tot Steps: 135 Tot Reward: -164\n",
      "Episode: 6 - Tot Steps: 77 Tot Reward: -77\n",
      "Episode: 7 - Tot Steps: 139 Tot Reward: -313\n",
      "Episode: 8 - Tot Steps: 64 Tot Reward: -151\n",
      "Episode: 9 - Tot Steps: 66 Tot Reward: -66\n",
      "Episode: 10 - Tot Steps: 162 Tot Reward: -307\n",
      "Episode: 11 - Tot Steps: 48 Tot Reward: -77\n",
      "Episode: 12 - Tot Steps: 68 Tot Reward: -68\n",
      "Episode: 13 - Tot Steps: 67 Tot Reward: -67\n",
      "Episode: 14 - Tot Steps: 92 Tot Reward: -150\n",
      "Episode: 15 - Tot Steps: 63 Tot Reward: -150\n",
      "Episode: 16 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 17 - Tot Steps: 50 Tot Reward: -50\n",
      "Episode: 18 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 19 - Tot Steps: 94 Tot Reward: -123\n",
      "Episode: 20 - Tot Steps: 32 Tot Reward: -32\n",
      "Episode: 21 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 22 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 23 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 24 - Tot Steps: 29 Tot Reward: -29\n",
      "Episode: 25 - Tot Steps: 38 Tot Reward: -38\n",
      "Episode: 26 - Tot Steps: 27 Tot Reward: -56\n",
      "Episode: 27 - Tot Steps: 21 Tot Reward: -79\n",
      "Episode: 28 - Tot Steps: 68 Tot Reward: -184\n",
      "Episode: 29 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 30 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 31 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 32 - Tot Steps: 19 Tot Reward: -48\n",
      "Episode: 33 - Tot Steps: 18 Tot Reward: -47\n",
      "Episode: 34 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 35 - Tot Steps: 16 Tot Reward: -16\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.48   0.77   0.29   0.95   0.81   0.75   0.86   0.65]\n",
      " [  0.87  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.86]\n",
      " [ -1.67  -1.67   0.09  -1.28  -1.67  -0.93  -1.66 -14.66]\n",
      " [  0.31  -1.67 -14.36 -22.37  -0.07 -22.26  -1.66 -22.23]\n",
      " [  0.6   -0.91  -1.67 -28.43 -14.68  -1.62   0.   -14.45]\n",
      " [  0.12 -14.81  -0.55  -1.67 -14.66  -1.53 -14.61 -14.6 ]\n",
      " [  0.45  -1.67 -22.47  -1.67 -14.45  -0.03  -1.04   0.94]\n",
      " [  0.17  -0.84  -1.33  -1.39   0.24 -14.87  -0.52   0.13]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.33   0.6    0.04   0.46   0.29   0.77   0.33   0.26]\n",
      " [  0.61  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -0.86]\n",
      " [ -1.67  -1.67  -0.29 -14.32 -14.91  -0.22 -14.87  -0.49]\n",
      " [  0.66  -1.67  -1.67  -1.3  -14.89 -14.85  -1.66  -0.17]\n",
      " [  0.82 -14.82 -22.48  -1.67  -0.93 -22.34  -0.31   0.09]\n",
      " [  0.84  -1.67  -0.94 -14.34   0.07 -22.39  -1.27  -0.28]\n",
      " [  0.21  -1.67  -1.67  -1.67  -1.67  -0.15 -14.59   0.9 ]\n",
      " [  0.63 -14.54 -14.87 -14.6  -22.34 -14.6  -14.45   0.83]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 7.000e-01  1.100e-01  8.000e-01  4.400e-01  6.000e-01  8.600e-01\n",
      "   4.200e-01  7.800e-01]\n",
      " [ 9.300e-01 -1.670e+00 -1.488e+01 -2.631e+01 -1.670e+00 -2.238e+01\n",
      "  -1.660e+00 -1.438e+01]\n",
      " [-1.670e+00 -1.670e+00  1.700e-01 -1.445e+01 -1.463e+01 -9.300e-01\n",
      "  -1.660e+00 -1.439e+01]\n",
      " [ 5.900e-01 -2.619e+01 -1.670e+00 -1.340e+00 -1.453e+01 -1.640e+00\n",
      "  -1.452e+01  6.300e-01]\n",
      " [ 2.000e-01 -7.700e-01 -2.220e+01 -1.670e+00 -1.451e+01 -1.600e+00\n",
      "  -1.000e-02 -1.473e+01]\n",
      " [ 2.200e-01 -1.670e+00 -8.300e-01 -1.670e+00 -3.400e-01 -2.230e+01\n",
      "  -1.250e+00  2.100e-01]\n",
      " [ 2.200e-01 -2.222e+01 -2.633e+01 -2.647e+01 -1.463e+01 -1.494e+01\n",
      "  -2.228e+01  8.500e-01]\n",
      " [ 5.200e-01 -1.434e+01 -1.449e+01 -1.470e+01 -1.468e+01 -1.437e+01\n",
      "  -1.476e+01  2.500e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.61   0.96   0.13   0.76   0.88   0.09   0.82   0.7 ]\n",
      " [  0.05  -1.67  -1.67  -1.67  -1.67  -1.67 -22.19 -14.37]\n",
      " [ -1.67 -14.55 -14.57  -1.02 -14.8   -0.4  -14.52 -14.51]\n",
      " [  0.24  -1.67 -28.16 -14.6   -0.22  -1.64 -14.58   0.19]\n",
      " [  0.99  -0.98  -1.67 -14.55  -0.31 -14.47 -14.37 -14.52]\n",
      " [  0.39 -22.35  -0.8  -14.85  -0.74  -1.5  -14.7  -14.7 ]\n",
      " [  0.77  -1.67  -1.67  -1.67 -14.62  -0.63  -0.62   0.83]\n",
      " [  0.05 -14.9  -14.86 -14.73 -14.58 -14.43 -14.53   0.27]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ ^ > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 285 Tot Reward: -1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 30 Tot Reward: -407\n",
      "Episode: 3 - Tot Steps: 237 Tot Reward: -498\n",
      "Episode: 4 - Tot Steps: 108 Tot Reward: -108\n",
      "Episode: 5 - Tot Steps: 21 Tot Reward: -50\n",
      "Episode: 6 - Tot Steps: 138 Tot Reward: -312\n",
      "Episode: 7 - Tot Steps: 52 Tot Reward: -110\n",
      "Episode: 8 - Tot Steps: 67 Tot Reward: -212\n",
      "Episode: 9 - Tot Steps: 153 Tot Reward: -269\n",
      "Episode: 10 - Tot Steps: 85 Tot Reward: -85\n",
      "Episode: 11 - Tot Steps: 81 Tot Reward: -139\n",
      "Episode: 12 - Tot Steps: 85 Tot Reward: -143\n",
      "Episode: 13 - Tot Steps: 71 Tot Reward: -100\n",
      "Episode: 14 - Tot Steps: 86 Tot Reward: -86\n",
      "Episode: 15 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 16 - Tot Steps: 116 Tot Reward: -174\n",
      "Episode: 17 - Tot Steps: 33 Tot Reward: -33\n",
      "Episode: 18 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 19 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 20 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 21 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 22 - Tot Steps: 36 Tot Reward: -36\n",
      "Episode: 23 - Tot Steps: 60 Tot Reward: -60\n",
      "Episode: 24 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 25 - Tot Steps: 77 Tot Reward: -106\n",
      "Episode: 26 - Tot Steps: 68 Tot Reward: -155\n",
      "Episode: 27 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 28 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 29 - Tot Steps: 21 Tot Reward: -79\n",
      "Episode: 30 - Tot Steps: 70 Tot Reward: -186\n",
      "Episode: 31 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 32 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 33 - Tot Steps: 15 Tot Reward: -44\n",
      "Episode: 34 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 35 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 36 - Tot Steps: 20 Tot Reward: -49\n",
      "Episode: 37 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 38 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 39 - Tot Steps: 40 Tot Reward: -40\n",
      "Episode: 40 - Tot Steps: 16 Tot Reward: -16\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 6.200e-01  1.000e-01  1.700e-01  2.000e-02  4.200e-01  9.400e-01\n",
      "   9.200e-01  1.000e-02]\n",
      " [ 7.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.461e+01]\n",
      " [-1.670e+00 -1.670e+00 -8.600e-01 -9.600e-01 -1.670e+00 -6.200e-01\n",
      "  -1.660e+00 -1.471e+01]\n",
      " [ 5.600e-01 -1.670e+00 -1.478e+01 -1.470e+01 -3.900e-01 -1.457e+01\n",
      "  -1.660e+00 -1.465e+01]\n",
      " [ 5.900e-01 -6.600e-01 -1.670e+00 -1.449e+01 -1.437e+01 -1.640e+00\n",
      "  -1.050e+00 -1.496e+01]\n",
      " [ 5.300e-01 -2.237e+01 -9.600e-01 -1.670e+00 -1.474e+01 -1.570e+00\n",
      "  -2.641e+01 -1.495e+01]\n",
      " [ 9.900e-01 -1.670e+00 -1.468e+01 -1.670e+00 -1.455e+01 -9.100e-01\n",
      "  -1.020e+00  5.000e-02]\n",
      " [ 3.700e-01 -4.000e-01 -3.000e-02 -1.270e+00 -7.900e-01 -1.453e+01\n",
      "  -2.900e-01  9.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 3.000e-02  1.900e-01  8.400e-01  9.200e-01  4.700e-01  6.700e-01\n",
      "   8.400e-01  3.700e-01]\n",
      " [ 1.900e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -9.900e-01]\n",
      " [-1.670e+00 -1.670e+00 -8.600e-01 -1.487e+01 -1.435e+01 -4.500e-01\n",
      "  -2.248e+01 -5.400e-01]\n",
      " [ 7.000e-01 -1.670e+00 -1.670e+00 -8.300e-01 -1.453e+01 -1.466e+01\n",
      "  -1.660e+00 -8.600e-01]\n",
      " [ 5.000e-02 -1.497e+01 -1.460e+01 -1.670e+00 -9.200e-01 -1.451e+01\n",
      "  -1.290e+00 -1.490e+01]\n",
      " [ 2.000e-02 -1.670e+00 -9.700e-01 -2.226e+01 -8.700e-01 -1.473e+01\n",
      "  -1.420e+00 -2.400e-01]\n",
      " [ 1.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.120e+00\n",
      "  -2.629e+01  2.000e-02]\n",
      " [ 5.000e-02 -1.474e+01 -1.448e+01 -1.475e+01 -1.457e+01  2.000e-01\n",
      "   2.600e-01  6.600e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.42   0.97   0.65   0.21   0.84   0.7    0.54   0.17]\n",
      " [  0.36  -1.67 -14.51 -29.19  -1.67 -26.15  -1.67 -14.97]\n",
      " [ -1.67  -1.67  -0.81 -22.31 -26.12  -0.89  -1.66 -14.5 ]\n",
      " [  0.48 -14.55  -1.67  -0.14 -15.    -1.64 -22.43 -15.  ]\n",
      " [  0.99  -0.68 -28.21  -1.67 -14.62  -1.61  -1.   -14.99]\n",
      " [  0.8   -1.67  -0.75  -1.67  -0.93 -14.51  -1.3   -0.37]\n",
      " [  0.66 -14.9  -14.81 -26.3  -22.22 -14.73 -14.82   0.11]\n",
      " [  0.37 -14.3  -14.63 -14.42 -14.38   0.67   0.33   0.17]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.08   0.71   0.92   0.95   0.43   0.74   0.18   0.39]\n",
      " [  0.78  -1.67  -1.67  -1.67  -1.67  -1.67 -26.18 -14.79]\n",
      " [ -1.67 -26.15 -14.78  -1.18 -14.63  -0.92 -14.36 -14.78]\n",
      " [  0.66  -1.67 -14.39 -14.84  -0.41  -1.65 -22.22 -14.48]\n",
      " [  0.91  -0.3   -1.67 -22.03  -0.43 -26.35 -14.8  -14.9 ]\n",
      " [  0.92 -14.54  -0.99 -28.12  -0.84  -1.52 -22.21 -14.8 ]\n",
      " [  0.86  -1.67  -1.67  -1.67 -22.48  -0.62  -0.75   0.62]\n",
      " [  0.08 -14.5  -14.81 -14.89 -14.71 -14.43 -14.51   0.74]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ ^ v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 94 Tot Reward: -1254\n",
      "Episode: 2 - Tot Steps: 227 Tot Reward: -1300\n",
      "Episode: 3 - Tot Steps: 183 Tot Reward: -299\n",
      "Episode: 4 - Tot Steps: 272 Tot Reward: -504\n",
      "Episode: 5 - Tot Steps: 72 Tot Reward: -72\n",
      "Episode: 6 - Tot Steps: 120 Tot Reward: -149\n",
      "Episode: 7 - Tot Steps: 79 Tot Reward: -108\n",
      "Episode: 8 - Tot Steps: 62 Tot Reward: -91\n",
      "Episode: 9 - Tot Steps: 110 Tot Reward: -110\n",
      "Episode: 10 - Tot Steps: 61 Tot Reward: -61\n",
      "Episode: 11 - Tot Steps: 116 Tot Reward: -290\n",
      "Episode: 12 - Tot Steps: 47 Tot Reward: -76\n",
      "Episode: 13 - Tot Steps: 38 Tot Reward: -96\n",
      "Episode: 14 - Tot Steps: 53 Tot Reward: -111\n",
      "Episode: 15 - Tot Steps: 41 Tot Reward: -41\n",
      "Episode: 16 - Tot Steps: 128 Tot Reward: -302\n",
      "Episode: 17 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 18 - Tot Steps: 75 Tot Reward: -133\n",
      "Episode: 19 - Tot Steps: 28 Tot Reward: -144\n",
      "Episode: 20 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 21 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 22 - Tot Steps: 37 Tot Reward: -37\n",
      "Episode: 23 - Tot Steps: 35 Tot Reward: -64\n",
      "Episode: 24 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 25 - Tot Steps: 90 Tot Reward: -177\n",
      "Episode: 26 - Tot Steps: 49 Tot Reward: -78\n",
      "Episode: 27 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 28 - Tot Steps: 48 Tot Reward: -48\n",
      "Episode: 29 - Tot Steps: 26 Tot Reward: -55\n",
      "Episode: 30 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 31 - Tot Steps: 42 Tot Reward: -71\n",
      "Episode: 32 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 33 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 34 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 35 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 36 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 37 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 38 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 39 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 40 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 41 - Tot Steps: 19 Tot Reward: -48\n",
      "Episode: 42 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 43 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 44 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 45 - Tot Steps: 15 Tot Reward: -15\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.27   0.54   0.81   0.38   0.68   0.37   0.89   0.54]\n",
      " [  0.77  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.76]\n",
      " [ -1.67  -1.67   0.12  -1.53  -1.67  -0.5   -1.66 -14.69]\n",
      " [  0.54  -1.67 -14.68 -22.61  -0.27 -26.27  -1.66 -14.76]\n",
      " [  0.49  -0.18  -1.67 -26.3  -14.86  -1.64   0.28 -22.16]\n",
      " [  0.72 -14.92  -0.81  -1.67 -14.55  -1.61 -14.65 -14.51]\n",
      " [  0.44  -1.67 -22.21  -1.67 -14.79  -0.92  -1.13   0.54]\n",
      " [  0.3   -0.88  -1.03  -1.45  -0.75 -14.89  -0.05   0.53]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.16   0.99   0.15   0.8    0.84   0.6    0.75   0.43]\n",
      " [  0.49  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.32]\n",
      " [ -1.67  -1.67  -0.47 -14.4  -22.52  -0.99 -22.41  -1.41]\n",
      " [  0.14  -1.67  -1.67  -1.27 -14.37 -22.32  -1.66  -0.31]\n",
      " [  0.76 -14.6  -22.26  -1.67  -1.04 -26.23  -0.12   0.1 ]\n",
      " [  0.9   -1.67  -0.9  -14.45  -0.22 -22.15  -1.3   -0.59]\n",
      " [  0.07  -1.67  -1.67  -1.67  -1.67  -0.57 -14.87   0.4 ]\n",
      " [  0.89 -14.86 -14.35 -14.65 -14.77 -14.71   0.04   0.58]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.81   0.61   0.29   0.49   0.27   0.54   0.81   0.69]\n",
      " [  0.29  -1.67 -14.77 -29.93  -1.67 -14.74  -1.67 -22.17]\n",
      " [ -1.67  -1.67  -0.45 -14.93 -14.53  -0.77  -1.66 -14.82]\n",
      " [  0.39 -14.81  -1.67  -1.06 -14.46  -1.64 -14.66 -14.62]\n",
      " [  0.98  -0.5  -26.17  -1.67 -14.59  -1.61  -0.14 -14.62]\n",
      " [  0.97  -1.67  -0.18  -1.67  -0.37 -22.47  -1.3   -0.32]\n",
      " [  0.5  -22.22 -22.38 -28.43 -26.29 -14.91 -14.62   0.65]\n",
      " [  0.38 -14.65 -14.35 -14.34 -14.39 -14.37   0.35   0.23]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.41   0.12   0.07   0.4    0.87   0.98   0.46   0.33]\n",
      " [  0.65  -1.67  -1.67  -1.67  -1.67  -1.67 -28.34 -14.47]\n",
      " [ -1.67 -22.19 -14.55  -1.49 -14.63  -0.96 -26.4  -14.55]\n",
      " [  0.53  -1.67 -26.36 -14.42  -0.9   -1.65 -14.44 -14.4 ]\n",
      " [  0.12  -0.89  -1.67 -22.59  -1.14 -14.4  -14.4    0.52]\n",
      " [  0.31 -14.89  -0.98 -14.61  -0.74  -1.52 -26.07 -14.7 ]\n",
      " [  0.79  -1.67  -1.67  -1.67 -22.17  -0.61  -0.74   0.1 ]\n",
      " [  0.27 -14.35 -14.39 -14.43 -14.82   0.05   0.2    0.36]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 389 Tot Reward: -2651\n",
      "Episode: 2 - Tot Steps: 143 Tot Reward: -346\n",
      "Episode: 3 - Tot Steps: 169 Tot Reward: -459\n",
      "Episode: 4 - Tot Steps: 51 Tot Reward: -80\n",
      "Episode: 5 - Tot Steps: 70 Tot Reward: -70\n",
      "Episode: 6 - Tot Steps: 125 Tot Reward: -183\n",
      "Episode: 7 - Tot Steps: 118 Tot Reward: -176\n",
      "Episode: 8 - Tot Steps: 80 Tot Reward: -80\n",
      "Episode: 9 - Tot Steps: 95 Tot Reward: -124\n",
      "Episode: 10 - Tot Steps: 80 Tot Reward: -109\n",
      "Episode: 11 - Tot Steps: 61 Tot Reward: -90\n",
      "Episode: 12 - Tot Steps: 68 Tot Reward: -68\n",
      "Episode: 13 - Tot Steps: 109 Tot Reward: -167\n",
      "Episode: 14 - Tot Steps: 68 Tot Reward: -68\n",
      "Episode: 15 - Tot Steps: 59 Tot Reward: -59\n",
      "Episode: 16 - Tot Steps: 54 Tot Reward: -112\n",
      "Episode: 17 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 18 - Tot Steps: 60 Tot Reward: -60\n",
      "Episode: 19 - Tot Steps: 37 Tot Reward: -66\n",
      "Episode: 20 - Tot Steps: 74 Tot Reward: -132\n",
      "Episode: 21 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 22 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 23 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 24 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 25 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 26 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 27 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 28 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 29 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 30 - Tot Steps: 67 Tot Reward: -96\n",
      "Episode: 31 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 32 - Tot Steps: 29 Tot Reward: -87\n",
      "Episode: 33 - Tot Steps: 50 Tot Reward: -50\n",
      "Episode: 34 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 35 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 36 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 37 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 38 - Tot Steps: 79 Tot Reward: -224\n",
      "Episode: 39 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 40 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 41 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 42 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 43 - Tot Steps: 17 Tot Reward: -46\n",
      "Episode: 44 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 45 - Tot Steps: 20 Tot Reward: -78\n",
      "Episode: 46 - Tot Steps: 17 Tot Reward: -46\n",
      "Episode: 47 - Tot Steps: 17 Tot Reward: -46\n",
      "Episode: 48 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 49 - Tot Steps: 27 Tot Reward: -56\n",
      "Episode: 50 - Tot Steps: 17 Tot Reward: -17\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.35   0.66   0.12   0.69   0.84   0.34   0.19   0.28]\n",
      " [  0.38  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.74]\n",
      " [ -1.67  -1.67  -1.04  -1.43  -1.67  -1.38  -1.66 -14.47]\n",
      " [  0.37  -1.67 -28.14 -14.5   -0.99 -29.21  -1.66   0.59]\n",
      " [  0.84  -0.62  -1.67 -14.55 -14.82  -1.62  -1.22 -14.6 ]\n",
      " [  0.78 -26.19  -0.61  -1.67 -14.49  -1.51 -14.93 -14.47]\n",
      " [  0.41  -1.67 -22.42  -1.67 -22.3   -0.3   -1.43   0.92]\n",
      " [  0.92  -0.97  -0.27  -0.05  -0.71 -14.66  -0.24   0.76]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 4.600e-01  9.900e-01  5.200e-01  2.800e-01  1.000e-02  9.800e-01\n",
      "   1.000e-02  6.200e-01]\n",
      " [ 8.600e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -8.500e-01]\n",
      " [-1.670e+00 -1.670e+00 -1.150e+00 -1.452e+01 -1.490e+01 -1.350e+00\n",
      "  -2.845e+01 -1.500e-01]\n",
      " [ 6.100e-01 -1.670e+00 -1.670e+00 -6.800e-01 -1.460e+01 -2.813e+01\n",
      "  -1.660e+00 -9.000e-02]\n",
      " [ 3.600e-01 -1.496e+01 -2.229e+01 -1.670e+00 -1.400e-01 -1.452e+01\n",
      "  -1.020e+00 -1.470e+01]\n",
      " [ 3.500e-01 -1.670e+00 -9.800e-01 -2.607e+01 -3.300e-01 -1.459e+01\n",
      "  -1.280e+00 -3.200e-01]\n",
      " [ 6.900e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -2.800e-01\n",
      "  -2.228e+01  2.700e-01]\n",
      " [ 7.900e-01 -1.454e+01 -1.438e+01 -1.458e+01 -1.455e+01 -1.492e+01\n",
      "  -1.473e+01 -1.455e+01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.34   0.73   0.32   0.2    0.22   0.2    0.1    0.48]\n",
      " [  0.31  -1.67 -14.72 -29.9   -1.67 -26.47  -1.66 -14.79]\n",
      " [ -1.67  -1.67  -1.34 -14.84 -14.76  -1.19  -1.66   0.21]\n",
      " [  0.27 -14.37  -1.67  -0.39 -14.53  -1.64 -22.53 -14.5 ]\n",
      " [  0.69  -0.9  -14.34  -1.67 -14.65  -1.6   -0.83 -14.8 ]\n",
      " [  0.39  -1.67  -0.85  -1.67  -0.87 -22.39  -1.25  -0.05]\n",
      " [  0.78 -22.49 -14.64 -14.59 -14.34 -14.95 -14.5    0.62]\n",
      " [  0.37 -14.75   0.18   0.2  -14.49 -22.25 -14.31   0.14]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.9    0.47   0.39   0.72   0.68   0.46   0.14   0.83]\n",
      " [  0.63  -1.67  -1.67  -1.67  -1.67  -1.67 -22.23 -14.93]\n",
      " [ -1.67 -28.34 -14.46  -1.29 -22.32  -1.4  -14.78 -14.36]\n",
      " [  0.09  -1.67 -14.7    0.17  -0.81  -1.65 -14.49   0.37]\n",
      " [  0.92  -0.83  -1.67 -14.5   -0.08 -28.18 -14.93 -14.43]\n",
      " [  0.81 -22.46  -0.81 -22.42  -0.77  -1.5  -22.18 -14.52]\n",
      " [  0.88  -1.67  -1.67  -1.67 -14.44  -0.66  -0.63   0.54]\n",
      " [  0.62 -14.78 -14.46 -14.41 -14.37 -14.45 -14.39   0.08]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > < █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "## episode의 횟수를 지정 5~60까지 5단위로\n",
    "episode_list = [5,10,15,20,25,30,35,40,45,50]\n",
    "episode_list_reward = []\n",
    "\n",
    "## episode_list를 하나씩 돌면서 값측정\n",
    "for i in episode_list:\n",
    "    ## reward 값을 반환받고, reward값은 음수이므로, 100을 더해서 값이 작을수록 좋은 것임을 나타냄\n",
    "    if __name__ == '__main__':\n",
    "        reward = main(i, alpha=0.5, gamma=0.4,\n",
    "             epsilon = 0.05,result_screening = False)\n",
    "        reward = reward\n",
    "    ## reward에 하나씩 추가\n",
    "    episode_list_reward.append(reward)\n",
    "    \n",
    "plt.plot(episode_list, episode_list_reward, marker='o', linestyle='-')\n",
    "plt.title('Episode - Reward')\n",
    "plt.xlabel('Number of episodes')\n",
    "plt.ylabel('Reward per episode')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fed3c5",
   "metadata": {},
   "source": [
    "#### b) 모든 파라미터가 동일하고, alpha에 따른 Reward값 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fcf5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 169 Tot Reward: -1126\n",
      "Episode: 2 - Tot Steps: 188 Tot Reward: -623\n",
      "Episode: 3 - Tot Steps: 334 Tot Reward: -769\n",
      "Episode: 4 - Tot Steps: 374 Tot Reward: -606\n",
      "Episode: 5 - Tot Steps: 205 Tot Reward: -263\n",
      "Episode: 6 - Tot Steps: 43 Tot Reward: -72\n",
      "Episode: 7 - Tot Steps: 208 Tot Reward: -237\n",
      "Episode: 8 - Tot Steps: 322 Tot Reward: -554\n",
      "Episode: 9 - Tot Steps: 127 Tot Reward: -301\n",
      "Episode: 10 - Tot Steps: 290 Tot Reward: -522\n",
      "Episode: 11 - Tot Steps: 216 Tot Reward: -274\n",
      "Episode: 12 - Tot Steps: 239 Tot Reward: -471\n",
      "Episode: 13 - Tot Steps: 181 Tot Reward: -268\n",
      "Episode: 14 - Tot Steps: 41 Tot Reward: -70\n",
      "Episode: 15 - Tot Steps: 109 Tot Reward: -138\n",
      "Episode: 16 - Tot Steps: 193 Tot Reward: -396\n",
      "Episode: 17 - Tot Steps: 205 Tot Reward: -292\n",
      "Episode: 18 - Tot Steps: 143 Tot Reward: -230\n",
      "Episode: 19 - Tot Steps: 80 Tot Reward: -109\n",
      "Episode: 20 - Tot Steps: 75 Tot Reward: -75\n",
      "Episode: 21 - Tot Steps: 96 Tot Reward: -154\n",
      "Episode: 22 - Tot Steps: 149 Tot Reward: -149\n",
      "Episode: 23 - Tot Steps: 181 Tot Reward: -326\n",
      "Episode: 24 - Tot Steps: 44 Tot Reward: -73\n",
      "Episode: 25 - Tot Steps: 72 Tot Reward: -72\n",
      "Episode: 26 - Tot Steps: 123 Tot Reward: -152\n",
      "Episode: 27 - Tot Steps: 76 Tot Reward: -163\n",
      "Episode: 28 - Tot Steps: 161 Tot Reward: -277\n",
      "Episode: 29 - Tot Steps: 68 Tot Reward: -213\n",
      "Episode: 30 - Tot Steps: 93 Tot Reward: -180\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.13   0.44   0.11   0.86   0.47   0.14   0.4    0.53]\n",
      " [  0.02  -1.66  -1.65  -1.65  -1.64  -1.64  -1.63  -2.78]\n",
      " [ -1.51  -1.66  -0.41  -0.    -1.65   0.19  -1.61  -2.75]\n",
      " [  0.25  -1.66 -12.01  -2.31   0.22  -5.61  -1.59  -2.63]\n",
      " [  0.75  -0.38  -1.66  -5.31  -2.63  -1.49  -0.08   0.49]\n",
      " [  0.9  -13.69   0.11  -1.65  -2.73  -1.38  -2.51   0.09]\n",
      " [  0.15  -1.66  -2.22  -1.65  -5.22   0.16  -0.56   0.44]\n",
      " [  0.64  -0.62   0.31  -0.06   0.23   0.06   0.53   0.57]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 0.8   0.6   0.69  0.06  0.97  0.47  0.14  0.7 ]\n",
      " [ 0.21 -1.66 -1.65 -1.65 -1.65 -1.64 -1.63  0.01]\n",
      " [-1.51 -1.66 -0.36 -2.63 -5.21  0.09 -5.66 -0.03]\n",
      " [ 0.41 -1.66 -1.66  0.29 -2.27 -7.85 -1.59  0.34]\n",
      " [ 0.82 -2.51 -2.38 -1.65  0.32 -5.    0.03 -2.14]\n",
      " [ 0.42 -1.66  0.11 -7.36  0.12 -2.71 -1.13 -0.04]\n",
      " [ 0.27 -1.66 -1.65 -1.65 -1.65  0.05 -2.11  0.66]\n",
      " [ 0.43 -2.2   0.26  0.04  0.3  -2.4   0.65  0.59]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 8.700e-01  3.300e-01  9.000e-02  2.000e-01  6.900e-01  9.400e-01\n",
      "   8.900e-01  7.000e-02]\n",
      " [ 6.000e-01 -1.660e+00 -1.213e+01 -1.378e+01 -1.650e+00 -5.070e+00\n",
      "  -1.630e+00 -2.840e+00]\n",
      " [-1.510e+00 -1.660e+00 -4.500e-01 -2.360e+00 -7.630e+00  2.600e-01\n",
      "  -1.610e+00  7.000e-02]\n",
      " [ 6.700e-01 -1.687e+01 -1.660e+00  2.200e-01 -2.240e+00 -1.550e+00\n",
      "  -7.470e+00 -2.130e+00]\n",
      " [ 1.600e-01 -3.200e-01 -7.540e+00 -1.650e+00 -2.550e+00 -1.490e+00\n",
      "   0.000e+00 -2.460e+00]\n",
      " [ 5.000e-01 -1.660e+00  2.300e-01 -1.650e+00  6.000e-02 -4.930e+00\n",
      "  -1.120e+00  8.000e-02]\n",
      " [ 1.200e-01 -1.384e+01 -4.980e+00 -1.213e+01 -5.450e+00  1.000e-02\n",
      "  -2.300e+00  6.600e-01]\n",
      " [ 6.200e-01 -2.320e+00  4.100e-01 -2.540e+00 -2.410e+00  5.000e-01\n",
      "   7.000e-02  3.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.61   0.6    0.35   0.61   0.43   0.05   0.06   0.61]\n",
      " [  0.03  -1.66  -1.65  -1.65  -1.65  -1.64  -5.5   -2.42]\n",
      " [ -1.53 -13.79  -2.2   -0.13  -7.47   0.12  -7.39  -2.82]\n",
      " [  0.48  -1.66  -7.61   0.14   0.17  -1.55  -5.5    0.21]\n",
      " [  0.9   -0.42  -1.66  -9.74   0.17  -7.59  -2.47   0.54]\n",
      " [  0.51  -2.33   0.13  -5.63   0.05  -1.37  -7.38  -2.47]\n",
      " [  0.88  -1.66  -1.66  -1.65 -10.17   0.04  -0.57   0.9 ]\n",
      " [  0.58  -2.44  -2.38  -2.64  -2.34   0.63  -2.26  -2.11]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ < ^ ^ ^ < < █ \n",
      "^ v █ █ ^ █ v █ \n",
      "█ < < █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < ^ < █ ^ ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 115 Tot Reward: -1101\n",
      "Episode: 2 - Tot Steps: 465 Tot Reward: -1683\n",
      "Episode: 3 - Tot Steps: 30 Tot Reward: -117\n",
      "Episode: 4 - Tot Steps: 200 Tot Reward: -287\n",
      "Episode: 5 - Tot Steps: 73 Tot Reward: -73\n",
      "Episode: 6 - Tot Steps: 233 Tot Reward: -320\n",
      "Episode: 7 - Tot Steps: 137 Tot Reward: -253\n",
      "Episode: 8 - Tot Steps: 119 Tot Reward: -148\n",
      "Episode: 9 - Tot Steps: 407 Tot Reward: -726\n",
      "Episode: 10 - Tot Steps: 107 Tot Reward: -165\n",
      "Episode: 11 - Tot Steps: 238 Tot Reward: -383\n",
      "Episode: 12 - Tot Steps: 138 Tot Reward: -225\n",
      "Episode: 13 - Tot Steps: 133 Tot Reward: -162\n",
      "Episode: 14 - Tot Steps: 60 Tot Reward: -118\n",
      "Episode: 15 - Tot Steps: 102 Tot Reward: -131\n",
      "Episode: 16 - Tot Steps: 164 Tot Reward: -193\n",
      "Episode: 17 - Tot Steps: 102 Tot Reward: -102\n",
      "Episode: 18 - Tot Steps: 102 Tot Reward: -131\n",
      "Episode: 19 - Tot Steps: 77 Tot Reward: -135\n",
      "Episode: 20 - Tot Steps: 101 Tot Reward: -101\n",
      "Episode: 21 - Tot Steps: 102 Tot Reward: -102\n",
      "Episode: 22 - Tot Steps: 195 Tot Reward: -311\n",
      "Episode: 23 - Tot Steps: 92 Tot Reward: -92\n",
      "Episode: 24 - Tot Steps: 88 Tot Reward: -204\n",
      "Episode: 25 - Tot Steps: 59 Tot Reward: -59\n",
      "Episode: 26 - Tot Steps: 48 Tot Reward: -48\n",
      "Episode: 27 - Tot Steps: 67 Tot Reward: -67\n",
      "Episode: 28 - Tot Steps: 53 Tot Reward: -53\n",
      "Episode: 29 - Tot Steps: 61 Tot Reward: -90\n",
      "Episode: 30 - Tot Steps: 60 Tot Reward: -118\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.91   0.99   0.98   0.93   0.95   0.7    0.46   0.42]\n",
      " [  0.43  -1.67  -1.67  -1.67  -1.67  -1.66  -1.66   0.16]\n",
      " [ -1.66  -1.67  -0.29  -0.18  -1.67   0.24  -1.66   0.74]\n",
      " [  0.88  -1.67 -10.74  -5.68  -0.15  -5.95  -1.65  -5.26]\n",
      " [  0.91  -0.18  -1.67 -14.41  -5.58  -1.61  -0.34  -5.71]\n",
      " [  0.36 -10.14  -0.63  -1.67  -5.76  -1.54  -5.28   0.47]\n",
      " [  0.94  -1.67 -14.6   -1.67 -17.59   0.12  -0.96   0.04]\n",
      " [  0.63  -1.07  -0.52  -0.84  -0.74   0.52   0.1    0.06]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.41   0.31   0.6    0.43   0.4    0.62   0.78   0.39]\n",
      " [  0.71  -1.67  -1.67  -1.67  -1.67  -1.66  -1.66   0.29]\n",
      " [ -1.66  -1.67  -0.3   -5.39  -5.85  -0.03  -5.52   0.46]\n",
      " [  0.7   -1.67  -1.67  -0.12  -5.28  -5.72  -1.65  -0.45]\n",
      " [  0.81  -5.18  -5.42  -1.67  -0.37 -10.65  -0.11   0.02]\n",
      " [  0.61  -1.67  -0.51 -17.34  -0.52  -5.97  -1.4    0.64]\n",
      " [  0.43  -1.67  -1.67  -1.67  -1.67  -0.04 -10.39   0.13]\n",
      " [  0.51  -5.37  -5.54  -5.86  -5.22  -5.43  -5.73   0.88]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.58   0.11   0.87   0.48   0.67   0.77   0.93   0.91]\n",
      " [  0.15  -1.67 -14.39 -10.38  -1.67 -10.59  -1.66   0.07]\n",
      " [ -1.66  -1.67  -0.17   0.05 -10.25  -0.09  -1.66  -5.31]\n",
      " [  0.07 -14.21  -1.67   0.05  -5.55  -1.64  -5.94  -5.27]\n",
      " [  0.73  -0.32 -14.34  -1.67  -5.28  -1.6   -0.27  -5.86]\n",
      " [  0.39  -1.67  -0.48  -1.67  -0.31  -5.53  -1.33   0.51]\n",
      " [  0.04 -23.63 -17.45 -20.12 -14.52   0.13 -10.51   0.42]\n",
      " [  0.17 -10.33  -5.73  -5.19  -5.2  -10.25 -10.21   0.86]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 2.600e-01  3.500e-01  5.200e-01  1.000e-02  4.500e-01  3.000e-01\n",
      "   5.000e-02  8.000e-01]\n",
      " [ 9.500e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.660e+00\n",
      "  -5.210e+00  8.000e-02]\n",
      " [-1.660e+00 -5.960e+00 -5.590e+00 -2.100e-01 -1.040e+01  1.300e-01\n",
      "  -5.560e+00 -5.140e+00]\n",
      " [ 1.200e-01 -1.670e+00 -1.026e+01 -5.590e+00 -2.900e-01 -1.640e+00\n",
      "  -1.424e+01 -5.240e+00]\n",
      " [ 8.300e-01 -2.300e-01 -1.670e+00 -1.462e+01 -4.700e-01 -1.452e+01\n",
      "  -5.600e+00 -5.180e+00]\n",
      " [ 1.000e-01 -1.444e+01 -5.500e-01 -1.439e+01 -3.800e-01 -1.530e+00\n",
      "  -5.600e+00  3.200e-01]\n",
      " [ 4.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -5.780e+00  3.100e-01\n",
      "  -8.300e-01  1.000e-01]\n",
      " [ 4.100e-01 -5.420e+00 -5.820e+00 -5.900e+00 -5.370e+00 -5.860e+00\n",
      "   2.000e-02  7.400e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ ^ ^ > > > v █ \n",
      "^ v █ █ ^ █ v █ \n",
      "█ < v █ █ v ^ █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 162 Tot Reward: -1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 124 Tot Reward: -820\n",
      "Episode: 3 - Tot Steps: 237 Tot Reward: -469\n",
      "Episode: 4 - Tot Steps: 235 Tot Reward: -264\n",
      "Episode: 5 - Tot Steps: 152 Tot Reward: -239\n",
      "Episode: 6 - Tot Steps: 171 Tot Reward: -229\n",
      "Episode: 7 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 8 - Tot Steps: 97 Tot Reward: -184\n",
      "Episode: 9 - Tot Steps: 139 Tot Reward: -168\n",
      "Episode: 10 - Tot Steps: 178 Tot Reward: -207\n",
      "Episode: 11 - Tot Steps: 121 Tot Reward: -121\n",
      "Episode: 12 - Tot Steps: 103 Tot Reward: -161\n",
      "Episode: 13 - Tot Steps: 113 Tot Reward: -142\n",
      "Episode: 14 - Tot Steps: 79 Tot Reward: -108\n",
      "Episode: 15 - Tot Steps: 57 Tot Reward: -57\n",
      "Episode: 16 - Tot Steps: 180 Tot Reward: -209\n",
      "Episode: 17 - Tot Steps: 89 Tot Reward: -89\n",
      "Episode: 18 - Tot Steps: 58 Tot Reward: -58\n",
      "Episode: 19 - Tot Steps: 133 Tot Reward: -249\n",
      "Episode: 20 - Tot Steps: 52 Tot Reward: -81\n",
      "Episode: 21 - Tot Steps: 216 Tot Reward: -361\n",
      "Episode: 22 - Tot Steps: 43 Tot Reward: -101\n",
      "Episode: 23 - Tot Steps: 84 Tot Reward: -113\n",
      "Episode: 24 - Tot Steps: 56 Tot Reward: -85\n",
      "Episode: 25 - Tot Steps: 45 Tot Reward: -45\n",
      "Episode: 26 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 27 - Tot Steps: 34 Tot Reward: -34\n",
      "Episode: 28 - Tot Steps: 34 Tot Reward: -34\n",
      "Episode: 29 - Tot Steps: 70 Tot Reward: -99\n",
      "Episode: 30 - Tot Steps: 43 Tot Reward: -43\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.21   0.19   0.44   0.53   0.38   0.72   0.3    0.17]\n",
      " [  0.36  -1.67  -1.67  -1.67  -1.67  -1.67  -1.66  -8.87]\n",
      " [ -1.67  -1.67  -0.58  -0.65  -1.67   0.15  -1.66  -8.37]\n",
      " [  0.33  -1.67 -19.41  -8.58  -0.61 -19.56  -1.66   0.06]\n",
      " [  0.02  -0.91  -1.67  -8.66  -8.29  -1.62  -0.64   0.84]\n",
      " [  0.5  -15.    -0.43  -1.67  -8.27  -1.55 -15.21   0.25]\n",
      " [  0.96  -1.67 -19.33  -1.67  -8.85  -0.22  -0.98   0.27]\n",
      " [  0.48  -0.46  -0.3   -0.22  -0.02  -8.75   0.21   0.18]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.14   0.81   0.78   0.77   0.74   0.99   0.87   0.04]\n",
      " [  0.37  -1.67  -1.67  -1.67  -1.67  -1.67  -1.66  -0.59]\n",
      " [ -1.67  -1.67  -0.71  -8.23 -14.94  -0.22  -8.6    0.49]\n",
      " [  0.23  -1.67  -1.67  -0.2   -8.54 -19.38  -1.66  -0.02]\n",
      " [  0.3  -15.    -8.46  -1.67   0.1   -8.91  -0.4   -8.3 ]\n",
      " [  0.13  -1.67  -0.38  -8.75  -0.34 -14.84  -1.37   0.24]\n",
      " [  0.04  -1.67  -1.67  -1.67  -1.67  -0.04  -8.7    0.33]\n",
      " [  0.8   -8.44  -8.86  -8.84  -8.58  -8.65  -8.46   0.66]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.73   0.59   0.14   0.68   0.1    0.84   0.81   0.72]\n",
      " [  0.95  -1.67  -8.93 -19.36  -1.67  -8.34  -1.66  -8.87]\n",
      " [ -1.67  -1.67  -0.87  -8.35 -14.94  -0.13  -1.66  -8.36]\n",
      " [  0.24 -26.47  -1.67   0.03  -8.51  -1.64 -19.51  -8.31]\n",
      " [  0.44  -0.64 -15.04  -1.67  -8.27  -1.61  -0.52  -8.35]\n",
      " [  0.47  -1.67  -0.58  -1.67  -0.25  -8.66  -1.34   0.21]\n",
      " [  0.84 -14.99  -8.89 -14.91  -8.78  -8.61  -8.66   0.3 ]\n",
      " [  0.19  -8.48  -8.97  -8.29  -8.33  -8.41   0.17   0.5 ]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 6.000e-01  3.800e-01  7.700e-01  1.000e-01  3.200e-01  0.000e+00\n",
      "   3.300e-01  9.000e-01]\n",
      " [ 5.100e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.491e+01 -8.780e+00]\n",
      " [-1.670e+00 -2.501e+01 -8.930e+00 -7.800e-01 -1.478e+01 -3.600e-01\n",
      "  -8.710e+00  5.800e-01]\n",
      " [ 5.000e-02 -1.670e+00 -1.519e+01 -8.460e+00 -4.200e-01 -1.640e+00\n",
      "  -8.360e+00 -8.680e+00]\n",
      " [ 1.900e-01 -8.800e-01 -1.670e+00 -8.240e+00 -1.000e-02 -1.522e+01\n",
      "  -8.560e+00  5.500e-01]\n",
      " [ 5.200e-01 -1.518e+01 -4.400e-01 -1.476e+01  2.200e-01 -1.540e+00\n",
      "  -8.400e+00 -8.420e+00]\n",
      " [ 5.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.487e+01 -3.500e-01\n",
      "  -8.600e-01  3.400e-01]\n",
      " [ 2.100e-01 -8.300e+00 -8.670e+00 -8.520e+00 -8.950e+00 -8.510e+00\n",
      "   3.900e-01  3.700e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ ^ < > ^ > ^ █ \n",
      "v < █ █ ^ █ v █ \n",
      "█ < v █ █ > < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 43 Tot Reward: -391\n",
      "Episode: 2 - Tot Steps: 196 Tot Reward: -1472\n",
      "Episode: 3 - Tot Steps: 339 Tot Reward: -1093\n",
      "Episode: 4 - Tot Steps: 122 Tot Reward: -180\n",
      "Episode: 5 - Tot Steps: 179 Tot Reward: -324\n",
      "Episode: 6 - Tot Steps: 133 Tot Reward: -162\n",
      "Episode: 7 - Tot Steps: 90 Tot Reward: -90\n",
      "Episode: 8 - Tot Steps: 80 Tot Reward: -167\n",
      "Episode: 9 - Tot Steps: 170 Tot Reward: -228\n",
      "Episode: 10 - Tot Steps: 87 Tot Reward: -145\n",
      "Episode: 11 - Tot Steps: 117 Tot Reward: -146\n",
      "Episode: 12 - Tot Steps: 18 Tot Reward: -47\n",
      "Episode: 13 - Tot Steps: 47 Tot Reward: -47\n",
      "Episode: 14 - Tot Steps: 58 Tot Reward: -58\n",
      "Episode: 15 - Tot Steps: 38 Tot Reward: -67\n",
      "Episode: 16 - Tot Steps: 210 Tot Reward: -355\n",
      "Episode: 17 - Tot Steps: 42 Tot Reward: -42\n",
      "Episode: 18 - Tot Steps: 53 Tot Reward: -53\n",
      "Episode: 19 - Tot Steps: 40 Tot Reward: -40\n",
      "Episode: 20 - Tot Steps: 45 Tot Reward: -103\n",
      "Episode: 21 - Tot Steps: 169 Tot Reward: -343\n",
      "Episode: 22 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 23 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 24 - Tot Steps: 104 Tot Reward: -133\n",
      "Episode: 25 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 26 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 27 - Tot Steps: 68 Tot Reward: -126\n",
      "Episode: 28 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 29 - Tot Steps: 104 Tot Reward: -133\n",
      "Episode: 30 - Tot Steps: 23 Tot Reward: -23\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 1.000e-02  2.000e-02  1.800e-01  7.400e-01  5.300e-01  9.700e-01\n",
      "   1.100e-01  8.800e-01]\n",
      " [ 8.300e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00  2.000e-02]\n",
      " [-1.670e+00 -1.670e+00 -4.500e-01  4.000e-02 -1.670e+00 -7.200e-01\n",
      "  -1.660e+00 -1.140e+01]\n",
      " [ 3.100e-01 -1.670e+00 -1.914e+01 -1.140e+01  3.000e-02 -2.609e+01\n",
      "  -1.660e+00 -1.135e+01]\n",
      " [ 4.000e-01 -2.500e-01 -1.670e+00 -1.898e+01 -1.138e+01 -1.630e+00\n",
      "  -1.900e-01 -1.186e+01]\n",
      " [ 5.300e-01 -1.165e+01 -6.600e-01 -1.670e+00 -1.169e+01 -1.540e+00\n",
      "  -1.190e+01 -1.148e+01]\n",
      " [ 1.500e-01 -1.670e+00 -1.162e+01 -1.670e+00 -1.182e+01 -4.100e-01\n",
      "  -9.900e-01  8.400e-01]\n",
      " [ 3.200e-01  4.000e-02 -7.600e-01 -1.530e+00  1.100e-01 -1.169e+01\n",
      "  -2.000e-01  1.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.18   0.84   0.37   0.02   0.58   0.61   0.42   0.21]\n",
      " [  0.17  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -0.14]\n",
      " [ -1.67  -1.67  -0.73 -11.86 -11.77  -0.9  -11.82  -0.35]\n",
      " [  0.21  -1.67  -1.67  -1.07 -11.79 -11.74  -1.66  -0.55]\n",
      " [  0.28 -11.95 -11.43  -1.67  -0.83 -11.52  -0.53   0.19]\n",
      " [  0.79  -1.67  -0.89 -18.99  -0.64 -18.89  -1.38  -0.27]\n",
      " [  0.33  -1.67  -1.67  -1.67  -1.67  -0.8  -11.85   0.56]\n",
      " [  0.66 -11.4  -11.82 -11.67 -11.61   0.35 -11.48   0.06]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 9.300e-01  5.800e-01  6.700e-01  5.400e-01  1.800e-01  6.900e-01\n",
      "   6.500e-01  4.100e-01]\n",
      " [ 2.500e-01 -1.670e+00 -1.156e+01 -1.882e+01 -1.670e+00 -1.907e+01\n",
      "  -1.660e+00 -1.165e+01]\n",
      " [-1.670e+00 -1.670e+00 -6.400e-01 -1.159e+01 -1.903e+01 -7.200e-01\n",
      "  -1.660e+00 -1.144e+01]\n",
      " [ 8.600e-01 -2.603e+01 -1.670e+00 -9.100e-01 -1.885e+01 -1.640e+00\n",
      "  -1.875e+01 -1.175e+01]\n",
      " [ 4.600e-01 -8.200e-01 -2.346e+01 -1.670e+00 -1.163e+01 -1.600e+00\n",
      "   1.000e-01 -1.878e+01]\n",
      " [ 8.400e-01 -1.670e+00 -6.600e-01 -1.670e+00 -5.800e-01 -2.334e+01\n",
      "  -1.260e+00 -1.800e-01]\n",
      " [ 7.800e-01 -1.132e+01 -1.899e+01 -2.903e+01 -1.143e+01 -1.145e+01\n",
      "  -1.184e+01  8.900e-01]\n",
      " [ 9.100e-01 -1.148e+01 -1.178e+01 -1.161e+01 -1.178e+01  1.000e-01\n",
      "   2.000e-02  7.400e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.1    0.84   0.77   0.05   0.96   0.38   0.24   0.9 ]\n",
      " [  0.79  -1.67  -1.67  -1.67  -1.67  -1.67 -11.69 -11.53]\n",
      " [ -1.67 -23.22 -11.69  -0.33 -11.7   -0.69 -11.81 -11.78]\n",
      " [  0.24  -1.67 -23.38 -11.41   0.23  -1.65 -19.02 -11.6 ]\n",
      " [  0.9   -0.74  -1.67 -23.35  -0.73 -11.65 -11.74 -11.39]\n",
      " [  0.81 -23.39  -0.58 -18.91  -0.09  -1.5  -18.99 -11.73]\n",
      " [  0.06  -1.67  -1.67  -1.67 -11.53  -0.42  -0.64   0.18]\n",
      " [  0.24 -11.92 -11.7  -11.59   0.27 -11.55   0.31   0.87]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ ^ > > > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ > < █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 167 Tot Reward: -1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 130 Tot Reward: -826\n",
      "Episode: 3 - Tot Steps: 200 Tot Reward: -432\n",
      "Episode: 4 - Tot Steps: 224 Tot Reward: -398\n",
      "Episode: 5 - Tot Steps: 59 Tot Reward: -88\n",
      "Episode: 6 - Tot Steps: 114 Tot Reward: -143\n",
      "Episode: 7 - Tot Steps: 211 Tot Reward: -298\n",
      "Episode: 8 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 9 - Tot Steps: 73 Tot Reward: -131\n",
      "Episode: 10 - Tot Steps: 114 Tot Reward: -172\n",
      "Episode: 11 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 12 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 13 - Tot Steps: 111 Tot Reward: -140\n",
      "Episode: 14 - Tot Steps: 38 Tot Reward: -67\n",
      "Episode: 15 - Tot Steps: 40 Tot Reward: -40\n",
      "Episode: 16 - Tot Steps: 102 Tot Reward: -131\n",
      "Episode: 17 - Tot Steps: 65 Tot Reward: -181\n",
      "Episode: 18 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 19 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 20 - Tot Steps: 28 Tot Reward: -86\n",
      "Episode: 21 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 22 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 23 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 24 - Tot Steps: 48 Tot Reward: -135\n",
      "Episode: 25 - Tot Steps: 45 Tot Reward: -103\n",
      "Episode: 26 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 27 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 28 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 29 - Tot Steps: 91 Tot Reward: -207\n",
      "Episode: 30 - Tot Steps: 37 Tot Reward: -66\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 9.000e-01  2.300e-01  5.700e-01  8.400e-01  3.500e-01  2.900e-01\n",
      "   7.100e-01  4.500e-01]\n",
      " [ 4.300e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.498e+01]\n",
      " [-1.670e+00 -1.670e+00 -2.000e-02 -1.360e+00 -1.670e+00 -1.320e+00\n",
      "  -1.660e+00 -1.452e+01]\n",
      " [ 2.300e-01 -1.670e+00 -1.476e+01 -2.242e+01 -1.100e+00 -2.631e+01\n",
      "  -1.660e+00 -1.480e+01]\n",
      " [ 6.700e-01 -7.800e-01 -1.670e+00 -2.821e+01 -1.495e+01 -1.640e+00\n",
      "  -4.500e-01  2.300e-01]\n",
      " [ 4.900e-01 -2.234e+01 -1.220e+00 -1.670e+00 -1.475e+01 -1.600e+00\n",
      "  -1.472e+01  2.800e-01]\n",
      " [ 3.000e-02 -1.670e+00 -2.219e+01 -1.670e+00 -2.234e+01 -1.700e-01\n",
      "  -1.030e+00  5.600e-01]\n",
      " [ 9.000e-01 -1.110e+00 -9.400e-01 -1.350e+00 -8.400e-01 -1.482e+01\n",
      "   5.100e-01 -0.000e+00]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 8.000e-02  3.600e-01  2.500e-01  1.000e-02  7.700e-01  5.000e-02\n",
      "   5.300e-01  7.700e-01]\n",
      " [ 2.900e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.240e+00]\n",
      " [-1.670e+00 -1.670e+00 -8.100e-01 -1.457e+01 -2.630e+01 -1.200e+00\n",
      "  -2.619e+01 -2.300e-01]\n",
      " [ 1.200e-01 -1.670e+00 -1.670e+00 -1.010e+00 -1.493e+01 -2.628e+01\n",
      "  -1.660e+00 -7.800e-01]\n",
      " [ 1.000e-02 -1.492e+01 -2.221e+01 -1.670e+00 -1.020e+00 -2.239e+01\n",
      "  -1.400e-01 -1.444e+01]\n",
      " [ 5.300e-01 -1.670e+00 -9.400e-01 -2.229e+01 -8.400e-01 -2.229e+01\n",
      "  -1.410e+00 -7.000e-02]\n",
      " [ 2.900e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -8.300e-01\n",
      "  -1.488e+01  6.700e-01]\n",
      " [ 3.100e-01 -1.488e+01 -1.492e+01 -1.493e+01 -1.495e+01 -1.459e+01\n",
      "   5.000e-01  1.200e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.64   0.3    0.32   0.35   0.09   0.45   0.31   0.53]\n",
      " [  0.53  -1.67 -22.2  -22.53  -1.67 -28.24  -1.67 -14.78]\n",
      " [ -1.67  -1.67  -0.79 -14.33 -14.47  -1.02  -1.66 -14.66]\n",
      " [  0.65 -22.31  -1.67  -1.24 -14.66  -1.64 -14.53 -14.53]\n",
      " [  0.09  -1.01 -22.23  -1.67 -14.48  -1.61  -0.68 -14.5 ]\n",
      " [  0.45  -1.67  -0.97  -1.67  -0.18 -22.29  -1.29  -0.29]\n",
      " [  0.72 -26.31 -22.3  -26.48 -22.26 -14.81 -14.38   0.29]\n",
      " [  0.81 -14.89 -14.97 -14.56 -14.46 -14.69   0.37   0.08]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.31   0.28   0.37   0.26   0.97   0.07   0.91   0.57]\n",
      " [  0.39  -1.67  -1.67  -1.67  -1.67  -1.67 -26.35 -22.37]\n",
      " [ -1.67 -22.39 -14.71  -1.29 -14.49  -1.07 -14.45 -14.64]\n",
      " [  1.    -1.67 -26.41 -22.39  -0.71  -1.65 -22.41 -14.31]\n",
      " [  0.94  -0.89  -1.67 -22.42  -0.86 -22.23 -14.43   0.21]\n",
      " [  0.98 -26.2   -0.31 -14.54  -0.86  -1.52 -14.55   0.57]\n",
      " [  0.34  -1.67  -1.67  -1.67 -14.48  -0.26  -0.73   0.43]\n",
      " [  0.41 -14.6  -14.84 -14.6  -14.5    0.09 -14.42 -14.3 ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "< ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ v █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 435 Tot Reward: -3045\n",
      "Episode: 2 - Tot Steps: 106 Tot Reward: -135\n",
      "Episode: 3 - Tot Steps: 123 Tot Reward: -181\n",
      "Episode: 4 - Tot Steps: 114 Tot Reward: -201\n",
      "Episode: 5 - Tot Steps: 89 Tot Reward: -147\n",
      "Episode: 6 - Tot Steps: 59 Tot Reward: -117\n",
      "Episode: 7 - Tot Steps: 84 Tot Reward: -142\n",
      "Episode: 8 - Tot Steps: 42 Tot Reward: -158\n",
      "Episode: 9 - Tot Steps: 142 Tot Reward: -229\n",
      "Episode: 10 - Tot Steps: 37 Tot Reward: -37\n",
      "Episode: 11 - Tot Steps: 68 Tot Reward: -68\n",
      "Episode: 12 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 13 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 14 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 15 - Tot Steps: 49 Tot Reward: -49\n",
      "Episode: 16 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 17 - Tot Steps: 41 Tot Reward: -70\n",
      "Episode: 18 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 19 - Tot Steps: 145 Tot Reward: -203\n",
      "Episode: 20 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 21 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 22 - Tot Steps: 38 Tot Reward: -38\n",
      "Episode: 23 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 24 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 25 - Tot Steps: 26 Tot Reward: -55\n",
      "Episode: 26 - Tot Steps: 63 Tot Reward: -121\n",
      "Episode: 27 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 28 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 29 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 30 - Tot Steps: 18 Tot Reward: -18\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.51   0.66   0.8    0.36   0.18   0.35   0.44   0.72]\n",
      " [  0.77  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -25.05]\n",
      " [ -1.67  -1.67  -1.14  -0.36  -1.67  -1.22  -1.66 -17.78]\n",
      " [  0.11  -1.67 -17.75 -17.94  -1.03 -25.14  -1.66 -17.84]\n",
      " [  0.76  -1.04  -1.67 -24.99 -17.62  -1.65  -0.7  -17.43]\n",
      " [  0.1  -25.17  -0.53  -1.67 -17.87  -1.6  -25.   -17.77]\n",
      " [  0.07  -1.67 -17.89  -1.67 -25.15  -0.92  -1.2    0.74]\n",
      " [  0.34  -1.55  -0.74  -1.47  -0.09 -17.7   -0.47   0.69]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  1.     0.7    0.77   0.57   0.61   0.1    0.53   0.21]\n",
      " [  0.16  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -0.48]\n",
      " [ -1.67  -1.67  -1.16 -17.82 -17.6   -1.13 -17.71  -0.74]\n",
      " [  0.54  -1.67  -1.67  -1.14 -17.68 -25.08  -1.66  -0.26]\n",
      " [  0.11 -17.78 -17.5   -1.67  -1.   -17.55  -0.51 -17.74]\n",
      " [  0.8   -1.67  -0.53 -25.12  -1.03 -17.61  -1.47  -0.54]\n",
      " [  0.04  -1.67  -1.67  -1.67  -1.67  -0.52 -25.06   0.51]\n",
      " [  0.07 -17.53 -17.56 -17.95 -17.84 -17.68 -17.64   0.85]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.72   0.49   0.09   0.67   0.3    0.99   0.99   0.37]\n",
      " [  0.66  -1.67 -29.46 -17.68  -1.67 -28.14  -1.67 -17.9 ]\n",
      " [ -1.67  -1.67  -1.33 -18.03 -17.58  -0.84  -1.66 -17.73]\n",
      " [  0.32 -25.05  -1.67  -0.56 -17.4   -1.64 -17.72 -17.69]\n",
      " [  0.91  -0.48 -17.65  -1.67 -17.62  -1.6   -1.02 -17.9 ]\n",
      " [  0.58  -1.67  -0.88  -1.67  -1.15 -25.09  -1.26  -0.39]\n",
      " [  0.3  -29.67 -24.92 -28.4  -17.44 -17.57 -17.71   0.85]\n",
      " [  0.34 -17.66 -17.89 -17.62   0.3    0.17 -17.56   0.91]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 8.900e-01  3.300e-01  4.900e-01  8.300e-01  1.700e-01  6.000e-01\n",
      "   2.700e-01  3.500e-01]\n",
      " [ 5.400e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.784e+01 -1.749e+01]\n",
      " [-1.670e+00 -2.504e+01 -1.768e+01 -1.300e-01 -2.525e+01 -1.150e+00\n",
      "  -2.485e+01 -1.744e+01]\n",
      " [ 3.500e-01 -1.670e+00 -1.744e+01 -1.747e+01 -3.500e-01 -1.650e+00\n",
      "  -1.761e+01 -1.738e+01]\n",
      " [ 9.500e-01 -1.120e+00 -1.670e+00 -2.805e+01 -1.070e+00 -2.528e+01\n",
      "  -1.744e+01 -1.765e+01]\n",
      " [ 6.300e-01 -2.515e+01 -8.300e-01 -2.818e+01 -1.150e+00 -1.510e+00\n",
      "  -2.504e+01 -1.772e+01]\n",
      " [ 8.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.760e+01 -7.600e-01\n",
      "  -6.600e-01  4.600e-01]\n",
      " [ 2.100e-01 -1.788e+01 -1.770e+01 -1.782e+01 -1.764e+01 -1.749e+01\n",
      "   1.000e-02  4.400e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> < █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ < < ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 160 Tot Reward: -1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 82 Tot Reward: -952\n",
      "Episode: 3 - Tot Steps: 69 Tot Reward: -98\n",
      "Episode: 4 - Tot Steps: 188 Tot Reward: -217\n",
      "Episode: 5 - Tot Steps: 203 Tot Reward: -406\n",
      "Episode: 6 - Tot Steps: 32 Tot Reward: -32\n",
      "Episode: 7 - Tot Steps: 95 Tot Reward: -95\n",
      "Episode: 8 - Tot Steps: 95 Tot Reward: -95\n",
      "Episode: 9 - Tot Steps: 67 Tot Reward: -154\n",
      "Episode: 10 - Tot Steps: 72 Tot Reward: -101\n",
      "Episode: 11 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 12 - Tot Steps: 54 Tot Reward: -54\n",
      "Episode: 13 - Tot Steps: 55 Tot Reward: -84\n",
      "Episode: 14 - Tot Steps: 58 Tot Reward: -58\n",
      "Episode: 15 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 16 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 17 - Tot Steps: 31 Tot Reward: -60\n",
      "Episode: 18 - Tot Steps: 68 Tot Reward: -126\n",
      "Episode: 19 - Tot Steps: 25 Tot Reward: -112\n",
      "Episode: 20 - Tot Steps: 38 Tot Reward: -67\n",
      "Episode: 21 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 22 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 23 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 24 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 25 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 26 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 27 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 28 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 29 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 30 - Tot Steps: 15 Tot Reward: -15\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 6.600e-01  2.400e-01  5.600e-01  4.000e-01  6.200e-01  7.800e-01\n",
      "   8.600e-01  7.600e-01]\n",
      " [ 1.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -2.065e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.380e+00 -1.260e+00 -1.670e+00 -1.160e+00\n",
      "  -1.670e+00 -2.084e+01]\n",
      " [ 9.000e-02 -1.670e+00 -2.088e+01 -2.086e+01 -4.200e-01 -2.085e+01\n",
      "  -1.660e+00 -2.061e+01]\n",
      " [ 6.700e-01 -4.300e-01 -1.670e+00 -2.073e+01 -2.055e+01 -1.650e+00\n",
      "  -1.250e+00 -2.073e+01]\n",
      " [ 6.400e-01 -2.073e+01 -4.400e-01 -1.670e+00 -2.081e+01 -1.540e+00\n",
      "  -2.060e+01  6.600e-01]\n",
      " [ 1.000e-02 -1.670e+00 -2.065e+01 -1.670e+00 -2.076e+01 -4.500e-01\n",
      "  -1.390e+00  4.000e-01]\n",
      " [ 9.500e-01 -4.400e-01 -4.800e-01 -1.540e+00 -1.280e+00  1.600e-01\n",
      "  -3.300e-01  4.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.43   0.13   0.17   0.91   0.08   0.34   0.3    0.78]\n",
      " [  0.04  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.31]\n",
      " [ -1.67  -1.67  -1.25 -20.56 -27.32  -0.82 -20.65  -1.36]\n",
      " [  0.49  -1.67  -1.67  -0.44 -20.77 -20.76  -1.66  -0.69]\n",
      " [  0.12 -20.74 -27.11  -1.67  -0.43 -20.74  -0.43 -20.9 ]\n",
      " [  0.52  -1.67  -0.44 -27.21  -1.03 -20.8   -1.41   0.5 ]\n",
      " [  0.54  -1.67  -1.67  -1.67  -1.67  -0.42 -20.64   0.46]\n",
      " [  0.38 -20.84 -20.78 -20.82 -20.76 -20.68 -20.61 -20.71]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  1.     0.78   0.68   0.22   0.89   0.14   0.72   0.21]\n",
      " [  0.35  -1.67 -29.34 -20.47  -1.67 -27.35  -1.66 -20.75]\n",
      " [ -1.67  -1.67  -1.31 -20.92 -20.67  -0.39  -1.66 -20.53]\n",
      " [  0.   -20.7   -1.67  -0.27 -20.68  -1.64 -27.27 -20.89]\n",
      " [  0.53  -1.26 -20.53  -1.67 -20.86  -1.6   -0.55   0.25]\n",
      " [  0.66  -1.67  -0.39  -1.67  -1.28 -20.6   -1.24  -0.18]\n",
      " [  0.6  -20.55 -20.74 -29.54 -27.09   0.27 -20.58   0.63]\n",
      " [  0.24 -20.67 -20.72 -20.68 -20.78 -20.54   0.45   0.04]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 5.000e-02  1.000e-01  3.700e-01  8.800e-01  1.000e-02  3.800e-01\n",
      "   5.900e-01  7.000e-01]\n",
      " [ 5.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -2.730e+01 -2.079e+01]\n",
      " [-1.670e+00 -2.737e+01 -2.069e+01 -5.300e-01 -2.078e+01 -6.100e-01\n",
      "  -2.718e+01 -2.084e+01]\n",
      " [ 2.400e-01 -1.670e+00 -2.072e+01 -2.084e+01 -7.000e-01 -1.640e+00\n",
      "  -2.082e+01 -2.071e+01]\n",
      " [ 2.200e-01 -6.400e-01 -1.670e+00 -2.050e+01 -3.800e-01 -2.086e+01\n",
      "  -2.068e+01  1.300e-01]\n",
      " [ 6.300e-01 -2.072e+01 -1.210e+00 -2.921e+01 -1.080e+00 -1.500e+00\n",
      "  -2.074e+01  1.400e-01]\n",
      " [ 6.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.072e+01 -3.700e-01\n",
      "  -6.100e-01  9.700e-01]\n",
      " [ 7.300e-01 -2.071e+01 -2.068e+01 -2.074e+01 -2.059e+01 -2.057e+01\n",
      "  -2.045e+01 -2.043e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 89 Tot Reward: -901\n",
      "Episode: 2 - Tot Steps: 221 Tot Reward: -1845\n",
      "Episode: 3 - Tot Steps: 178 Tot Reward: -265\n",
      "Episode: 4 - Tot Steps: 214 Tot Reward: -475\n",
      "Episode: 5 - Tot Steps: 54 Tot Reward: -228\n",
      "Episode: 6 - Tot Steps: 83 Tot Reward: -83\n",
      "Episode: 7 - Tot Steps: 39 Tot Reward: -39\n",
      "Episode: 8 - Tot Steps: 64 Tot Reward: -64\n",
      "Episode: 9 - Tot Steps: 38 Tot Reward: -67\n",
      "Episode: 10 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 11 - Tot Steps: 45 Tot Reward: -45\n",
      "Episode: 12 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 13 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 14 - Tot Steps: 110 Tot Reward: -110\n",
      "Episode: 15 - Tot Steps: 25 Tot Reward: -54\n",
      "Episode: 16 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 17 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 18 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 19 - Tot Steps: 94 Tot Reward: -152\n",
      "Episode: 20 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 21 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 22 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 23 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 24 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 25 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 26 - Tot Steps: 18 Tot Reward: -76\n",
      "Episode: 27 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 28 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 29 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 30 - Tot Steps: 15 Tot Reward: -15\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.81   0.43   0.69   0.19   0.2    0.31   0.62   0.36]\n",
      " [  0.41  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -23.91]\n",
      " [ -1.67  -1.67  -0.37  -0.95  -1.67  -1.38  -1.66 -24.11]\n",
      " [  0.05  -1.67 -28.84 -23.68  -1.46 -28.85  -1.66 -23.66]\n",
      " [  0.31  -1.57  -1.67 -28.85 -23.85  -1.64  -1.43 -23.9 ]\n",
      " [  0.98 -23.72  -0.81  -1.67 -23.95  -1.62 -28.98 -23.9 ]\n",
      " [  0.71  -1.67 -28.86  -1.67 -23.6   -1.35  -1.23   0.17]\n",
      " [  0.64  -0.9   -1.41  -0.51  -0.74 -23.89  -0.41   0.48]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.29   0.98   0.23   0.04   0.77   0.25   0.22   0.65]\n",
      " [  0.25  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.43]\n",
      " [ -1.67  -1.67  -0.59 -23.8  -23.8   -0.91 -23.64  -1.45]\n",
      " [  0.74  -1.67  -1.67  -1.39 -23.95 -28.93  -1.66  -1.18]\n",
      " [  0.09 -28.59 -23.83  -1.67  -1.43 -23.74  -1.24 -23.59]\n",
      " [  0.08  -1.67  -0.87 -23.76  -1.44 -28.95  -1.29   0.35]\n",
      " [  0.07  -1.67  -1.67  -1.67  -1.67  -1.48 -30.03   0.06]\n",
      " [  0.09 -23.55 -23.68 -24.11 -23.94 -23.72 -23.87 -23.66]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 4.900e-01  8.000e-01  2.400e-01  7.600e-01  3.000e-01  6.500e-01\n",
      "   7.000e-01  6.400e-01]\n",
      " [ 4.000e-01 -1.670e+00 -2.365e+01 -2.380e+01 -1.670e+00 -2.892e+01\n",
      "  -1.670e+00 -2.390e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.390e+00 -2.360e+01 -2.873e+01 -1.160e+00\n",
      "  -1.660e+00 -2.352e+01]\n",
      " [ 6.100e-01 -2.988e+01 -1.670e+00 -5.700e-01 -2.377e+01 -1.640e+00\n",
      "  -2.849e+01 -2.360e+01]\n",
      " [ 2.000e-01 -4.800e-01 -2.378e+01 -1.670e+00 -2.382e+01 -1.600e+00\n",
      "  -6.000e-01 -2.372e+01]\n",
      " [ 1.000e-02 -1.670e+00 -1.390e+00 -1.670e+00 -5.200e-01 -2.892e+01\n",
      "  -1.280e+00 -4.100e-01]\n",
      " [ 8.700e-01 -2.368e+01 -2.864e+01 -2.353e+01 -2.371e+01 -2.382e+01\n",
      "  -2.384e+01  4.700e-01]\n",
      " [ 6.700e-01 -2.383e+01 -2.365e+01 -2.372e+01 -2.369e+01 -2.355e+01\n",
      "  -2.370e+01  2.200e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.88   0.3    0.3    0.64   0.79   0.43   0.9    0.63]\n",
      " [  0.06  -1.67  -1.67  -1.67  -1.67  -1.67 -28.56 -23.75]\n",
      " [ -1.67 -23.58 -23.57  -0.45 -28.92  -1.32 -28.69 -23.96]\n",
      " [  0.24  -1.67 -23.79 -24.1   -1.04  -1.66 -23.89 -23.51]\n",
      " [  0.06  -0.72  -1.67 -28.88  -0.67 -23.68 -23.73 -23.64]\n",
      " [  0.09 -28.93  -1.44 -23.69  -0.69  -1.51 -23.73 -23.64]\n",
      " [  0.75  -1.67  -1.67  -1.67 -23.8   -1.14  -0.69   0.77]\n",
      " [  0.83 -23.59 -23.79 -23.91 -23.55 -23.6  -23.58   0.38]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ ^ v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 55 Tot Reward: -867\n",
      "Episode: 2 - Tot Steps: 418 Tot Reward: -2013\n",
      "Episode: 3 - Tot Steps: 44 Tot Reward: -44\n",
      "Episode: 4 - Tot Steps: 99 Tot Reward: -128\n",
      "Episode: 5 - Tot Steps: 40 Tot Reward: -69\n",
      "Episode: 6 - Tot Steps: 53 Tot Reward: -140\n",
      "Episode: 7 - Tot Steps: 78 Tot Reward: -136\n",
      "Episode: 8 - Tot Steps: 97 Tot Reward: -126\n",
      "Episode: 9 - Tot Steps: 30 Tot Reward: -117\n",
      "Episode: 10 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 11 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 12 - Tot Steps: 36 Tot Reward: -36\n",
      "Episode: 13 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 14 - Tot Steps: 98 Tot Reward: -156\n",
      "Episode: 15 - Tot Steps: 33 Tot Reward: -33\n",
      "Episode: 16 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 17 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 18 - Tot Steps: 20 Tot Reward: -49\n",
      "Episode: 19 - Tot Steps: 21 Tot Reward: -50\n",
      "Episode: 20 - Tot Steps: 41 Tot Reward: -70\n",
      "Episode: 21 - Tot Steps: 15 Tot Reward: -44\n",
      "Episode: 22 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 23 - Tot Steps: 18 Tot Reward: -105\n",
      "Episode: 24 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 25 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 26 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 27 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 28 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 29 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 30 - Tot Steps: 15 Tot Reward: -15\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.85   0.04   0.26   0.44   0.66   0.62   0.3    0.91]\n",
      " [  0.25  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -26.91]\n",
      " [ -1.67  -1.67  -0.62  -0.55  -1.67  -1.55  -1.67 -26.69]\n",
      " [  0.35  -1.67 -26.8  -26.92  -1.56 -26.78  -1.66 -26.67]\n",
      " [  0.39  -1.55  -1.67 -29.87 -27.13  -1.66  -1.06 -26.77]\n",
      " [  0.76 -26.88  -1.13  -1.67 -26.85  -1.61 -26.63 -26.66]\n",
      " [  0.76  -1.67 -30.08  -1.67 -27.17  -0.46  -1.4    0.4 ]\n",
      " [  0.21  -1.39  -0.78  -0.68  -0.44 -26.58  -0.75  -0.48]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 9.000e-01  3.700e-01  7.900e-01  5.700e-01  5.200e-01  8.700e-01\n",
      "   7.400e-01  6.100e-01]\n",
      " [ 8.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.650e+00]\n",
      " [-1.670e+00 -1.670e+00 -1.560e+00 -2.714e+01 -2.671e+01 -6.000e-01\n",
      "  -2.679e+01 -1.570e+00]\n",
      " [ 7.100e-01 -1.670e+00 -1.670e+00 -1.030e+00 -2.671e+01 -2.675e+01\n",
      "  -1.660e+00 -5.300e-01]\n",
      " [ 5.000e-01 -2.671e+01 -2.991e+01 -1.670e+00 -6.500e-01 -2.699e+01\n",
      "  -7.000e-01 -2.659e+01]\n",
      " [ 4.500e-01 -1.670e+00 -1.560e+00 -2.680e+01 -1.570e+00 -2.994e+01\n",
      "  -1.380e+00 -5.600e-01]\n",
      " [ 8.600e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -6.900e-01\n",
      "  -2.689e+01  1.000e-02]\n",
      " [ 7.800e-01 -2.689e+01 -2.664e+01  2.900e-01  2.800e-01 -2.661e+01\n",
      "  -2.665e+01  3.200e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 5.200e-01  3.500e-01  1.000e-02  8.000e-02  9.100e-01  7.100e-01\n",
      "   6.200e-01  2.000e-01]\n",
      " [ 8.500e-01 -1.670e+00 -2.993e+01 -2.984e+01 -1.670e+00 -2.987e+01\n",
      "  -1.660e+00 -2.666e+01]\n",
      " [-1.670e+00 -1.670e+00 -6.700e-01 -2.682e+01 -3.016e+01 -7.300e-01\n",
      "  -1.660e+00 -2.679e+01]\n",
      " [ 2.600e-01 -2.987e+01 -1.670e+00 -1.150e+00 -2.664e+01 -1.640e+00\n",
      "  -2.686e+01 -2.660e+01]\n",
      " [ 2.000e-02 -1.570e+00 -3.021e+01 -1.670e+00 -2.681e+01 -1.600e+00\n",
      "  -1.410e+00 -2.662e+01]\n",
      " [ 5.700e-01 -1.670e+00 -1.610e+00 -1.670e+00 -8.000e-01 -2.674e+01\n",
      "  -1.250e+00 -5.100e-01]\n",
      " [ 5.100e-01 -2.958e+01 -2.660e+01 -2.659e+01 -2.658e+01 -2.678e+01\n",
      "  -2.946e+01  9.200e-01]\n",
      " [ 5.500e-01 -2.698e+01 -2.681e+01  5.700e-01 -2.656e+01 -2.677e+01\n",
      "  -2.675e+01  4.500e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 4.800e-01  3.200e-01  9.800e-01  7.800e-01  8.000e-01  6.200e-01\n",
      "   7.000e-01  8.200e-01]\n",
      " [ 6.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.052e+01 -2.694e+01]\n",
      " [-1.670e+00 -2.995e+01 -2.669e+01 -1.550e+00 -2.688e+01 -1.060e+00\n",
      "  -2.993e+01 -2.668e+01]\n",
      " [ 4.000e-01 -1.670e+00 -2.676e+01 -2.679e+01 -7.400e-01 -1.650e+00\n",
      "  -2.671e+01 -2.677e+01]\n",
      " [ 1.000e-02 -7.700e-01 -1.670e+00 -2.683e+01 -1.090e+00 -2.990e+01\n",
      "  -2.675e+01  3.700e-01]\n",
      " [ 9.700e-01 -2.686e+01 -1.550e+00 -2.954e+01 -7.000e-01 -1.500e+00\n",
      "  -2.943e+01 -2.666e+01]\n",
      " [ 8.500e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.677e+01 -5.600e-01\n",
      "  -6.300e-01  7.000e-01]\n",
      " [ 8.200e-01 -2.678e+01  1.200e-01  9.000e-01 -2.685e+01 -2.665e+01\n",
      "  -2.663e+01  8.200e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ < > ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 295 Tot Reward: -2644\n",
      "Episode: 2 - Tot Steps: 50 Tot Reward: -50\n",
      "Episode: 3 - Tot Steps: 72 Tot Reward: -72\n",
      "Episode: 4 - Tot Steps: 105 Tot Reward: -134\n",
      "Episode: 5 - Tot Steps: 49 Tot Reward: -49\n",
      "Episode: 6 - Tot Steps: 29 Tot Reward: -58\n",
      "Episode: 7 - Tot Steps: 49 Tot Reward: -49\n",
      "Episode: 8 - Tot Steps: 95 Tot Reward: -124\n",
      "Episode: 9 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 10 - Tot Steps: 89 Tot Reward: -147\n",
      "Episode: 11 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 12 - Tot Steps: 26 Tot Reward: -55\n",
      "Episode: 13 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 14 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 15 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 16 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 17 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 18 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 19 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 20 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 21 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 22 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 23 - Tot Steps: 17 Tot Reward: -46\n",
      "Episode: 24 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 25 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 26 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 27 - Tot Steps: 22 Tot Reward: -138\n",
      "Episode: 28 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 29 - Tot Steps: 15 Tot Reward: -15\n",
      "Episode: 30 - Tot Steps: 21 Tot Reward: -50\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.62   0.48   0.94   0.94   0.3    0.82   0.72   0.36]\n",
      " [  0.05  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67   0.07]\n",
      " [ -1.67  -1.67  -0.96  -1.26  -1.67  -1.67  -1.67 -29.71]\n",
      " [  0.57  -1.67 -30.28 -30.26  -0.68 -30.28  -1.66 -29.81]\n",
      " [  0.6   -1.51  -1.67 -30.33 -29.69  -1.66  -1.26 -29.78]\n",
      " [  0.91 -29.88  -0.83  -1.67 -29.6   -1.64 -29.66 -29.82]\n",
      " [  0.94  -1.67 -29.72  -1.67 -29.98  -0.86  -1.5    0.59]\n",
      " [  0.51   0.08  -1.39  -0.98  -0.64 -29.79  -0.96   0.91]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.6    0.5    0.97   0.94   0.65   0.56   0.41   0.56]\n",
      " [  0.91  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -0.76]\n",
      " [ -1.67  -1.67  -1.67 -29.95 -29.66  -0.81 -29.77  -1.67]\n",
      " [  0.1   -1.67  -1.67  -1.67 -29.62 -29.63  -1.66  -0.81]\n",
      " [  0.4    0.12 -29.78  -1.67  -1.38 -29.99  -0.82 -29.9 ]\n",
      " [  0.9   -1.67  -0.87 -29.88  -1.53 -29.89  -1.6   -0.89]\n",
      " [  0.77  -1.67  -1.67  -1.67  -1.67  -0.81 -30.31   0.29]\n",
      " [  0.28 -29.88 -29.73 -29.62 -29.63 -29.86 -29.78   0.71]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 3.100e-01  2.000e-02  5.100e-01  2.800e-01  7.600e-01  5.300e-01\n",
      "   5.900e-01  2.800e-01]\n",
      " [ 4.700e-01 -1.670e+00 -2.996e+01 -2.983e+01 -1.670e+00 -3.027e+01\n",
      "  -1.670e+00 -3.050e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.670e+00 -2.962e+01 -2.965e+01 -7.900e-01\n",
      "  -1.660e+00 -2.984e+01]\n",
      " [ 2.400e-01 -2.978e+01 -1.670e+00 -1.670e+00 -2.962e+01 -1.640e+00\n",
      "  -2.988e+01 -2.961e+01]\n",
      " [ 4.900e-01 -7.400e-01 -2.991e+01 -1.670e+00 -2.985e+01 -1.600e+00\n",
      "  -9.300e-01 -2.973e+01]\n",
      " [ 5.800e-01 -1.670e+00 -7.800e-01 -1.670e+00 -1.390e+00 -2.984e+01\n",
      "  -1.270e+00 -6.900e-01]\n",
      " [ 1.600e-01 -2.983e+01 -2.989e+01 -2.963e+01 -2.973e+01 -2.980e+01\n",
      "  -2.962e+01  1.000e-02]\n",
      " [ 4.200e-01 -2.983e+01 -2.962e+01  1.600e-01 -2.986e+01  2.700e-01\n",
      "   5.000e-01  5.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.55   0.7    0.72   0.56   0.62   0.     0.45   0.48]\n",
      " [  0.69  -1.67  -1.67  -1.67  -1.67  -1.67 -29.62 -29.62]\n",
      " [ -1.67 -30.29 -29.63  -0.75 -29.71  -1.66 -29.93 -29.93]\n",
      " [  0.5   -1.67 -29.99 -29.64  -0.71  -1.66 -29.66 -29.66]\n",
      " [  0.39  -0.73  -1.67 -29.75  -0.79 -29.64 -29.97 -29.61]\n",
      " [  0.15 -29.74  -0.69 -30.38  -1.6   -1.51 -29.95 -29.82]\n",
      " [  0.89  -1.67  -1.67  -1.67 -29.67  -1.27  -0.69   0.78]\n",
      " [  0.58 -30.5  -29.66 -29.75 -29.72 -29.66   0.84   0.33]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > < █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < > ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "## alpha 값을 0.1~ 1까지 0.1씩 증가\n",
    "alpha_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "alpha_list_reward = []\n",
    "\n",
    "## alpha_list를 하나씩 돌면서 값측정\n",
    "for i in alpha_list:\n",
    "    ## reward 값을 반환받고, reward값은 음수이므로, 100을 더해서 값이 작을수록 좋은 것임을 나타냄\n",
    "    if __name__ == '__main__':\n",
    "        reward = main(n_episodes=30, alpha =i, gamma=0.4,\n",
    "             epsilon = 0.05, result_screening = False)\n",
    "        reward = reward\n",
    "    ## reward에 하나씩 추가\n",
    "    alpha_list_reward.append(reward)\n",
    "    \n",
    "plt.plot(alpha_list, alpha_list_reward, marker='o', linestyle='-')\n",
    "plt.title('alpha - Reward')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Reward per alpha')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fb412",
   "metadata": {},
   "source": [
    "#### c) 모든 파라미터가 동일하고, gamma에 따른 Reward값 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edfd483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 293 Tot Reward: -2352\n",
      "Episode: 2 - Tot Steps: 464 Tot Reward: -1073\n",
      "Episode: 3 - Tot Steps: 170 Tot Reward: -228\n",
      "Episode: 4 - Tot Steps: 140 Tot Reward: -169\n",
      "Episode: 5 - Tot Steps: 161 Tot Reward: -248\n",
      "Episode: 6 - Tot Steps: 86 Tot Reward: -115\n",
      "Episode: 7 - Tot Steps: 91 Tot Reward: -91\n",
      "Episode: 8 - Tot Steps: 179 Tot Reward: -266\n",
      "Episode: 9 - Tot Steps: 108 Tot Reward: -253\n",
      "Episode: 10 - Tot Steps: 125 Tot Reward: -125\n",
      "Episode: 11 - Tot Steps: 87 Tot Reward: -116\n",
      "Episode: 12 - Tot Steps: 74 Tot Reward: -132\n",
      "Episode: 13 - Tot Steps: 137 Tot Reward: -282\n",
      "Episode: 14 - Tot Steps: 61 Tot Reward: -61\n",
      "Episode: 15 - Tot Steps: 88 Tot Reward: -175\n",
      "Episode: 16 - Tot Steps: 35 Tot Reward: -64\n",
      "Episode: 17 - Tot Steps: 51 Tot Reward: -80\n",
      "Episode: 18 - Tot Steps: 51 Tot Reward: -51\n",
      "Episode: 19 - Tot Steps: 107 Tot Reward: -107\n",
      "Episode: 20 - Tot Steps: 108 Tot Reward: -166\n",
      "Episode: 21 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 22 - Tot Steps: 114 Tot Reward: -172\n",
      "Episode: 23 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 24 - Tot Steps: 63 Tot Reward: -63\n",
      "Episode: 25 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 26 - Tot Steps: 71 Tot Reward: -129\n",
      "Episode: 27 - Tot Steps: 21 Tot Reward: -50\n",
      "Episode: 28 - Tot Steps: 86 Tot Reward: -115\n",
      "Episode: 29 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 30 - Tot Steps: 29 Tot Reward: -87\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.24   0.48   0.93   0.09   0.46   0.04   0.68   0.88]\n",
      " [  0.92  -1.11  -1.11  -1.11  -1.11  -1.11  -1.11 -14.63]\n",
      " [ -1.11  -1.11  -0.57  -0.83  -1.11  -0.74  -1.11 -22.3 ]\n",
      " [  0.74  -1.11 -22.44 -14.88  -0.4  -29.09  -1.11 -14.85]\n",
      " [  0.76  -0.87  -1.11 -28.14 -14.54  -1.11  -0.18 -14.85]\n",
      " [  0.29 -28.12  -0.66  -1.11 -14.82  -1.11 -14.84 -14.87]\n",
      " [  0.07  -1.11 -22.51  -1.11 -14.53  -0.68  -0.92   0.  ]\n",
      " [  0.57  -0.65  -0.26  -0.84  -0.6  -14.48   0.65  -0.18]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 4.500e-01  9.000e-01  1.400e-01  5.800e-01  6.400e-01  1.400e-01\n",
      "   9.000e-01  4.200e-01]\n",
      " [ 1.000e-02 -1.110e+00 -1.110e+00 -1.110e+00 -1.110e+00 -1.110e+00\n",
      "  -1.110e+00 -1.040e+00]\n",
      " [-1.110e+00 -1.110e+00 -4.200e-01 -1.469e+01 -2.245e+01 -8.000e-01\n",
      "  -2.229e+01 -8.800e-01]\n",
      " [ 4.400e-01 -1.110e+00 -1.110e+00 -9.000e-01 -1.456e+01 -1.476e+01\n",
      "  -1.110e+00 -3.400e-01]\n",
      " [ 7.300e-01 -1.455e+01 -1.463e+01 -1.110e+00 -4.900e-01 -1.455e+01\n",
      "  -4.200e-01 -1.495e+01]\n",
      " [ 4.500e-01 -1.110e+00 -8.600e-01 -2.616e+01 -2.000e-01 -1.477e+01\n",
      "  -1.100e+00 -3.200e-01]\n",
      " [ 3.600e-01 -1.110e+00 -1.110e+00 -1.110e+00 -1.110e+00 -3.000e-01\n",
      "  -1.457e+01  4.200e-01]\n",
      " [ 6.400e-01 -1.451e+01 -1.483e+01 -1.448e+01 -1.466e+01 -1.449e+01\n",
      "  -1.446e+01  1.500e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.33   0.1    0.94   0.44   0.51   0.67   0.95   0.03]\n",
      " [  0.77  -1.11 -22.47 -28.14  -1.11 -22.49  -1.11 -14.68]\n",
      " [ -1.11  -1.11  -0.6  -14.97 -14.79  -0.91  -1.11 -14.72]\n",
      " [  0.72 -29.11  -1.11  -0.94 -14.57  -1.11 -14.87 -14.74]\n",
      " [  0.96  -0.94 -14.75  -1.11 -14.83  -1.11  -0.58 -14.55]\n",
      " [  0.    -1.11  -0.73  -1.11  -0.32 -22.45  -1.09   0.2 ]\n",
      " [  0.18 -22.37 -14.58 -26.15 -22.33 -14.47 -14.49   0.12]\n",
      " [  0.18 -14.53   0.33 -14.57 -22.31   0.07   0.37   0.43]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 4.500e-01  4.900e-01  1.900e-01  2.000e-01  9.100e-01  2.300e-01\n",
      "   7.100e-01  2.200e-01]\n",
      " [ 8.700e-01 -1.110e+00 -1.110e+00 -1.110e+00 -1.110e+00 -1.110e+00\n",
      "  -2.818e+01 -1.498e+01]\n",
      " [-1.110e+00 -1.482e+01 -1.472e+01 -8.600e-01 -2.240e+01 -8.700e-01\n",
      "  -2.809e+01 -1.499e+01]\n",
      " [ 4.100e-01 -1.110e+00 -2.234e+01 -1.460e+01 -1.000e-02 -1.110e+00\n",
      "  -1.473e+01 -1.469e+01]\n",
      " [ 9.000e-01 -9.900e-01 -1.110e+00 -2.247e+01 -5.900e-01 -2.224e+01\n",
      "  -1.453e+01 -2.244e+01]\n",
      " [ 6.200e-01 -2.625e+01 -7.400e-01 -2.234e+01 -5.800e-01 -1.110e+00\n",
      "  -1.487e+01 -1.453e+01]\n",
      " [ 7.500e-01 -1.110e+00 -1.110e+00 -1.110e+00 -1.465e+01 -3.300e-01\n",
      "  -9.000e-01  9.700e-01]\n",
      " [ 9.400e-01 -1.491e+01 -1.446e+01 -1.451e+01 -1.460e+01 -1.458e+01\n",
      "  -1.448e+01  3.300e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > v > v █ \n",
      "< v █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 63 Tot Reward: -875\n",
      "Episode: 2 - Tot Steps: 566 Tot Reward: -2219\n",
      "Episode: 3 - Tot Steps: 152 Tot Reward: -210\n",
      "Episode: 4 - Tot Steps: 135 Tot Reward: -193\n",
      "Episode: 5 - Tot Steps: 126 Tot Reward: -213\n",
      "Episode: 6 - Tot Steps: 157 Tot Reward: -215\n",
      "Episode: 7 - Tot Steps: 72 Tot Reward: -101\n",
      "Episode: 8 - Tot Steps: 112 Tot Reward: -344\n",
      "Episode: 9 - Tot Steps: 61 Tot Reward: -61\n",
      "Episode: 10 - Tot Steps: 101 Tot Reward: -130\n",
      "Episode: 11 - Tot Steps: 145 Tot Reward: -232\n",
      "Episode: 12 - Tot Steps: 75 Tot Reward: -75\n",
      "Episode: 13 - Tot Steps: 123 Tot Reward: -239\n",
      "Episode: 14 - Tot Steps: 45 Tot Reward: -74\n",
      "Episode: 15 - Tot Steps: 57 Tot Reward: -115\n",
      "Episode: 16 - Tot Steps: 105 Tot Reward: -163\n",
      "Episode: 17 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 18 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 19 - Tot Steps: 47 Tot Reward: -76\n",
      "Episode: 20 - Tot Steps: 16 Tot Reward: -45\n",
      "Episode: 21 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 22 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 23 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 24 - Tot Steps: 49 Tot Reward: -78\n",
      "Episode: 25 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 26 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 27 - Tot Steps: 84 Tot Reward: -84\n",
      "Episode: 28 - Tot Steps: 46 Tot Reward: -46\n",
      "Episode: 29 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 30 - Tot Steps: 48 Tot Reward: -48\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 3.700e-01  2.800e-01  5.600e-01  8.100e-01  1.000e-02  7.800e-01\n",
      "   4.000e-02  6.900e-01]\n",
      " [ 4.800e-01 -1.250e+00 -1.250e+00 -1.250e+00 -1.250e+00 -1.250e+00\n",
      "  -1.250e+00 -1.458e+01]\n",
      " [-1.250e+00 -1.250e+00 -6.900e-01 -6.500e-01 -1.250e+00 -5.200e-01\n",
      "  -1.250e+00 -1.467e+01]\n",
      " [ 5.700e-01 -1.250e+00 -2.624e+01 -1.494e+01 -7.300e-01 -1.450e+01\n",
      "  -1.250e+00 -1.479e+01]\n",
      " [ 1.900e-01 -1.030e+00 -1.250e+00 -1.482e+01 -1.484e+01 -1.250e+00\n",
      "  -2.500e-01 -1.445e+01]\n",
      " [ 6.000e-01 -2.629e+01 -7.200e-01 -1.250e+00 -1.483e+01 -1.240e+00\n",
      "  -1.447e+01  1.700e-01]\n",
      " [ 8.500e-01 -1.250e+00 -2.238e+01 -1.250e+00 -2.238e+01 -9.400e-01\n",
      "  -1.170e+00  1.900e-01]\n",
      " [ 4.700e-01 -6.800e-01 -1.050e+00 -9.300e-01 -2.300e-01 -1.478e+01\n",
      "  -1.900e-01  1.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 4.000e-01  3.600e-01  7.300e-01  8.600e-01  2.600e-01  9.300e-01\n",
      "   5.400e-01  9.000e-02]\n",
      " [ 3.800e-01 -1.250e+00 -1.250e+00 -1.250e+00 -1.250e+00 -1.250e+00\n",
      "  -1.250e+00 -1.010e+00]\n",
      " [-1.250e+00 -1.250e+00 -6.700e-01 -1.492e+01 -1.499e+01 -6.100e-01\n",
      "  -2.246e+01 -8.400e-01]\n",
      " [ 9.600e-01 -1.250e+00 -1.250e+00 -6.500e-01 -1.476e+01 -2.227e+01\n",
      "  -1.250e+00  3.000e-02]\n",
      " [ 6.400e-01 -1.499e+01 -2.248e+01 -1.250e+00 -7.500e-01 -1.475e+01\n",
      "  -7.100e-01  1.600e-01]\n",
      " [ 8.800e-01 -1.250e+00 -7.200e-01 -2.250e+01 -1.800e-01 -1.450e+01\n",
      "  -1.170e+00 -3.400e-01]\n",
      " [ 5.400e-01 -1.250e+00 -1.250e+00 -1.250e+00 -1.250e+00 -7.500e-01\n",
      "  -2.626e+01  5.500e-01]\n",
      " [ 7.900e-01 -1.452e+01 -1.485e+01 -2.229e+01 -1.444e+01 -1.488e+01\n",
      "  -1.442e+01  1.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.28   0.58   0.07   0.31   0.56   0.43   0.68   0.87]\n",
      " [  0.9   -1.25 -14.44 -22.25  -1.25 -22.46  -1.25 -14.77]\n",
      " [ -1.25  -1.25  -0.77 -14.99 -14.61  -0.26  -1.25 -14.42]\n",
      " [  0.54 -28.2   -1.25  -0.17 -14.83  -1.25 -14.72 -14.6 ]\n",
      " [  0.44  -0.95 -22.25  -1.25 -14.63  -1.25  -0.55 -14.73]\n",
      " [  0.13  -1.25  -0.79  -1.25  -0.64 -22.4   -1.17  -0.25]\n",
      " [  0.36 -22.26 -22.47 -28.16 -14.64 -14.63 -22.4    0.74]\n",
      " [  0.71 -14.94 -14.94 -14.86   0.49 -14.5  -14.5    0.1 ]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.47   0.41   0.82   0.72   0.59   0.48   0.48   0.59]\n",
      " [  0.47  -1.25  -1.25  -1.25  -1.25  -1.25 -26.31 -14.65]\n",
      " [ -1.25 -22.49 -14.56  -0.09 -14.54  -0.65 -22.28 -14.6 ]\n",
      " [  0.2   -1.25 -22.31 -14.77  -0.37  -1.25 -14.72   0.03]\n",
      " [  0.25  -0.97  -1.25 -26.2   -0.8  -26.15 -14.72 -14.79]\n",
      " [  0.13 -14.7   -0.38 -14.47  -0.08  -1.23 -14.73 -14.76]\n",
      " [  0.93  -1.25  -1.25  -1.25 -22.34  -0.77  -0.85   0.74]\n",
      " [  0.87 -14.56 -14.61 -14.66 -14.59 -14.71 -14.83   0.85]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 78 Tot Reward: -1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 253 Tot Reward: -1587\n",
      "Episode: 3 - Tot Steps: 203 Tot Reward: -551\n",
      "Episode: 4 - Tot Steps: 256 Tot Reward: -401\n",
      "Episode: 5 - Tot Steps: 99 Tot Reward: -215\n",
      "Episode: 6 - Tot Steps: 79 Tot Reward: -137\n",
      "Episode: 7 - Tot Steps: 92 Tot Reward: -179\n",
      "Episode: 8 - Tot Steps: 75 Tot Reward: -133\n",
      "Episode: 9 - Tot Steps: 165 Tot Reward: -194\n",
      "Episode: 10 - Tot Steps: 69 Tot Reward: -98\n",
      "Episode: 11 - Tot Steps: 220 Tot Reward: -307\n",
      "Episode: 12 - Tot Steps: 79 Tot Reward: -137\n",
      "Episode: 13 - Tot Steps: 58 Tot Reward: -58\n",
      "Episode: 14 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 15 - Tot Steps: 50 Tot Reward: -50\n",
      "Episode: 16 - Tot Steps: 55 Tot Reward: -55\n",
      "Episode: 17 - Tot Steps: 55 Tot Reward: -84\n",
      "Episode: 18 - Tot Steps: 52 Tot Reward: -52\n",
      "Episode: 19 - Tot Steps: 56 Tot Reward: -85\n",
      "Episode: 20 - Tot Steps: 25 Tot Reward: -54\n",
      "Episode: 21 - Tot Steps: 51 Tot Reward: -51\n",
      "Episode: 22 - Tot Steps: 21 Tot Reward: -50\n",
      "Episode: 23 - Tot Steps: 52 Tot Reward: -81\n",
      "Episode: 24 - Tot Steps: 55 Tot Reward: -84\n",
      "Episode: 25 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 26 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 27 - Tot Steps: 51 Tot Reward: -51\n",
      "Episode: 28 - Tot Steps: 29 Tot Reward: -58\n",
      "Episode: 29 - Tot Steps: 49 Tot Reward: -78\n",
      "Episode: 30 - Tot Steps: 17 Tot Reward: -17\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 1.800e-01  3.300e-01  8.500e-01  5.400e-01  6.800e-01  3.900e-01\n",
      "   6.600e-01  4.700e-01]\n",
      " [ 2.500e-01 -1.430e+00 -1.430e+00 -1.430e+00 -1.430e+00 -1.430e+00\n",
      "  -1.430e+00 -1.487e+01]\n",
      " [-1.430e+00 -1.430e+00 -1.130e+00 -8.300e-01 -1.430e+00 -6.600e-01\n",
      "  -1.430e+00 -1.489e+01]\n",
      " [ 6.400e-01 -1.430e+00 -2.617e+01 -2.223e+01 -2.000e-02 -2.231e+01\n",
      "  -1.430e+00 -1.470e+01]\n",
      " [ 7.700e-01 -1.070e+00 -1.430e+00 -1.456e+01 -1.463e+01 -1.420e+00\n",
      "  -1.090e+00 -1.451e+01]\n",
      " [ 3.500e-01 -2.631e+01 -1.300e-01 -1.430e+00 -1.445e+01 -1.390e+00\n",
      "  -2.626e+01 -1.480e+01]\n",
      " [ 2.800e-01 -1.430e+00 -1.474e+01 -1.430e+00 -1.458e+01 -6.300e-01\n",
      "  -8.400e-01  7.500e-01]\n",
      " [ 5.100e-01 -5.800e-01 -4.000e-02 -6.300e-01 -1.100e-01 -1.456e+01\n",
      "   1.000e-02  1.400e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.17   0.3    0.65   0.36   0.9    0.34   0.84   0.9 ]\n",
      " [  0.29  -1.43  -1.43  -1.43  -1.43  -1.43  -1.43  -1.11]\n",
      " [ -1.43  -1.43  -1.24 -14.69 -14.71  -0.9  -26.16  -0.67]\n",
      " [  0.91  -1.43  -1.43  -0.84 -14.59 -14.61  -1.43  -0.28]\n",
      " [  0.94 -14.57 -22.46  -1.43  -1.1  -26.3   -0.75 -14.97]\n",
      " [  0.95  -1.43  -0.7  -14.65  -0.87 -22.33  -1.32  -0.05]\n",
      " [  0.07  -1.43  -1.43  -1.43  -1.43  -0.33 -22.48   0.54]\n",
      " [  0.72 -14.72 -14.6  -14.44 -14.62 -14.79 -14.7    0.72]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 5.300e-01  6.400e-01  5.500e-01  4.100e-01  4.200e-01  3.200e-01\n",
      "   9.200e-01  2.400e-01]\n",
      " [ 5.200e-01 -1.430e+00 -2.262e+01 -2.234e+01 -1.430e+00 -1.451e+01\n",
      "  -1.430e+00 -1.467e+01]\n",
      " [-1.430e+00 -1.430e+00 -1.070e+00 -1.449e+01 -1.479e+01 -4.500e-01\n",
      "  -1.430e+00 -1.467e+01]\n",
      " [ 1.900e-01 -2.630e+01 -1.430e+00 -3.800e-01 -1.491e+01 -1.420e+00\n",
      "  -2.620e+01 -1.469e+01]\n",
      " [ 4.500e-01 -9.200e-01 -2.227e+01 -1.430e+00 -1.459e+01 -1.410e+00\n",
      "  -1.010e+00 -1.471e+01]\n",
      " [ 1.000e-01 -1.430e+00 -3.000e-02 -1.430e+00 -5.900e-01 -1.454e+01\n",
      "  -1.230e+00  3.700e-01]\n",
      " [ 9.100e-01 -2.227e+01 -1.467e+01 -2.232e+01 -1.448e+01 -1.452e+01\n",
      "  -1.459e+01  6.300e-01]\n",
      " [ 1.000e-02 -1.450e+01  1.700e-01 -1.447e+01 -1.444e+01  2.300e-01\n",
      "  -1.448e+01  4.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 5.900e-01  9.500e-01  2.600e-01  6.100e-01  5.300e-01  6.100e-01\n",
      "   5.900e-01  6.100e-01]\n",
      " [ 9.000e-01 -1.430e+00 -1.430e+00 -1.430e+00 -1.430e+00 -1.430e+00\n",
      "  -2.622e+01 -1.494e+01]\n",
      " [-1.430e+00 -2.924e+01 -1.491e+01 -4.400e-01 -2.234e+01 -9.100e-01\n",
      "  -2.223e+01 -1.464e+01]\n",
      " [ 5.200e-01 -1.430e+00 -2.619e+01 -1.491e+01 -1.600e-01 -1.420e+00\n",
      "  -1.457e+01 -1.463e+01]\n",
      " [ 1.000e-01 -1.110e+00 -1.430e+00 -2.239e+01 -9.100e-01 -2.239e+01\n",
      "  -1.467e+01 -1.458e+01]\n",
      " [ 5.700e-01 -1.465e+01  1.000e-02 -2.616e+01 -6.700e-01 -1.370e+00\n",
      "  -1.468e+01 -1.465e+01]\n",
      " [ 2.200e-01 -1.430e+00 -1.430e+00 -1.430e+00 -2.235e+01 -6.900e-01\n",
      "  -7.700e-01  5.600e-01]\n",
      " [ 5.000e-01 -1.458e+01 -1.443e+01 -1.467e+01 -1.450e+01 -1.464e+01\n",
      "   8.000e-02  3.600e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "^ ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 407 Tot Reward: -2901\n",
      "Episode: 2 - Tot Steps: 128 Tot Reward: -186\n",
      "Episode: 3 - Tot Steps: 121 Tot Reward: -179\n",
      "Episode: 4 - Tot Steps: 128 Tot Reward: -128\n",
      "Episode: 5 - Tot Steps: 82 Tot Reward: -111\n",
      "Episode: 6 - Tot Steps: 102 Tot Reward: -102\n",
      "Episode: 7 - Tot Steps: 140 Tot Reward: -198\n",
      "Episode: 8 - Tot Steps: 51 Tot Reward: -80\n",
      "Episode: 9 - Tot Steps: 53 Tot Reward: -53\n",
      "Episode: 10 - Tot Steps: 98 Tot Reward: -98\n",
      "Episode: 11 - Tot Steps: 59 Tot Reward: -88\n",
      "Episode: 12 - Tot Steps: 119 Tot Reward: -177\n",
      "Episode: 13 - Tot Steps: 64 Tot Reward: -122\n",
      "Episode: 14 - Tot Steps: 53 Tot Reward: -82\n",
      "Episode: 15 - Tot Steps: 61 Tot Reward: -90\n",
      "Episode: 16 - Tot Steps: 52 Tot Reward: -110\n",
      "Episode: 17 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 18 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 19 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 20 - Tot Steps: 44 Tot Reward: -73\n",
      "Episode: 21 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 22 - Tot Steps: 89 Tot Reward: -89\n",
      "Episode: 23 - Tot Steps: 34 Tot Reward: -34\n",
      "Episode: 24 - Tot Steps: 67 Tot Reward: -125\n",
      "Episode: 25 - Tot Steps: 59 Tot Reward: -88\n",
      "Episode: 26 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 27 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 28 - Tot Steps: 63 Tot Reward: -266\n",
      "Episode: 29 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 30 - Tot Steps: 18 Tot Reward: -18\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 3.700e-01  6.000e-02  8.800e-01  4.200e-01  3.200e-01  9.300e-01\n",
      "   3.300e-01  1.000e-02]\n",
      " [ 1.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.455e+01]\n",
      " [-1.670e+00 -1.670e+00 -5.000e-01 -1.340e+00 -1.670e+00 -6.500e-01\n",
      "  -1.660e+00 -1.475e+01]\n",
      " [ 8.500e-01 -1.670e+00 -1.478e+01 -1.481e+01 -4.200e-01 -2.612e+01\n",
      "  -1.660e+00 -1.451e+01]\n",
      " [ 4.900e-01 -1.260e+00 -1.670e+00 -1.476e+01 -1.488e+01 -1.630e+00\n",
      "   3.000e-02 -1.456e+01]\n",
      " [ 9.500e-01 -2.231e+01 -8.300e-01 -1.670e+00 -1.475e+01 -1.570e+00\n",
      "  -1.479e+01  1.500e-01]\n",
      " [ 9.600e-01 -1.670e+00 -2.616e+01 -1.670e+00 -1.449e+01 -7.800e-01\n",
      "  -7.000e-01  2.300e-01]\n",
      " [ 6.900e-01 -1.540e+00 -3.100e-01  6.000e-02 -1.340e+00 -1.471e+01\n",
      "  -3.900e-01  1.000e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 2.000e-02  3.500e-01  9.900e-01  7.400e-01  0.000e+00  2.600e-01\n",
      "   7.800e-01  5.000e-01]\n",
      " [ 7.100e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -8.800e-01]\n",
      " [-1.670e+00 -1.670e+00 -6.700e-01 -1.457e+01 -2.640e+01 -8.100e-01\n",
      "  -1.487e+01 -2.100e-01]\n",
      " [ 0.000e+00 -1.670e+00 -1.670e+00 -1.360e+00 -1.456e+01 -1.480e+01\n",
      "  -1.660e+00 -4.300e-01]\n",
      " [ 2.200e-01 -1.475e+01 -1.445e+01 -1.670e+00 -9.600e-01 -1.486e+01\n",
      "  -3.300e-01 -1.436e+01]\n",
      " [ 5.900e-01 -1.670e+00 -3.100e-01 -2.234e+01 -1.000e-02 -2.224e+01\n",
      "  -1.450e+00  8.100e-01]\n",
      " [ 4.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -2.000e-01\n",
      "  -1.467e+01  7.700e-01]\n",
      " [ 5.600e-01 -1.493e+01 -1.458e+01 -1.467e+01 -1.444e+01 -1.486e+01\n",
      "  -1.478e+01 -1.480e+01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 6.100e-01  3.800e-01  1.000e-02  7.000e-01  8.900e-01  7.300e-01\n",
      "   3.300e-01  7.600e-01]\n",
      " [ 1.300e-01 -1.670e+00 -1.498e+01 -2.843e+01 -1.670e+00 -1.449e+01\n",
      "  -1.660e+00 -1.460e+01]\n",
      " [-1.670e+00 -1.670e+00 -8.300e-01 -1.454e+01 -1.451e+01 -7.200e-01\n",
      "  -1.660e+00 -1.461e+01]\n",
      " [ 5.900e-01 -2.816e+01 -1.670e+00 -1.270e+00 -1.471e+01 -1.640e+00\n",
      "  -1.473e+01 -1.465e+01]\n",
      " [ 7.300e-01 -9.800e-01 -1.447e+01 -1.670e+00 -1.441e+01 -1.600e+00\n",
      "  -4.000e-02  3.500e-01]\n",
      " [ 8.900e-01 -1.670e+00 -7.000e-01 -1.670e+00 -2.900e-01 -2.240e+01\n",
      "  -1.260e+00  1.700e-01]\n",
      " [ 6.600e-01 -2.944e+01 -1.444e+01 -2.221e+01 -2.244e+01 -1.481e+01\n",
      "  -1.444e+01  8.900e-01]\n",
      " [ 7.400e-01 -1.464e+01 -1.447e+01  3.200e-01 -2.239e+01  4.700e-01\n",
      "  -1.450e+01 -1.434e+01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 8.800e-01  3.500e-01  9.600e-01  6.800e-01  2.700e-01  1.400e-01\n",
      "   3.900e-01  5.100e-01]\n",
      " [ 6.500e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -2.241e+01 -1.469e+01]\n",
      " [-1.670e+00 -2.612e+01 -1.475e+01 -1.480e+00 -1.456e+01 -5.000e-02\n",
      "  -1.438e+01 -1.441e+01]\n",
      " [ 9.000e-02 -1.670e+00 -2.938e+01 -1.450e+01  1.700e-01 -1.640e+00\n",
      "  -1.463e+01 -1.471e+01]\n",
      " [ 3.900e-01 -1.000e+00 -1.670e+00 -2.239e+01 -3.400e-01 -1.493e+01\n",
      "  -1.480e+01  3.300e-01]\n",
      " [ 5.500e-01 -1.456e+01 -9.700e-01 -1.453e+01 -5.800e-01 -1.500e+00\n",
      "  -1.449e+01  3.500e-01]\n",
      " [ 2.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.433e+01 -3.200e-01\n",
      "  -6.400e-01  1.000e-02]\n",
      " [ 7.800e-01 -1.467e+01 -1.438e+01 -2.240e+01 -1.458e+01 -1.468e+01\n",
      "  -1.467e+01  1.400e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ ^ v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 132 Tot Reward: -1379\n",
      "Episode: 2 - Tot Steps: 343 Tot Reward: -1358\n",
      "Episode: 3 - Tot Steps: 139 Tot Reward: -226\n",
      "Episode: 4 - Tot Steps: 134 Tot Reward: -134\n",
      "Episode: 5 - Tot Steps: 74 Tot Reward: -132\n",
      "Episode: 6 - Tot Steps: 24 Tot Reward: -53\n",
      "Episode: 7 - Tot Steps: 57 Tot Reward: -86\n",
      "Episode: 8 - Tot Steps: 119 Tot Reward: -206\n",
      "Episode: 9 - Tot Steps: 128 Tot Reward: -215\n",
      "Episode: 10 - Tot Steps: 82 Tot Reward: -111\n",
      "Episode: 11 - Tot Steps: 86 Tot Reward: -115\n",
      "Episode: 12 - Tot Steps: 31 Tot Reward: -60\n",
      "Episode: 13 - Tot Steps: 68 Tot Reward: -126\n",
      "Episode: 14 - Tot Steps: 118 Tot Reward: -292\n",
      "Episode: 15 - Tot Steps: 71 Tot Reward: -71\n",
      "Episode: 16 - Tot Steps: 36 Tot Reward: -36\n",
      "Episode: 17 - Tot Steps: 58 Tot Reward: -87\n",
      "Episode: 18 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 19 - Tot Steps: 61 Tot Reward: -264\n",
      "Episode: 20 - Tot Steps: 44 Tot Reward: -44\n",
      "Episode: 21 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 22 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 23 - Tot Steps: 31 Tot Reward: -89\n",
      "Episode: 24 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 25 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 26 - Tot Steps: 29 Tot Reward: -29\n",
      "Episode: 27 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 28 - Tot Steps: 97 Tot Reward: -184\n",
      "Episode: 29 - Tot Steps: 31 Tot Reward: -60\n",
      "Episode: 30 - Tot Steps: 17 Tot Reward: -17\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.59   0.1    0.71   0.04   0.93   0.33   0.87   0.42]\n",
      " [  1.    -2.    -2.    -2.    -2.    -2.    -1.99   0.35]\n",
      " [ -2.    -2.    -1.06  -1.09  -2.    -0.29  -1.98 -14.37]\n",
      " [  0.18  -2.   -14.79 -14.46  -1.35 -14.83  -1.96 -14.29]\n",
      " [  0.34  -1.1   -2.   -14.73 -14.52  -1.84  -0.74 -14.64]\n",
      " [  0.54 -26.18  -1.09  -2.   -22.2   -1.67 -14.77 -14.31]\n",
      " [  0.88  -2.   -14.61  -2.   -22.15   0.04  -0.95   0.89]\n",
      " [  0.13  -1.53  -1.8   -0.03  -0.16   0.51   0.03  -0.14]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 1.300e-01  2.000e-02  8.700e-01  8.500e-01  8.300e-01  2.300e-01\n",
      "   2.100e-01  4.200e-01]\n",
      " [ 8.100e-01 -2.000e+00 -2.000e+00 -2.000e+00 -2.000e+00 -2.000e+00\n",
      "  -1.990e+00 -2.900e-01]\n",
      " [-2.000e+00 -2.000e+00 -7.000e-01 -1.448e+01 -2.637e+01 -9.600e-01\n",
      "  -2.231e+01 -1.170e+00]\n",
      " [ 3.100e-01 -2.000e+00 -2.000e+00 -4.000e-01 -1.472e+01 -2.644e+01\n",
      "  -1.950e+00 -1.100e-01]\n",
      " [ 1.400e-01 -1.491e+01 -2.207e+01 -2.000e+00 -3.900e-01 -1.469e+01\n",
      "  -1.900e-01 -1.493e+01]\n",
      " [ 4.300e-01 -2.000e+00 -4.400e-01 -2.815e+01 -1.420e+00 -2.226e+01\n",
      "  -1.530e+00 -6.800e-01]\n",
      " [ 6.100e-01 -2.000e+00 -2.000e+00 -2.000e+00 -2.000e+00 -9.000e-02\n",
      "  -2.235e+01  9.700e-01]\n",
      " [ 7.800e-01 -1.488e+01 -1.477e+01 -1.451e+01 -1.460e+01  2.600e-01\n",
      "   5.400e-01  0.000e+00]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 8.000e-01  7.700e-01  3.600e-01  9.300e-01  4.600e-01  1.900e-01\n",
      "   4.600e-01  1.200e-01]\n",
      " [ 3.100e-01 -2.000e+00 -2.225e+01 -2.225e+01 -2.000e+00 -2.232e+01\n",
      "  -1.990e+00 -1.453e+01]\n",
      " [-2.000e+00 -2.000e+00 -1.090e+00 -1.451e+01 -2.230e+01 -3.900e-01\n",
      "  -1.980e+00 -1.443e+01]\n",
      " [ 9.800e-01 -1.477e+01 -2.000e+00 -2.900e-01 -1.448e+01 -1.910e+00\n",
      "  -2.225e+01 -1.432e+01]\n",
      " [ 4.900e-01 -8.600e-01 -2.232e+01 -2.000e+00 -1.500e+01 -1.810e+00\n",
      "  -7.900e-01 -1.474e+01]\n",
      " [ 1.000e-02 -2.000e+00 -1.180e+00 -2.000e+00 -1.020e+00 -1.476e+01\n",
      "  -1.260e+00 -9.000e-02]\n",
      " [ 9.700e-01 -2.838e+01 -2.861e+01 -1.449e+01 -1.487e+01 -1.475e+01\n",
      "  -1.466e+01  5.900e-01]\n",
      " [ 7.900e-01 -1.474e+01 -1.491e+01 -1.429e+01  1.000e-01  1.200e-01\n",
      "  -1.434e+01 -1.465e+01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 5.700e-01  3.800e-01  2.600e-01  2.000e-02  6.700e-01  1.600e-01\n",
      "   4.000e-01  5.500e-01]\n",
      " [ 6.900e-01 -2.000e+00 -2.000e+00 -2.000e+00 -2.000e+00 -1.990e+00\n",
      "  -1.488e+01 -1.439e+01]\n",
      " [-2.000e+00 -2.616e+01 -1.476e+01 -1.490e+00 -1.436e+01 -1.080e+00\n",
      "  -2.239e+01 -1.486e+01]\n",
      " [ 6.300e-01 -2.000e+00 -1.486e+01 -1.499e+01 -1.260e+00 -1.930e+00\n",
      "  -1.427e+01 -1.432e+01]\n",
      " [ 1.700e-01 -9.600e-01 -2.000e+00 -2.239e+01 -1.000e+00 -1.445e+01\n",
      "  -1.482e+01 -1.434e+01]\n",
      " [ 3.700e-01 -1.435e+01 -8.300e-01 -2.633e+01 -8.500e-01 -1.630e+00\n",
      "  -2.210e+01 -1.464e+01]\n",
      " [ 2.300e-01 -2.000e+00 -2.000e+00 -2.000e+00 -1.447e+01 -3.100e-01\n",
      "  -5.200e-01  9.000e-01]\n",
      " [ 7.800e-01 -2.259e+01 -1.441e+01 -1.439e+01  2.600e-01 -1.452e+01\n",
      "  -1.460e+01 -1.467e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "step 15\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      ". . █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . 🏁\n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "Finish!\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 169 Tot Reward: -1213\n",
      "Episode: 2 - Tot Steps: 206 Tot Reward: -989\n",
      "Episode: 3 - Tot Steps: 105 Tot Reward: -308\n",
      "Episode: 4 - Tot Steps: 123 Tot Reward: -152\n",
      "Episode: 5 - Tot Steps: 97 Tot Reward: -126\n",
      "Episode: 6 - Tot Steps: 75 Tot Reward: -220\n",
      "Episode: 7 - Tot Steps: 27 Tot Reward: -85\n",
      "Episode: 8 - Tot Steps: 51 Tot Reward: -138\n",
      "Episode: 9 - Tot Steps: 42 Tot Reward: -42\n",
      "Episode: 10 - Tot Steps: 134 Tot Reward: -366\n",
      "Episode: 11 - Tot Steps: 16 Tot Reward: -132\n",
      "Episode: 12 - Tot Steps: 55 Tot Reward: -142\n",
      "Episode: 13 - Tot Steps: 157 Tot Reward: -302\n",
      "Episode: 14 - Tot Steps: 39 Tot Reward: -39\n",
      "Episode: 15 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 16 - Tot Steps: 108 Tot Reward: -282\n",
      "Episode: 17 - Tot Steps: 38 Tot Reward: -38\n",
      "Episode: 18 - Tot Steps: 34 Tot Reward: -34\n",
      "Episode: 19 - Tot Steps: 41 Tot Reward: -99\n",
      "Episode: 20 - Tot Steps: 39 Tot Reward: -39\n",
      "Episode: 21 - Tot Steps: 42 Tot Reward: -71\n",
      "Episode: 22 - Tot Steps: 59 Tot Reward: -88\n",
      "Episode: 23 - Tot Steps: 74 Tot Reward: -132\n",
      "Episode: 24 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 25 - Tot Steps: 33 Tot Reward: -33\n",
      "Episode: 26 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 27 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 28 - Tot Steps: 66 Tot Reward: -66\n",
      "Episode: 29 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 30 - Tot Steps: 41 Tot Reward: -41\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 7.100e-01  2.100e-01  5.100e-01  3.200e-01  9.300e-01  9.500e-01\n",
      "   3.000e-02  2.700e-01]\n",
      " [ 8.000e-01 -2.500e+00 -2.490e+00 -2.490e+00 -2.480e+00 -2.470e+00\n",
      "  -2.450e+00 -1.456e+01]\n",
      " [-2.500e+00 -2.500e+00 -1.400e-01 -1.200e-01 -2.480e+00 -9.300e-01\n",
      "  -2.460e+00 -1.456e+01]\n",
      " [ 6.000e-02 -2.500e+00 -2.211e+01  7.000e-02  2.000e-02 -1.467e+01\n",
      "  -2.390e+00  2.000e-02]\n",
      " [ 4.200e-01 -1.220e+00 -2.500e+00 -1.448e+01 -1.464e+01 -2.220e+00\n",
      "  -1.450e+00  0.000e+00]\n",
      " [ 9.500e-01 -1.437e+01 -1.180e+00 -2.500e+00 -1.451e+01 -1.800e+00\n",
      "  -2.623e+01  2.900e-01]\n",
      " [ 3.100e-01 -2.500e+00 -2.258e+01 -2.500e+00 -2.241e+01 -1.150e+00\n",
      "  -1.450e+00  6.800e-01]\n",
      " [ 4.000e-02 -1.880e+00 -3.400e-01 -1.240e+00 -1.140e+00 -1.424e+01\n",
      "  -5.100e-01  1.500e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 9.600e-01  8.200e-01  4.600e-01  1.400e-01  7.300e-01  4.400e-01\n",
      "   1.600e-01  2.000e-02]\n",
      " [ 4.200e-01 -2.500e+00 -2.490e+00 -2.490e+00 -2.490e+00 -2.470e+00\n",
      "  -2.470e+00 -1.200e+00]\n",
      " [-2.500e+00 -2.500e+00 -1.310e+00  5.000e-02 -2.234e+01 -2.300e-01\n",
      "  -1.479e+01 -1.070e+00]\n",
      " [ 3.500e-01 -2.500e+00 -2.500e+00 -4.600e-01 -1.439e+01 -1.430e+01\n",
      "  -2.350e+00 -2.900e-01]\n",
      " [ 9.000e-02 -1.451e+01 -2.223e+01 -2.500e+00 -7.000e-01 -1.448e+01\n",
      "  -1.210e+00 -1.445e+01]\n",
      " [ 8.000e-02 -2.500e+00 -7.300e-01 -2.240e+01 -1.290e+00 -1.484e+01\n",
      "  -1.590e+00 -8.000e-02]\n",
      " [ 7.400e-01 -2.500e+00 -2.500e+00 -2.500e+00 -2.500e+00 -6.200e-01\n",
      "  -1.455e+01  4.900e-01]\n",
      " [ 1.600e-01 -1.499e+01 -1.450e+01 -1.455e+01 -1.478e+01 -1.474e+01\n",
      "  -1.475e+01  2.700e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.32   0.33   0.14   0.97   0.63   0.06   0.46   0.25]\n",
      " [  0.24  -2.49 -14.71 -14.69  -2.48 -28.12  -2.44 -14.56]\n",
      " [ -2.5   -2.5   -1.29 -14.76 -14.59  -1.23  -2.41 -14.28]\n",
      " [  0.18 -26.17  -2.5    0.07 -14.42  -2.24 -14.76 -14.7 ]\n",
      " [  0.08  -1.7  -22.41  -2.5  -15.33  -2.07  -1.31 -14.63]\n",
      " [  0.83  -2.5   -1.5   -2.5   -1.45 -26.14  -1.31   0.23]\n",
      " [  0.17 -26.45 -14.6  -22.08 -14.51 -14.7  -22.32   0.81]\n",
      " [  0.5  -14.36 -14.5  -14.22   0.1  -14.3  -14.53 -14.24]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 4.800e-01  3.700e-01  3.000e-02  1.500e-01  9.100e-01  6.500e-01\n",
      "   6.000e-02  8.700e-01]\n",
      " [ 1.100e-01 -2.490e+00 -2.490e+00 -2.490e+00 -2.480e+00 -2.470e+00\n",
      "  -2.207e+01 -1.424e+01]\n",
      " [-2.500e+00 -2.616e+01 -1.436e+01 -3.600e-01 -1.446e+01 -1.060e+00\n",
      "  -2.222e+01  1.000e-02]\n",
      " [ 1.000e-02 -2.500e+00 -1.478e+01 -1.448e+01 -7.000e-01 -2.250e+00\n",
      "  -1.492e+01 -2.205e+01]\n",
      " [ 9.900e-01 -2.000e-01 -2.500e+00 -2.227e+01 -3.300e-01 -2.650e+01\n",
      "  -1.457e+01 -1.463e+01]\n",
      " [ 7.300e-01 -2.248e+01 -1.380e+00 -2.827e+01 -1.600e+00 -1.790e+00\n",
      "  -1.463e+01 -1.424e+01]\n",
      " [ 9.200e-01 -2.500e+00 -2.500e+00 -2.500e+00 -2.232e+01 -5.600e-01\n",
      "  -5.200e-01  5.000e-01]\n",
      " [ 8.700e-01 -1.468e+01 -1.492e+01 -1.480e+01 -1.433e+01 -1.457e+01\n",
      "  -1.452e+01  4.400e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > ^ > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ ^ v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 121 Tot Reward: -1223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 379 Tot Reward: -1568\n",
      "Episode: 3 - Tot Steps: 63 Tot Reward: -121\n",
      "Episode: 4 - Tot Steps: 68 Tot Reward: -184\n",
      "Episode: 5 - Tot Steps: 100 Tot Reward: -129\n",
      "Episode: 6 - Tot Steps: 64 Tot Reward: -93\n",
      "Episode: 7 - Tot Steps: 51 Tot Reward: -80\n",
      "Episode: 8 - Tot Steps: 191 Tot Reward: -365\n",
      "Episode: 9 - Tot Steps: 48 Tot Reward: -48\n",
      "Episode: 10 - Tot Steps: 60 Tot Reward: -60\n",
      "Episode: 11 - Tot Steps: 68 Tot Reward: -126\n",
      "Episode: 12 - Tot Steps: 46 Tot Reward: -46\n",
      "Episode: 13 - Tot Steps: 37 Tot Reward: -37\n",
      "Episode: 14 - Tot Steps: 83 Tot Reward: -286\n",
      "Episode: 15 - Tot Steps: 53 Tot Reward: -140\n",
      "Episode: 16 - Tot Steps: 19 Tot Reward: -48\n",
      "Episode: 17 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 18 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 19 - Tot Steps: 32 Tot Reward: -32\n",
      "Episode: 20 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 21 - Tot Steps: 114 Tot Reward: -172\n",
      "Episode: 22 - Tot Steps: 39 Tot Reward: -68\n",
      "Episode: 23 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 24 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 25 - Tot Steps: 49 Tot Reward: -78\n",
      "Episode: 26 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 27 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 28 - Tot Steps: 17 Tot Reward: -17\n",
      "Episode: 29 - Tot Steps: 25 Tot Reward: -83\n",
      "Episode: 30 - Tot Steps: 17 Tot Reward: -17\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 3.900e-01  1.300e-01  6.000e-01  2.000e-02  1.300e-01  2.000e-01\n",
      "   3.300e-01  5.300e-01]\n",
      " [ 4.400e-01 -3.280e+00 -3.270e+00 -3.250e+00 -3.210e+00 -3.190e+00\n",
      "  -3.120e+00 -1.480e+01]\n",
      " [-3.310e+00 -3.300e+00 -1.120e+00 -2.560e+00 -3.220e+00 -4.900e-01\n",
      "  -3.060e+00 -1.437e+01]\n",
      " [ 9.900e-01 -3.300e+00 -2.214e+01 -1.446e+01 -4.400e-01 -1.461e+01\n",
      "  -2.930e+00 -1.434e+01]\n",
      " [ 4.700e-01 -8.600e-01 -3.300e+00 -1.463e+01 -1.474e+01 -2.320e+00\n",
      "  -1.070e+00 -1.430e+01]\n",
      " [ 7.900e-01 -2.236e+01 -1.710e+00 -3.290e+00  1.200e-01 -2.190e+00\n",
      "  -1.456e+01  4.300e-01]\n",
      " [ 8.300e-01 -3.290e+00 -1.458e+01 -3.300e+00 -2.206e+01  2.000e-02\n",
      "  -6.300e-01  8.700e-01]\n",
      " [ 4.600e-01 -1.610e+00 -1.570e+00 -8.100e-01 -1.570e+00  6.000e-01\n",
      "   1.200e-01  1.400e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.75   0.35   0.86   0.97   0.92   0.     0.87   0.6 ]\n",
      " [  0.05  -3.29  -3.27  -3.26  -3.21  -3.18  -3.11  -2.57]\n",
      " [ -3.31  -3.3   -0.78 -14.55 -14.92  -1.13 -22.34  -0.06]\n",
      " [  0.05  -3.3   -3.3   -1.24 -14.64 -22.22  -2.83  -0.17]\n",
      " [  0.97 -14.44 -14.92  -3.3   -1.52 -22.21  -1.7  -14.91]\n",
      " [  0.42  -3.29  -1.26 -22.67  -0.29 -14.69  -1.61   0.07]\n",
      " [  0.69  -3.29  -3.29  -3.29  -3.3   -0.89 -14.54   0.94]\n",
      " [  0.86 -14.71 -14.51 -14.43 -14.76 -14.69   0.08   0.5 ]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.48   0.07   0.43   0.44   0.76   0.38   0.16   0.49]\n",
      " [  0.08  -3.28 -26.33 -29.96  -3.22 -22.09  -3.09 -14.73]\n",
      " [ -3.3   -3.3   -1.96 -14.4  -14.66  -0.28  -2.98 -14.55]\n",
      " [  0.18 -22.46  -3.3   -1.18 -14.46  -2.62 -28.14 -21.83]\n",
      " [  0.98  -0.39 -28.27  -3.29 -14.9   -2.31  -1.06 -14.28]\n",
      " [  0.53  -3.3   -1.76  -3.29  -0.13 -14.31  -1.24   0.08]\n",
      " [  0.34 -22.22 -22.29 -22.17 -22.23   0.13 -14.59   0.5 ]\n",
      " [  0.72 -15.   -14.77 -14.79 -14.26   0.32   0.95   0.26]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.39   0.8    0.32   0.84   0.82   0.67   0.33   0.68]\n",
      " [  0.22  -3.28  -3.27  -3.24  -3.21  -3.16 -28.93 -14.69]\n",
      " [ -3.3  -22.37 -14.55  -2.24 -14.87  -1.37 -14.55   0.29]\n",
      " [  0.76  -3.3  -26.26 -14.44  -1.49  -2.71 -22.1  -14.9 ]\n",
      " [  0.03  -1.59  -3.3  -26.08  -0.76 -14.83 -14.42   0.36]\n",
      " [  0.69 -22.39  -2.05 -14.3   -1.64  -1.87 -14.75   0.49]\n",
      " [  0.74  -3.29  -3.29  -3.3  -14.39   0.06  -0.34   0.75]\n",
      " [  0.63 -14.27 -14.59 -14.58 -14.61   0.99 -14.29 -14.45]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > < > v █ \n",
      "> < █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ ^ v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 64 Tot Reward: -731\n",
      "Episode: 2 - Tot Steps: 150 Tot Reward: -1252\n",
      "Episode: 3 - Tot Steps: 162 Tot Reward: -510\n",
      "Episode: 4 - Tot Steps: 203 Tot Reward: -580\n",
      "Episode: 5 - Tot Steps: 59 Tot Reward: -59\n",
      "Episode: 6 - Tot Steps: 55 Tot Reward: -84\n",
      "Episode: 7 - Tot Steps: 64 Tot Reward: -151\n",
      "Episode: 8 - Tot Steps: 101 Tot Reward: -130\n",
      "Episode: 9 - Tot Steps: 112 Tot Reward: -170\n",
      "Episode: 10 - Tot Steps: 55 Tot Reward: -113\n",
      "Episode: 11 - Tot Steps: 41 Tot Reward: -70\n",
      "Episode: 12 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 13 - Tot Steps: 91 Tot Reward: -120\n",
      "Episode: 14 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 15 - Tot Steps: 123 Tot Reward: -210\n",
      "Episode: 16 - Tot Steps: 39 Tot Reward: -68\n",
      "Episode: 17 - Tot Steps: 111 Tot Reward: -198\n",
      "Episode: 18 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 19 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 20 - Tot Steps: 39 Tot Reward: -39\n",
      "Episode: 21 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 22 - Tot Steps: 31 Tot Reward: -31\n",
      "Episode: 23 - Tot Steps: 22 Tot Reward: -22\n",
      "Episode: 24 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 25 - Tot Steps: 91 Tot Reward: -178\n",
      "Episode: 26 - Tot Steps: 29 Tot Reward: -29\n",
      "Episode: 27 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 28 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 29 - Tot Steps: 33 Tot Reward: -33\n",
      "Episode: 30 - Tot Steps: 16 Tot Reward: -16\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 8.000e-02  8.000e-01  1.500e-01  8.700e-01  3.300e-01  7.400e-01\n",
      "   6.800e-01  9.300e-01]\n",
      " [ 7.500e-01 -4.670e+00 -4.620e+00 -4.540e+00 -4.410e+00 -4.290e+00\n",
      "  -4.080e+00  1.800e-01]\n",
      " [-4.780e+00 -4.730e+00 -2.050e+00 -8.000e-02 -4.460e+00 -1.900e-01\n",
      "  -3.850e+00  3.900e-01]\n",
      " [ 4.100e-01 -4.750e+00 -2.222e+01 -1.474e+01 -8.000e-01 -1.427e+01\n",
      "  -3.740e+00 -1.454e+01]\n",
      " [ 2.300e-01 -2.700e+00 -4.750e+00 -1.433e+01 -1.491e+01 -2.870e+00\n",
      "  -9.500e-01 -1.438e+01]\n",
      " [ 4.500e-01 -2.831e+01 -3.200e-01 -4.730e+00 -1.472e+01 -2.460e+00\n",
      "  -2.216e+01 -1.454e+01]\n",
      " [ 3.700e-01 -4.720e+00 -2.234e+01 -4.720e+00 -1.463e+01  2.000e-02\n",
      "  -1.160e+00  4.500e-01]\n",
      " [ 5.000e-01 -2.690e+00 -2.650e+00 -3.570e+00  2.000e-01 -1.456e+01\n",
      "   1.200e-01  1.600e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 2.400e-01  5.300e-01  7.100e-01  2.000e-02  8.000e-01  2.400e-01\n",
      "   0.000e+00  6.600e-01]\n",
      " [ 3.900e-01 -4.690e+00 -4.640e+00 -4.540e+00 -4.470e+00 -4.320e+00\n",
      "  -4.090e+00  1.200e-01]\n",
      " [-4.780e+00 -4.730e+00 -3.360e+00 -1.454e+01 -1.458e+01  1.100e-01\n",
      "  -2.593e+01  6.000e-02]\n",
      " [ 1.200e-01 -4.730e+00 -4.750e+00  3.000e-02 -1.479e+01 -1.449e+01\n",
      "  -3.510e+00  1.600e-01]\n",
      " [ 2.600e-01 -1.444e+01 -2.235e+01 -4.740e+00 -2.540e+00 -1.497e+01\n",
      "  -3.300e-01 -1.454e+01]\n",
      " [ 4.600e-01 -4.720e+00 -3.300e-01 -1.471e+01  7.000e-02 -1.468e+01\n",
      "  -2.290e+00  1.500e-01]\n",
      " [ 4.900e-01 -4.730e+00 -4.730e+00 -4.690e+00 -4.710e+00 -1.160e+00\n",
      "  -1.497e+01  6.700e-01]\n",
      " [ 4.000e-02 -1.483e+01 -1.456e+01 -1.464e+01 -1.483e+01  3.500e-01\n",
      "   2.100e-01  4.500e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.04   0.68   0.15   0.22   0.76   0.97   0.2    0.73]\n",
      " [  0.66  -4.67 -26.15 -14.51  -4.47 -14.19  -4.05   0.3 ]\n",
      " [ -4.77  -4.74  -0.22   0.1  -22.06  -1.54  -3.81 -14.46]\n",
      " [  0.3  -26.45  -4.73   0.23 -14.67  -3.14 -22.15 -14.62]\n",
      " [  0.74  -2.42 -14.24  -4.72 -14.2   -2.68  -1.11 -14.5 ]\n",
      " [  0.55  -4.73  -2.22  -4.7   -2.17 -14.6   -1.37  -0.15]\n",
      " [  0.91 -26.41 -29.28 -26.65 -14.58 -14.42 -14.19   0.38]\n",
      " [  0.09 -14.22 -14.91 -14.28 -14.16   0.08 -14.31 -14.28]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.89   0.89   0.37   0.61   0.31   0.28   0.72   0.07]\n",
      " [  0.    -4.67  -4.6   -4.51  -4.39  -4.24 -14.36   0.69]\n",
      " [ -4.77 -22.25 -14.51  -1.47 -14.16  -1.59 -14.48   0.89]\n",
      " [  0.75  -4.74 -14.62 -14.58  -0.04  -3.59 -14.25 -14.37]\n",
      " [  0.52  -2.08  -4.72 -26.24  -1.39 -14.67 -14.4    0.35]\n",
      " [  0.96 -14.6    0.2  -26.01  -0.66  -2.1  -14.64 -14.45]\n",
      " [  0.56  -4.73  -4.7   -4.71 -14.3   -0.03  -0.47   0.64]\n",
      " [  0.04 -14.64 -23.24 -14.85 -14.41 -14.63 -14.41 -14.16]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ v > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ > < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 188 Tot Reward: -1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 249 Tot Reward: -771\n",
      "Episode: 3 - Tot Steps: 81 Tot Reward: -110\n",
      "Episode: 4 - Tot Steps: 98 Tot Reward: -127\n",
      "Episode: 5 - Tot Steps: 125 Tot Reward: -125\n",
      "Episode: 6 - Tot Steps: 101 Tot Reward: -130\n",
      "Episode: 7 - Tot Steps: 51 Tot Reward: -51\n",
      "Episode: 8 - Tot Steps: 37 Tot Reward: -95\n",
      "Episode: 9 - Tot Steps: 34 Tot Reward: -63\n",
      "Episode: 10 - Tot Steps: 98 Tot Reward: -127\n",
      "Episode: 11 - Tot Steps: 87 Tot Reward: -116\n",
      "Episode: 12 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 13 - Tot Steps: 33 Tot Reward: -178\n",
      "Episode: 14 - Tot Steps: 94 Tot Reward: -123\n",
      "Episode: 15 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 16 - Tot Steps: 42 Tot Reward: -42\n",
      "Episode: 17 - Tot Steps: 127 Tot Reward: -272\n",
      "Episode: 18 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 19 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 20 - Tot Steps: 29 Tot Reward: -29\n",
      "Episode: 21 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 22 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 23 - Tot Steps: 30 Tot Reward: -59\n",
      "Episode: 24 - Tot Steps: 74 Tot Reward: -132\n",
      "Episode: 25 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 26 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 27 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 28 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 29 - Tot Steps: 16 Tot Reward: -16\n",
      "Episode: 30 - Tot Steps: 21 Tot Reward: -21\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.64   0.62   0.93   0.     0.7    0.05   0.54   0.7 ]\n",
      " [  0.45  -7.13  -6.96  -6.59  -6.16  -5.88  -5.41 -14.12]\n",
      " [ -7.7   -7.39  -2.29  -2.88  -6.36  -0.37  -4.88   0.15]\n",
      " [  0.63  -7.45 -22.17 -14.44  -0.28 -14.17  -4.71 -14.4 ]\n",
      " [  0.6   -1.81  -7.54 -26.77 -14.58  -3.06  -2.23 -14.72]\n",
      " [  0.68 -14.41  -3.87  -7.29 -14.51  -2.69 -14.81   0.75]\n",
      " [  0.81  -7.34 -14.45  -7.4  -14.78  -1.18  -0.4    0.54]\n",
      " [  0.06  -0.11  -3.63  -3.34  -0.4    0.34   0.05   0.7 ]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 4.500e-01  4.000e-02  9.900e-01  3.200e-01  3.100e-01  5.600e-01\n",
      "   5.800e-01  1.600e-01]\n",
      " [ 5.800e-01 -7.250e+00 -6.940e+00 -6.850e+00 -6.300e+00 -6.100e+00\n",
      "  -5.380e+00 -6.000e-02]\n",
      " [-7.620e+00 -7.400e+00 -4.000e-01 -1.446e+01 -2.231e+01  1.000e-02\n",
      "  -1.455e+01 -2.300e-01]\n",
      " [ 2.300e-01 -7.490e+00 -7.490e+00 -3.960e+00 -1.475e+01 -1.430e+01\n",
      "  -4.180e+00 -2.370e+00]\n",
      " [ 8.200e-01 -1.467e+01 -2.207e+01 -7.530e+00 -2.870e+00 -2.210e+01\n",
      "  -1.180e+00 -1.451e+01]\n",
      " [ 2.900e-01 -7.340e+00 -2.800e+00 -2.234e+01 -6.000e-02 -1.477e+01\n",
      "  -2.240e+00  7.400e-01]\n",
      " [ 7.500e-01 -7.300e+00 -7.300e+00 -7.320e+00 -7.350e+00 -0.000e+00\n",
      "  -1.443e+01  9.600e-01]\n",
      " [ 6.300e-01 -1.406e+01 -1.452e+01 -1.432e+01 -1.478e+01  9.000e-02\n",
      "   3.800e-01  5.500e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.13   0.25   0.86   0.13   0.23   0.69   0.29   0.95]\n",
      " [  0.28  -7.33 -22.32 -22.17  -6.35 -25.94  -5.28   0.6 ]\n",
      " [ -7.73  -7.43  -3.88 -14.99 -14.49  -1.55  -4.76 -14.18]\n",
      " [  0.2  -26.36  -7.44  -4.86 -14.26  -3.53 -22.07 -14.5 ]\n",
      " [  0.24  -1.42 -14.59  -7.38 -14.18  -2.81   0.07   0.68]\n",
      " [  0.9   -7.4   -0.11  -7.34  -3.3  -14.61  -1.12   0.34]\n",
      " [  0.93 -14.32 -26.17 -22.26 -14.82   0.12 -14.33   0.4 ]\n",
      " [  0.25 -14.64 -14.7  -14.29 -14.77   0.41   0.66   0.68]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 6.000e-01  2.900e-01  7.200e-01  2.000e-02  9.100e-01  3.900e-01\n",
      "   8.200e-01  7.500e-01]\n",
      " [ 2.400e-01 -7.150e+00 -6.870e+00 -6.540e+00 -6.170e+00 -5.750e+00\n",
      "  -1.450e+01  3.300e-01]\n",
      " [-7.620e+00 -1.489e+01 -1.434e+01 -3.400e-01 -1.414e+01 -2.600e+00\n",
      "  -1.450e+01  9.000e-02]\n",
      " [ 8.200e-01 -7.410e+00 -2.724e+01 -1.465e+01  2.300e-01 -3.930e+00\n",
      "  -2.217e+01 -1.437e+01]\n",
      " [ 6.400e-01 -3.670e+00 -7.530e+00 -1.470e+01 -6.400e-01 -1.437e+01\n",
      "  -1.420e+01 -1.409e+01]\n",
      " [ 4.100e-01 -2.223e+01 -3.700e-01 -2.207e+01 -7.000e-02 -2.010e+00\n",
      "  -1.431e+01  8.200e-01]\n",
      " [ 4.500e-01 -7.410e+00 -7.370e+00 -7.330e+00 -2.205e+01 -4.000e-02\n",
      "  -1.400e-01  3.400e-01]\n",
      " [ 6.600e-01 -1.476e+01 -1.417e+01 -1.468e+01  1.500e-01  3.000e-02\n",
      "   5.200e-01  1.400e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ ^ > > ^ > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ < < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 71 Tot Reward: -1057\n",
      "Episode: 2 - Tot Steps: 296 Tot Reward: -1862\n",
      "Episode: 3 - Tot Steps: 81 Tot Reward: -110\n",
      "Episode: 4 - Tot Steps: 151 Tot Reward: -209\n",
      "Episode: 5 - Tot Steps: 123 Tot Reward: -239\n",
      "Episode: 6 - Tot Steps: 56 Tot Reward: -56\n",
      "Episode: 7 - Tot Steps: 93 Tot Reward: -122\n",
      "Episode: 8 - Tot Steps: 93 Tot Reward: -122\n",
      "Episode: 9 - Tot Steps: 60 Tot Reward: -89\n",
      "Episode: 10 - Tot Steps: 32 Tot Reward: -61\n",
      "Episode: 11 - Tot Steps: 49 Tot Reward: -49\n",
      "Episode: 12 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 13 - Tot Steps: 56 Tot Reward: -56\n",
      "Episode: 14 - Tot Steps: 30 Tot Reward: -30\n",
      "Episode: 15 - Tot Steps: 101 Tot Reward: -188\n",
      "Episode: 16 - Tot Steps: 37 Tot Reward: -37\n",
      "Episode: 17 - Tot Steps: 27 Tot Reward: -56\n",
      "Episode: 18 - Tot Steps: 34 Tot Reward: -179\n",
      "Episode: 19 - Tot Steps: 32 Tot Reward: -32\n",
      "Episode: 20 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 21 - Tot Steps: 34 Tot Reward: -63\n",
      "Episode: 22 - Tot Steps: 73 Tot Reward: -73\n",
      "Episode: 23 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 24 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 25 - Tot Steps: 43 Tot Reward: -72\n",
      "Episode: 26 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 27 - Tot Steps: 40 Tot Reward: -40\n",
      "Episode: 28 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 29 - Tot Steps: 57 Tot Reward: -57\n",
      "Episode: 30 - Tot Steps: 17 Tot Reward: -75\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 3.800e-01  9.600e-01  9.500e-01  9.200e-01  1.600e-01  6.500e-01\n",
      "   8.900e-01  6.300e-01]\n",
      " [ 6.900e-01 -1.220e+01 -1.106e+01 -1.060e+01 -9.530e+00 -8.220e+00\n",
      "  -7.530e+00 -1.431e+01]\n",
      " [-1.354e+01 -1.274e+01 -5.860e+00 -1.100e-01 -9.280e+00 -5.700e-01\n",
      "  -6.360e+00 -1.425e+01]\n",
      " [ 1.100e-01 -1.288e+01 -2.202e+01 -1.414e+01 -2.420e+00 -1.476e+01\n",
      "  -5.700e+00 -1.432e+01]\n",
      " [ 1.700e-01 -1.300e-01 -1.306e+01 -2.616e+01 -1.449e+01 -4.690e+00\n",
      "  -3.020e+00 -1.473e+01]\n",
      " [ 6.800e-01 -1.449e+01  1.000e-02 -1.303e+01 -1.449e+01 -2.790e+00\n",
      "  -1.472e+01  7.500e-01]\n",
      " [ 5.300e-01 -1.326e+01 -2.204e+01 -1.294e+01 -1.462e+01 -3.000e-02\n",
      "  -5.600e-01  2.000e-02]\n",
      " [ 8.300e-01 -4.500e-01  1.000e-02 -5.750e+00  7.000e-02 -1.481e+01\n",
      "  -5.800e-01  1.200e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 5.100e-01  8.000e-01  8.400e-01  1.000e-02  8.400e-01  5.600e-01\n",
      "   9.100e-01  5.300e-01]\n",
      " [ 7.900e-01 -1.247e+01 -1.217e+01 -1.100e+01 -9.180e+00 -8.850e+00\n",
      "  -7.750e+00 -5.570e+00]\n",
      " [-1.330e+01 -1.280e+01 -3.830e+00 -1.418e+01 -1.445e+01 -2.600e-01\n",
      "  -2.242e+01 -3.790e+00]\n",
      " [ 3.300e-01 -1.263e+01 -1.299e+01 -2.750e+00 -1.431e+01 -2.222e+01\n",
      "  -5.230e+00 -2.980e+00]\n",
      " [ 9.900e-01 -1.460e+01 -1.451e+01 -1.309e+01  1.500e-01 -1.429e+01\n",
      "  -1.880e+00 -1.483e+01]\n",
      " [ 1.400e-01 -1.325e+01 -4.710e+00 -1.462e+01 -1.300e-01 -1.443e+01\n",
      "  -1.750e+00  3.500e-01]\n",
      " [ 5.000e-01 -1.329e+01 -1.326e+01 -1.277e+01 -1.259e+01 -2.700e-01\n",
      "  -1.434e+01  1.100e-01]\n",
      " [ 3.300e-01 -1.467e+01 -2.187e+01 -1.409e+01  1.600e-01 -1.435e+01\n",
      "  -1.483e+01 -1.462e+01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.72   0.08   0.06   0.37   0.17   0.47   0.61   0.9 ]\n",
      " [  0.52 -12.62 -29.01 -14.39  -9.26 -22.55  -7.23 -14.86]\n",
      " [-13.52 -12.69  -6.53 -14.53 -14.42  -1.5   -6.23 -14.18]\n",
      " [  0.42 -22.42 -12.71  -0.61 -14.41  -4.23 -28.17 -14.46]\n",
      " [  0.5   -0.27 -14.24 -12.69 -14.48  -3.23  -1.32   0.12]\n",
      " [  0.43 -13.31  -0.6  -12.55  -0.06 -22.21  -1.23   0.37]\n",
      " [  0.9  -14.94 -14.7  -25.47 -14.48 -14.38 -14.63   0.77]\n",
      " [  0.18 -14.01 -14.74   0.41 -14.07 -29.06 -14.75   0.15]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 5.000e-01  2.500e-01  7.000e-01  3.500e-01  5.400e-01  3.300e-01\n",
      "   3.600e-01  2.800e-01]\n",
      " [ 2.300e-01 -1.193e+01 -1.106e+01 -1.015e+01 -9.200e+00 -8.220e+00\n",
      "  -3.080e+01 -1.447e+01]\n",
      " [-1.335e+01 -2.312e+01 -1.452e+01  1.600e-01 -1.430e+01 -1.130e+00\n",
      "  -2.645e+01 -1.482e+01]\n",
      " [ 5.500e-01 -1.280e+01 -2.230e+01 -1.423e+01  1.000e-02 -5.070e+00\n",
      "  -2.229e+01 -1.407e+01]\n",
      " [ 5.700e-01 -2.390e+00 -1.267e+01 -1.486e+01 -1.400e-01 -1.444e+01\n",
      "  -1.469e+01 -1.449e+01]\n",
      " [ 9.900e-01 -1.442e+01  1.300e-01 -2.182e+01 -1.270e+00 -2.230e+00\n",
      "  -1.408e+01  3.500e-01]\n",
      " [ 7.300e-01 -1.313e+01 -1.288e+01 -1.241e+01 -1.437e+01 -2.300e-01\n",
      "  -2.300e-01  4.600e-01]\n",
      " [ 8.600e-01 -1.448e+01  9.000e-02 -1.450e+01 -2.924e+01 -2.210e+01\n",
      "  -1.449e+01  5.000e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > ^ > < ^ v █ \n",
      "< v █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ > > > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "## gamma값을 0.1~ 1까지 0.1씩 증가\n",
    "gamma_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "gamma_list_reward = []\n",
    "\n",
    "## gamma_list를 하나씩 돌면서 값측정\n",
    "for i in gamma_list:\n",
    "    ## reward 값을 반환받고, reward값은 음수이므로, 100을 더해서 값이 작을수록 좋은 것임을 나타냄\n",
    "    if __name__ == '__main__':\n",
    "        reward = main(n_episodes=30, alpha =0.5, gamma=i,\n",
    "             epsilon = 0.05, result_screening = False)\n",
    "        reward = reward\n",
    "    ## reward에 하나씩 추가\n",
    "    gamma_list_reward.append(reward)\n",
    "    \n",
    "plt.plot(gamma_list, gamma_list_reward, marker='o', linestyle='-')\n",
    "plt.title('gamma - Reward')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('Reward per gamma')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4844df2b",
   "metadata": {},
   "source": [
    "#### d) 모든 파라미터가 동일하고, epsilon에 따른 Reward값 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d653794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 61 Tot Reward: -728\n",
      "Episode: 2 - Tot Steps: 101 Tot Reward: -826\n",
      "Episode: 3 - Tot Steps: 260 Tot Reward: -1246\n",
      "Episode: 4 - Tot Steps: 183 Tot Reward: -212\n",
      "Episode: 5 - Tot Steps: 93 Tot Reward: -180\n",
      "Episode: 6 - Tot Steps: 169 Tot Reward: -459\n",
      "Episode: 7 - Tot Steps: 176 Tot Reward: -263\n",
      "Episode: 8 - Tot Steps: 55 Tot Reward: -113\n",
      "Episode: 9 - Tot Steps: 79 Tot Reward: -108\n",
      "Episode: 10 - Tot Steps: 104 Tot Reward: -220\n",
      "Episode: 11 - Tot Steps: 170 Tot Reward: -344\n",
      "Episode: 12 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 13 - Tot Steps: 94 Tot Reward: -152\n",
      "Episode: 14 - Tot Steps: 45 Tot Reward: -45\n",
      "Episode: 15 - Tot Steps: 35 Tot Reward: -64\n",
      "Episode: 16 - Tot Steps: 80 Tot Reward: -167\n",
      "Episode: 17 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 18 - Tot Steps: 37 Tot Reward: -66\n",
      "Episode: 19 - Tot Steps: 33 Tot Reward: -33\n",
      "Episode: 20 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 21 - Tot Steps: 192 Tot Reward: -308\n",
      "Episode: 22 - Tot Steps: 29 Tot Reward: -58\n",
      "Episode: 23 - Tot Steps: 29 Tot Reward: -29\n",
      "Episode: 24 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 25 - Tot Steps: 30 Tot Reward: -59\n",
      "Episode: 26 - Tot Steps: 21 Tot Reward: -50\n",
      "Episode: 27 - Tot Steps: 19 Tot Reward: -19\n",
      "Episode: 28 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 29 - Tot Steps: 36 Tot Reward: -36\n",
      "Episode: 30 - Tot Steps: 16 Tot Reward: -16\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 2.500e-01  6.800e-01  2.400e-01  8.600e-01  2.100e-01  1.600e-01\n",
      "   5.600e-01  2.500e-01]\n",
      " [ 6.000e-02 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.449e+01]\n",
      " [-1.670e+00 -1.670e+00 -8.700e-01 -8.800e-01 -1.670e+00 -1.090e+00\n",
      "  -1.660e+00 -1.462e+01]\n",
      " [ 5.000e-02 -1.670e+00 -2.229e+01 -1.490e+01 -4.000e-02 -1.449e+01\n",
      "  -1.660e+00 -1.478e+01]\n",
      " [ 8.400e-01 -1.460e+00 -1.670e+00 -2.258e+01 -1.459e+01 -1.600e+00\n",
      "  -6.800e-01 -1.463e+01]\n",
      " [ 5.100e-01 -2.631e+01 -1.230e+00 -1.670e+00 -1.506e+01 -1.530e+00\n",
      "  -2.230e+01  1.500e-01]\n",
      " [ 1.300e-01 -1.670e+00 -2.244e+01 -1.670e+00 -1.456e+01 -2.300e-01\n",
      "  -1.000e+00  9.900e-01]\n",
      " [ 6.600e-01 -3.000e-02  2.000e-02 -1.470e+00 -1.260e+00 -1.444e+01\n",
      "  -2.800e-01 -1.300e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 3.900e-01  2.000e-01  3.100e-01  3.700e-01  9.800e-01  3.600e-01\n",
      "   2.000e-01  2.000e-01]\n",
      " [ 3.500e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -2.400e-01]\n",
      " [-1.670e+00 -1.670e+00 -3.400e-01 -1.475e+01 -1.491e+01 -9.300e-01\n",
      "  -2.248e+01 -9.700e-01]\n",
      " [ 6.200e-01 -1.670e+00 -1.670e+00 -1.280e+00 -1.477e+01 -1.474e+01\n",
      "  -1.660e+00 -2.600e-01]\n",
      " [ 5.000e-01 -1.497e+01 -2.849e+01 -1.670e+00 -1.050e+00 -2.242e+01\n",
      "  -9.000e-02  6.000e-02]\n",
      " [ 2.000e-01 -1.670e+00 -1.430e+00 -2.929e+01 -3.400e-01 -2.618e+01\n",
      "  -1.480e+00 -4.000e-02]\n",
      " [ 5.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -3.900e-01\n",
      "  -2.229e+01  1.000e-02]\n",
      " [ 1.900e-01  7.000e-02 -1.451e+01 -1.444e+01 -1.519e+01 -1.472e+01\n",
      "  -1.461e+01  7.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 9.500e-01  1.900e-01  9.400e-01  4.700e-01  8.700e-01  2.500e-01\n",
      "   1.000e-02  1.600e-01]\n",
      " [ 7.000e-02 -1.670e+00 -1.482e+01 -2.823e+01 -1.670e+00 -2.623e+01\n",
      "  -1.660e+00 -1.484e+01]\n",
      " [-1.670e+00 -1.670e+00 -8.300e-01 -1.493e+01 -1.456e+01 -1.200e+00\n",
      "  -1.660e+00 -1.449e+01]\n",
      " [ 8.300e-01 -2.825e+01 -1.670e+00 -9.700e-01 -1.473e+01 -1.640e+00\n",
      "  -1.476e+01 -1.453e+01]\n",
      " [ 8.500e-01 -1.410e+00 -2.644e+01 -1.670e+00 -1.474e+01 -1.600e+00\n",
      "  -2.800e-01 -1.471e+01]\n",
      " [ 2.500e-01 -1.670e+00 -1.340e+00 -1.670e+00 -8.900e-01 -1.436e+01\n",
      "  -1.240e+00  5.000e-02]\n",
      " [ 7.600e-01 -1.469e+01 -1.480e+01 -2.828e+01 -2.629e+01 -1.453e+01\n",
      "  -2.215e+01  8.900e-01]\n",
      " [ 8.700e-01  8.400e-01 -1.448e+01 -1.489e+01 -1.478e+01 -1.464e+01\n",
      "   2.000e-02 -1.457e+01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 8.100e-01  5.000e-02  2.600e-01  7.100e-01  3.500e-01  7.900e-01\n",
      "   9.000e-02  9.300e-01]\n",
      " [ 2.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.460e+01  2.000e-02]\n",
      " [-1.670e+00 -2.229e+01 -1.435e+01 -1.240e+00 -2.639e+01 -8.500e-01\n",
      "  -2.230e+01 -1.442e+01]\n",
      " [ 8.300e-01 -1.670e+00 -2.622e+01 -1.478e+01 -3.800e-01 -1.640e+00\n",
      "  -1.487e+01 -1.447e+01]\n",
      " [ 5.900e-01 -1.330e+00 -1.670e+00 -2.217e+01 -8.800e-01 -1.470e+01\n",
      "  -1.465e+01 -1.463e+01]\n",
      " [ 6.700e-01 -2.615e+01 -1.190e+00 -1.457e+01 -3.700e-01 -1.500e+00\n",
      "  -1.451e+01  4.800e-01]\n",
      " [ 2.100e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.222e+01 -6.900e-01\n",
      "  -6.000e-01  1.600e-01]\n",
      " [ 7.500e-01 -1.456e+01 -1.466e+01 -1.494e+01 -1.440e+01 -1.478e+01\n",
      "  -1.463e+01 -1.437e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > ^ > > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 134 Tot Reward: -1381\n",
      "Episode: 2 - Tot Steps: 427 Tot Reward: -1848\n",
      "Episode: 3 - Tot Steps: 100 Tot Reward: -245\n",
      "Episode: 4 - Tot Steps: 186 Tot Reward: -302\n",
      "Episode: 5 - Tot Steps: 54 Tot Reward: -83\n",
      "Episode: 6 - Tot Steps: 75 Tot Reward: -162\n",
      "Episode: 7 - Tot Steps: 62 Tot Reward: -62\n",
      "Episode: 8 - Tot Steps: 119 Tot Reward: -235\n",
      "Episode: 9 - Tot Steps: 63 Tot Reward: -150\n",
      "Episode: 10 - Tot Steps: 67 Tot Reward: -96\n",
      "Episode: 11 - Tot Steps: 293 Tot Reward: -786\n",
      "Episode: 12 - Tot Steps: 47 Tot Reward: -76\n",
      "Episode: 13 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 14 - Tot Steps: 64 Tot Reward: -93\n",
      "Episode: 15 - Tot Steps: 32 Tot Reward: -90\n",
      "Episode: 16 - Tot Steps: 36 Tot Reward: -36\n",
      "Episode: 17 - Tot Steps: 30 Tot Reward: -175\n",
      "Episode: 18 - Tot Steps: 39 Tot Reward: -126\n",
      "Episode: 19 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 20 - Tot Steps: 26 Tot Reward: -26\n",
      "Episode: 21 - Tot Steps: 28 Tot Reward: -57\n",
      "Episode: 22 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 23 - Tot Steps: 108 Tot Reward: -311\n",
      "Episode: 24 - Tot Steps: 93 Tot Reward: -209\n",
      "Episode: 25 - Tot Steps: 23 Tot Reward: -23\n",
      "Episode: 26 - Tot Steps: 36 Tot Reward: -94\n",
      "Episode: 27 - Tot Steps: 18 Tot Reward: -18\n",
      "Episode: 28 - Tot Steps: 20 Tot Reward: -20\n",
      "Episode: 29 - Tot Steps: 65 Tot Reward: -152\n",
      "Episode: 30 - Tot Steps: 19 Tot Reward: -48\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.46   0.61   0.14   0.58   0.06   0.86   0.84   0.19]\n",
      " [  0.72  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.94]\n",
      " [ -1.67  -1.67  -1.28  -0.88  -1.67  -1.37  -1.66 -14.58]\n",
      " [  0.38  -1.67 -14.65 -14.91  -0.82 -22.43  -1.66 -14.92]\n",
      " [  0.35  -1.44  -1.67 -28.38 -14.89  -1.65  -0.82 -14.69]\n",
      " [  0.13 -26.53  -1.49  -1.67 -14.83  -1.58 -14.71   0.46]\n",
      " [  0.53  -1.67 -26.43  -1.67 -22.23  -0.91  -1.16   0.17]\n",
      " [  0.51  -1.48  -1.49  -1.55  -0.89 -14.58  -0.61   0.59]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 2.100e-01  7.900e-01  1.000e-01  5.400e-01  9.000e-01  5.200e-01\n",
      "   3.200e-01  1.600e-01]\n",
      " [ 6.100e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.640e+00]\n",
      " [-1.670e+00 -1.670e+00 -1.010e+00 -1.454e+01 -1.490e+01 -1.130e+00\n",
      "  -2.932e+01 -4.000e-01]\n",
      " [ 6.100e-01 -1.670e+00 -1.670e+00 -1.310e+00 -1.503e+01 -2.621e+01\n",
      "  -1.660e+00 -1.310e+00]\n",
      " [ 8.000e-01 -1.492e+01 -2.836e+01 -1.670e+00 -2.000e-02 -2.240e+01\n",
      "  -3.600e-01  3.600e-01]\n",
      " [ 9.200e-01 -1.670e+00 -1.380e+00 -2.632e+01 -1.250e+00 -2.233e+01\n",
      "  -1.380e+00 -2.400e-01]\n",
      " [ 7.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.280e+00\n",
      "  -2.633e+01  6.100e-01]\n",
      " [ 4.400e-01 -1.467e+01 -1.463e+01 -1.477e+01 -1.457e+01 -1.489e+01\n",
      "  -1.436e+01 -1.441e+01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 1.000e+00  5.200e-01  6.000e-02  4.200e-01  9.600e-01  9.500e-01\n",
      "   2.000e-01  6.300e-01]\n",
      " [ 7.400e-01 -1.670e+00 -2.636e+01 -2.236e+01 -1.670e+00 -2.839e+01\n",
      "  -1.670e+00 -1.484e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.260e+00 -1.478e+01 -1.468e+01 -1.320e+00\n",
      "  -1.660e+00 -1.471e+01]\n",
      " [ 5.600e-01 -2.847e+01 -1.670e+00 -1.400e+00 -1.437e+01 -1.640e+00\n",
      "  -1.481e+01 -1.480e+01]\n",
      " [ 5.000e-02 -1.370e+00 -2.845e+01 -1.670e+00 -1.472e+01 -1.600e+00\n",
      "  -2.000e-02 -1.448e+01]\n",
      " [ 9.800e-01 -1.670e+00 -1.480e+00 -1.670e+00 -1.180e+00 -2.636e+01\n",
      "  -1.270e+00  1.000e-02]\n",
      " [ 2.700e-01 -2.952e+01 -2.630e+01 -2.949e+01 -2.220e+01 -1.469e+01\n",
      "  -2.209e+01  5.000e-01]\n",
      " [ 1.000e-01 -1.436e+01 -1.494e+01 -1.486e+01 -1.455e+01 -1.450e+01\n",
      "  -1.441e+01  3.800e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 7.400e-01  9.700e-01  3.000e-01  2.400e-01  3.200e-01  6.400e-01\n",
      "   7.100e-01  4.600e-01]\n",
      " [ 7.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.036e+01 -1.495e+01]\n",
      " [-1.670e+00 -2.832e+01 -1.463e+01 -3.600e-01 -1.445e+01 -1.200e+00\n",
      "  -1.450e+01 -1.483e+01]\n",
      " [ 6.100e-01 -1.670e+00 -2.643e+01 -1.458e+01 -9.600e-01 -1.650e+00\n",
      "  -2.633e+01 -1.476e+01]\n",
      " [ 3.000e-02 -1.470e+00 -1.670e+00 -1.479e+01 -8.000e-01 -2.234e+01\n",
      "  -1.435e+01 -1.448e+01]\n",
      " [ 3.200e-01 -2.937e+01 -1.330e+00 -2.935e+01 -1.270e+00 -1.510e+00\n",
      "  -1.481e+01 -1.480e+01]\n",
      " [ 8.600e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.237e+01 -1.050e+00\n",
      "  -6.800e-01  7.900e-01]\n",
      " [ 5.200e-01 -2.252e+01 -1.470e+01 -1.473e+01 -1.480e+01 -1.444e+01\n",
      "  -1.435e+01  6.000e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ < > > > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ > ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 55 Tot Reward: -577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 33 Tot Reward: -381\n",
      "Episode: 3 - Tot Steps: 144 Tot Reward: -811\n",
      "Episode: 4 - Tot Steps: 508 Tot Reward: -2393\n",
      "Episode: 5 - Tot Steps: 44 Tot Reward: -131\n",
      "Episode: 6 - Tot Steps: 63 Tot Reward: -150\n",
      "Episode: 7 - Tot Steps: 195 Tot Reward: -659\n",
      "Episode: 8 - Tot Steps: 91 Tot Reward: -207\n",
      "Episode: 9 - Tot Steps: 127 Tot Reward: -243\n",
      "Episode: 10 - Tot Steps: 133 Tot Reward: -191\n",
      "Episode: 11 - Tot Steps: 93 Tot Reward: -209\n",
      "Episode: 12 - Tot Steps: 57 Tot Reward: -86\n",
      "Episode: 13 - Tot Steps: 62 Tot Reward: -91\n",
      "Episode: 14 - Tot Steps: 74 Tot Reward: -248\n",
      "Episode: 15 - Tot Steps: 30 Tot Reward: -59\n",
      "Episode: 16 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 17 - Tot Steps: 253 Tot Reward: -601\n",
      "Episode: 18 - Tot Steps: 46 Tot Reward: -104\n",
      "Episode: 19 - Tot Steps: 29 Tot Reward: -58\n",
      "Episode: 20 - Tot Steps: 153 Tot Reward: -443\n",
      "Episode: 21 - Tot Steps: 27 Tot Reward: -27\n",
      "Episode: 22 - Tot Steps: 25 Tot Reward: -25\n",
      "Episode: 23 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 24 - Tot Steps: 23 Tot Reward: -52\n",
      "Episode: 25 - Tot Steps: 44 Tot Reward: -73\n",
      "Episode: 26 - Tot Steps: 21 Tot Reward: -21\n",
      "Episode: 27 - Tot Steps: 25 Tot Reward: -54\n",
      "Episode: 28 - Tot Steps: 31 Tot Reward: -60\n",
      "Episode: 29 - Tot Steps: 37 Tot Reward: -95\n",
      "Episode: 30 - Tot Steps: 18 Tot Reward: -18\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.98   0.82   0.67   0.97   0.89   0.66   0.83   0.63]\n",
      " [  0.51  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.75]\n",
      " [ -1.67  -1.67  -1.5   -1.36  -1.67  -1.36  -1.66 -14.7 ]\n",
      " [  0.98  -1.67 -29.51 -14.51  -1.26 -22.42  -1.66 -14.88]\n",
      " [  0.19  -1.52  -1.67 -26.43 -14.56  -1.62  -1.06 -22.23]\n",
      " [  0.03 -28.3   -1.51  -1.67 -14.7   -1.63 -26.25 -25.39]\n",
      " [  0.7   -1.67 -28.48  -1.67 -22.4   -0.82  -0.75   0.88]\n",
      " [  0.76  -1.38  -1.65  -1.47  -1.05 -14.51  -0.31   0.62]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.53   0.13   0.74   0.3    0.47   0.07   0.98   0.51]\n",
      " [  0.32  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.66]\n",
      " [ -1.67  -1.67  -1.46 -14.59 -26.41  -1.39 -29.4   -1.46]\n",
      " [  0.36  -1.67  -1.67  -1.27 -14.64 -29.86  -1.66  -1.15]\n",
      " [  0.48 -14.76 -22.46  -1.67  -1.35 -28.28  -0.67 -14.73]\n",
      " [  0.59  -1.67  -1.5  -30.31  -1.28 -26.44  -1.53  -0.08]\n",
      " [  0.35  -1.67  -1.67  -1.67  -1.67  -0.62 -22.24   0.55]\n",
      " [  0.43 -22.15 -14.59 -14.66 -14.86 -14.64   0.14 -14.52]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.73   0.42   0.12   0.39   0.79   0.53   0.77   0.07]\n",
      " [  0.51  -1.67 -29.95 -28.37  -1.67 -28.2   -1.66 -14.98]\n",
      " [ -1.67  -1.67  -1.62 -14.55 -14.55  -1.26  -1.66 -14.64]\n",
      " [  0.43 -30.22  -1.67  -1.02 -14.51  -1.64 -26.05 -22.14]\n",
      " [  0.38  -1.48 -26.36  -1.67 -14.4   -1.6   -1.11 -22.2 ]\n",
      " [  0.75  -1.67  -1.43  -1.67  -1.07 -22.32  -1.26  -0.11]\n",
      " [  0.48 -28.31 -30.5  -28.41 -22.49 -14.82 -14.76   0.66]\n",
      " [  0.07 -14.7  -14.85 -22.22 -14.46   0.43 -14.4    0.35]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 3.800e-01  3.000e-02  8.200e-01  1.500e-01  2.200e-01  3.200e-01\n",
      "   8.800e-01  6.200e-01]\n",
      " [ 4.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.061e+01 -1.480e+01]\n",
      " [-1.670e+00 -2.842e+01 -1.482e+01 -1.450e+00 -2.249e+01 -1.150e+00\n",
      "  -2.842e+01 -2.228e+01]\n",
      " [ 1.500e-01 -1.670e+00 -2.244e+01 -1.450e+01 -1.410e+00 -1.650e+00\n",
      "  -2.253e+01 -1.473e+01]\n",
      " [ 5.200e-01 -1.460e+00 -1.670e+00 -2.630e+01 -1.190e+00 -2.249e+01\n",
      "  -1.475e+01 -1.493e+01]\n",
      " [ 6.400e-01 -2.267e+01 -1.450e+00 -2.618e+01 -9.700e-01 -1.500e+00\n",
      "  -2.232e+01  5.000e-02]\n",
      " [ 9.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.245e+01 -8.900e-01\n",
      "  -6.500e-01  6.500e-01]\n",
      " [ 9.100e-01 -1.466e+01 -1.472e+01 -1.471e+01 -1.442e+01  4.600e-01\n",
      "  -1.439e+01  2.000e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > > > > v █ \n",
      "^ v █ █ ^ █ v █ \n",
      "█ < < █ █ v < █ \n",
      "█ █ > < █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 85 Tot Reward: -984\n",
      "Episode: 2 - Tot Steps: 47 Tot Reward: -250\n",
      "Episode: 3 - Tot Steps: 540 Tot Reward: -3005\n",
      "Episode: 4 - Tot Steps: 105 Tot Reward: -308\n",
      "Episode: 5 - Tot Steps: 129 Tot Reward: -361\n",
      "Episode: 6 - Tot Steps: 74 Tot Reward: -161\n",
      "Episode: 7 - Tot Steps: 44 Tot Reward: -102\n",
      "Episode: 8 - Tot Steps: 108 Tot Reward: -340\n",
      "Episode: 9 - Tot Steps: 185 Tot Reward: -417\n",
      "Episode: 10 - Tot Steps: 75 Tot Reward: -249\n",
      "Episode: 11 - Tot Steps: 20 Tot Reward: -49\n",
      "Episode: 12 - Tot Steps: 43 Tot Reward: -43\n",
      "Episode: 13 - Tot Steps: 93 Tot Reward: -267\n",
      "Episode: 14 - Tot Steps: 51 Tot Reward: -109\n",
      "Episode: 15 - Tot Steps: 44 Tot Reward: -73\n",
      "Episode: 16 - Tot Steps: 109 Tot Reward: -370\n",
      "Episode: 17 - Tot Steps: 29 Tot Reward: -29\n",
      "Episode: 18 - Tot Steps: 39 Tot Reward: -39\n",
      "Episode: 19 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 20 - Tot Steps: 56 Tot Reward: -85\n",
      "Episode: 21 - Tot Steps: 120 Tot Reward: -410\n",
      "Episode: 22 - Tot Steps: 24 Tot Reward: -24\n",
      "Episode: 23 - Tot Steps: 39 Tot Reward: -97\n",
      "Episode: 24 - Tot Steps: 33 Tot Reward: -62\n",
      "Episode: 25 - Tot Steps: 26 Tot Reward: -84\n",
      "Episode: 26 - Tot Steps: 45 Tot Reward: -74\n",
      "Episode: 27 - Tot Steps: 28 Tot Reward: -86\n",
      "Episode: 28 - Tot Steps: 41 Tot Reward: -186\n",
      "Episode: 29 - Tot Steps: 22 Tot Reward: -51\n",
      "Episode: 30 - Tot Steps: 40 Tot Reward: -156\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 2.300e-01  8.000e-02  5.200e-01  4.000e-02  7.000e-01  5.600e-01\n",
      "   3.600e-01  7.500e-01]\n",
      " [ 9.500e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.488e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.580e+00 -1.520e+00 -1.670e+00 -1.500e+00\n",
      "  -1.660e+00 -2.227e+01]\n",
      " [ 1.000e-02 -1.670e+00 -2.847e+01 -2.235e+01 -1.180e+00 -2.646e+01\n",
      "  -1.660e+00 -1.451e+01]\n",
      " [ 5.400e-01 -1.460e+00 -1.670e+00 -2.646e+01 -1.490e+01 -1.610e+00\n",
      "  -8.500e-01 -2.256e+01]\n",
      " [ 2.200e-01 -2.843e+01 -1.540e+00 -1.670e+00 -2.651e+01 -1.610e+00\n",
      "  -2.638e+01 -1.451e+01]\n",
      " [ 4.600e-01 -1.670e+00 -2.647e+01 -1.670e+00 -2.972e+01 -1.000e+00\n",
      "  -1.430e+00  7.800e-01]\n",
      " [ 3.600e-01 -1.510e+00 -1.270e+00 -1.570e+00 -1.260e+00 -1.492e+01\n",
      "  -4.100e-01  2.300e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.07   0.5    0.6    0.94   0.29   0.49   0.91   0.11]\n",
      " [  0.87  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.63]\n",
      " [ -1.67  -1.67  -1.52 -22.27 -26.5   -1.45 -29.47  -0.34]\n",
      " [  0.35  -1.67  -1.67  -1.35 -14.62 -22.58  -1.66  -1.61]\n",
      " [  0.04 -22.43 -29.5   -1.67  -1.45 -28.38  -1.16 -14.87]\n",
      " [  0.62  -1.67  -1.53 -29.98  -0.98 -22.24  -1.35  -0.3 ]\n",
      " [  0.88  -1.67  -1.67  -1.67  -1.67  -0.79 -22.47   0.71]\n",
      " [  0.5  -14.44 -14.79 -14.49 -14.94 -14.89 -14.73 -14.58]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.93   0.71   0.47   0.11   0.85   0.93   0.88   0.33]\n",
      " [  0.28  -1.67 -29.94 -30.28  -1.67 -29.41  -1.67 -14.74]\n",
      " [ -1.67  -1.67  -1.55 -14.46 -26.17  -1.47  -1.66 -22.56]\n",
      " [  0.33 -29.29  -1.67  -1.47 -14.82  -1.64 -28.25 -25.11]\n",
      " [  0.65  -1.48 -29.28  -1.67 -14.64  -1.6   -1.23 -14.62]\n",
      " [  0.6   -1.67  -1.47  -1.67  -1.05 -22.51  -1.27  -0.29]\n",
      " [  0.78 -28.47 -26.34 -29.5  -26.28 -14.69 -22.24   0.74]\n",
      " [  0.46 -14.79 -14.86 -14.96 -14.68 -14.65 -22.09 -14.41]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 4.300e-01  6.200e-01  8.900e-01  4.200e-01  6.600e-01  8.800e-01\n",
      "   8.000e-02  2.000e-02]\n",
      " [ 8.100e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.010e+01 -1.469e+01]\n",
      " [-1.670e+00 -2.954e+01 -1.455e+01 -1.610e+00 -2.838e+01 -1.520e+00\n",
      "  -2.613e+01 -1.492e+01]\n",
      " [ 4.100e-01 -1.670e+00 -2.991e+01 -1.455e+01 -9.400e-01 -1.660e+00\n",
      "  -2.950e+01 -2.258e+01]\n",
      " [ 2.500e-01 -1.590e+00 -1.670e+00 -2.639e+01 -1.470e+00 -2.229e+01\n",
      "  -1.442e+01 -2.517e+01]\n",
      " [ 8.000e-01 -3.000e+01 -1.550e+00 -1.477e+01 -1.180e+00 -1.510e+00\n",
      "  -2.215e+01  5.200e-01]\n",
      " [ 6.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.465e+01 -7.200e-01\n",
      "  -6.600e-01  8.400e-01]\n",
      " [ 3.500e-01 -1.463e+01 -1.476e+01 -1.460e+01 -1.469e+01 -1.450e+01\n",
      "  -1.450e+01  3.900e-01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > < ^ > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ > v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 126 Tot Reward: -1373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 61 Tot Reward: -525\n",
      "Episode: 3 - Tot Steps: 386 Tot Reward: -2155\n",
      "Episode: 4 - Tot Steps: 89 Tot Reward: -524\n",
      "Episode: 5 - Tot Steps: 108 Tot Reward: -543\n",
      "Episode: 6 - Tot Steps: 126 Tot Reward: -445\n",
      "Episode: 7 - Tot Steps: 135 Tot Reward: -425\n",
      "Episode: 8 - Tot Steps: 91 Tot Reward: -236\n",
      "Episode: 9 - Tot Steps: 146 Tot Reward: -436\n",
      "Episode: 10 - Tot Steps: 187 Tot Reward: -622\n",
      "Episode: 11 - Tot Steps: 48 Tot Reward: -251\n",
      "Episode: 12 - Tot Steps: 215 Tot Reward: -795\n",
      "Episode: 13 - Tot Steps: 49 Tot Reward: -223\n",
      "Episode: 14 - Tot Steps: 41 Tot Reward: -99\n",
      "Episode: 15 - Tot Steps: 26 Tot Reward: -55\n",
      "Episode: 16 - Tot Steps: 149 Tot Reward: -439\n",
      "Episode: 17 - Tot Steps: 36 Tot Reward: -123\n",
      "Episode: 18 - Tot Steps: 48 Tot Reward: -77\n",
      "Episode: 19 - Tot Steps: 48 Tot Reward: -251\n",
      "Episode: 20 - Tot Steps: 37 Tot Reward: -95\n",
      "Episode: 21 - Tot Steps: 65 Tot Reward: -181\n",
      "Episode: 22 - Tot Steps: 32 Tot Reward: -90\n",
      "Episode: 23 - Tot Steps: 21 Tot Reward: -108\n",
      "Episode: 24 - Tot Steps: 21 Tot Reward: -50\n",
      "Episode: 25 - Tot Steps: 33 Tot Reward: -91\n",
      "Episode: 26 - Tot Steps: 69 Tot Reward: -330\n",
      "Episode: 27 - Tot Steps: 54 Tot Reward: -112\n",
      "Episode: 28 - Tot Steps: 25 Tot Reward: -141\n",
      "Episode: 29 - Tot Steps: 35 Tot Reward: -93\n",
      "Episode: 30 - Tot Steps: 21 Tot Reward: -50\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.72   0.64   0.19   0.11   0.92   0.45   0.65   0.23]\n",
      " [  0.39  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -14.8 ]\n",
      " [ -1.67  -1.67  -1.66  -1.52  -1.67  -1.58  -1.66 -14.8 ]\n",
      " [  0.11  -1.67 -30.11 -14.82  -1.38 -28.2   -1.66 -22.37]\n",
      " [  0.15  -1.62  -1.67 -29.46 -14.59  -1.64  -1.42 -14.88]\n",
      " [  0.37 -30.32  -1.54  -1.67 -26.31  -1.63 -28.51 -14.52]\n",
      " [  0.08  -1.67 -26.36  -1.67 -30.36  -1.34  -1.3    0.81]\n",
      " [  0.41  -1.66  -1.56  -1.46  -0.85 -14.79  -0.19   0.2 ]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 3.800e-01  8.600e-01  4.100e-01  9.000e-01  9.100e-01  1.500e-01\n",
      "   4.300e-01  4.500e-01]\n",
      " [ 3.000e-02 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.520e+00]\n",
      " [-1.670e+00 -1.670e+00 -1.660e+00 -2.620e+01 -2.830e+01 -1.570e+00\n",
      "  -3.007e+01 -1.470e+00]\n",
      " [ 2.700e-01 -1.670e+00 -1.670e+00 -1.590e+00 -2.244e+01 -2.936e+01\n",
      "  -1.660e+00 -1.500e+00]\n",
      " [ 1.800e-01 -2.269e+01 -2.857e+01 -1.670e+00 -1.630e+00 -3.003e+01\n",
      "  -1.490e+00 -1.459e+01]\n",
      " [ 3.800e-01 -1.670e+00 -1.560e+00 -2.991e+01 -1.610e+00 -3.062e+01\n",
      "  -1.570e+00 -7.000e-02]\n",
      " [ 5.400e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.410e+00\n",
      "  -2.941e+01  1.700e-01]\n",
      " [ 5.800e-01 -1.469e+01 -2.219e+01 -1.484e+01 -2.260e+01 -1.485e+01\n",
      "  -1.480e+01  1.300e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.5    0.2    0.17   0.99   0.24   0.49   0.5    0.21]\n",
      " [  0.62  -1.67 -30.64 -30.43  -1.67 -30.19  -1.66 -14.55]\n",
      " [ -1.67  -1.67  -1.66 -26.56 -26.5   -1.53  -1.66 -26.37]\n",
      " [  0.43 -30.44  -1.67  -1.56 -14.47  -1.64 -30.22 -14.41]\n",
      " [  0.69  -1.59 -30.4   -1.67 -22.31  -1.6   -1.42 -14.76]\n",
      " [  0.56  -1.67  -1.49  -1.67  -1.6  -28.34  -1.25  -0.32]\n",
      " [  0.72 -30.61 -29.48 -26.3  -26.02 -14.66 -14.65   0.2 ]\n",
      " [  0.5  -22.57 -14.36 -22.67 -14.65 -14.79   0.06   0.74]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.38   0.93   0.53   0.85   0.5    0.39   0.65   0.62]\n",
      " [  0.05  -1.67  -1.67  -1.67  -1.67  -1.67 -29.43 -14.66]\n",
      " [ -1.67 -30.66 -22.14  -1.46 -28.38  -1.53 -29.4  -14.91]\n",
      " [  0.58  -1.67 -28.39 -14.7   -1.41  -1.66 -28.46 -14.72]\n",
      " [  0.84  -1.63  -1.67 -29.43  -1.43 -26.29 -14.63   0.56]\n",
      " [  0.92 -22.62  -1.45 -30.6   -1.6   -1.5  -25.95 -14.44]\n",
      " [  0.77  -1.67  -1.67  -1.67 -26.38  -1.17  -0.64   0.91]\n",
      " [  0.27 -26.24 -14.85 -14.54 -14.73 -14.64   0.47   0.54]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > ^ > > > v █ \n",
      "< ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > < █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < < > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 131 Tot Reward: -1610\n",
      "Episode: 2 - Tot Steps: 273 Tot Reward: -2100\n",
      "Episode: 3 - Tot Steps: 426 Tot Reward: -1702\n",
      "Episode: 4 - Tot Steps: 62 Tot Reward: -265\n",
      "Episode: 5 - Tot Steps: 205 Tot Reward: -843\n",
      "Episode: 6 - Tot Steps: 34 Tot Reward: -121\n",
      "Episode: 7 - Tot Steps: 97 Tot Reward: -474\n",
      "Episode: 8 - Tot Steps: 74 Tot Reward: -190\n",
      "Episode: 9 - Tot Steps: 59 Tot Reward: -204\n",
      "Episode: 10 - Tot Steps: 70 Tot Reward: -244\n",
      "Episode: 11 - Tot Steps: 43 Tot Reward: -130\n",
      "Episode: 12 - Tot Steps: 39 Tot Reward: -126\n",
      "Episode: 13 - Tot Steps: 47 Tot Reward: -163\n",
      "Episode: 14 - Tot Steps: 150 Tot Reward: -846\n",
      "Episode: 15 - Tot Steps: 47 Tot Reward: -105\n",
      "Episode: 16 - Tot Steps: 124 Tot Reward: -414\n",
      "Episode: 17 - Tot Steps: 58 Tot Reward: -290\n",
      "Episode: 18 - Tot Steps: 23 Tot Reward: -81\n",
      "Episode: 19 - Tot Steps: 83 Tot Reward: -431\n",
      "Episode: 20 - Tot Steps: 49 Tot Reward: -223\n",
      "Episode: 21 - Tot Steps: 171 Tot Reward: -780\n",
      "Episode: 22 - Tot Steps: 83 Tot Reward: -286\n",
      "Episode: 23 - Tot Steps: 45 Tot Reward: -219\n",
      "Episode: 24 - Tot Steps: 30 Tot Reward: -59\n",
      "Episode: 25 - Tot Steps: 55 Tot Reward: -229\n",
      "Episode: 26 - Tot Steps: 119 Tot Reward: -554\n",
      "Episode: 27 - Tot Steps: 28 Tot Reward: -28\n",
      "Episode: 28 - Tot Steps: 86 Tot Reward: -318\n",
      "Episode: 29 - Tot Steps: 83 Tot Reward: -344\n",
      "Episode: 30 - Tot Steps: 23 Tot Reward: -52\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.63   0.48   0.7    0.06   0.84   0.66   0.17   0.32]\n",
      " [  0.98  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -22.62]\n",
      " [ -1.67  -1.67  -1.67  -1.64  -1.67  -1.46  -1.67 -22.57]\n",
      " [  0.8   -1.67 -30.65 -14.6   -1.5  -22.39  -1.66 -14.81]\n",
      " [  0.73  -1.66  -1.67 -30.08 -26.52  -1.62  -1.48 -14.67]\n",
      " [  0.38 -30.6   -1.65  -1.67 -22.59  -1.64 -28.48 -14.8 ]\n",
      " [  0.67  -1.67 -30.58  -1.67 -30.17  -1.39  -1.44   0.14]\n",
      " [  0.78  -1.66  -1.66  -1.66  -1.48 -14.89  -1.28  -0.15]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 6.600e-01  3.000e-02  8.500e-01  4.700e-01  1.200e-01  6.400e-01\n",
      "   2.100e-01  6.400e-01]\n",
      " [ 1.800e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.660e+00]\n",
      " [-1.670e+00 -1.670e+00 -1.670e+00 -2.224e+01 -2.641e+01 -1.410e+00\n",
      "  -2.939e+01 -1.650e+00]\n",
      " [ 5.500e-01 -1.670e+00 -1.670e+00 -1.620e+00 -1.474e+01 -2.946e+01\n",
      "  -1.660e+00 -1.580e+00]\n",
      " [ 8.700e-01 -2.959e+01 -2.960e+01 -1.670e+00 -1.600e+00 -3.049e+01\n",
      "  -1.560e+00 -1.483e+01]\n",
      " [ 4.700e-01 -1.670e+00 -1.650e+00 -3.001e+01 -1.500e+00 -2.848e+01\n",
      "  -1.600e+00 -7.300e-01]\n",
      " [ 4.300e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.470e+00\n",
      "  -2.943e+01  4.000e-02]\n",
      " [ 1.000e-01 -3.006e+01 -2.644e+01 -1.485e+01 -2.643e+01 -1.461e+01\n",
      "  -2.523e+01  1.400e-01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 7.900e-01  2.000e-02  9.000e-01  7.000e-02  5.100e-01  1.700e-01\n",
      "   5.500e-01  7.200e-01]\n",
      " [ 7.000e-02 -1.670e+00 -3.067e+01 -3.060e+01 -1.670e+00 -3.003e+01\n",
      "  -1.670e+00 -2.260e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.670e+00 -2.264e+01 -2.622e+01 -1.400e+00\n",
      "  -1.660e+00 -1.448e+01]\n",
      " [ 7.000e-02 -3.061e+01 -1.670e+00 -1.630e+00 -2.236e+01 -1.650e+00\n",
      "  -2.942e+01 -1.444e+01]\n",
      " [ 9.300e-01 -1.650e+00 -3.060e+01 -1.670e+00 -1.478e+01 -1.610e+00\n",
      "  -1.370e+00 -2.240e+01]\n",
      " [ 5.500e-01 -1.670e+00 -1.650e+00 -1.670e+00 -1.480e+00 -2.935e+01\n",
      "  -1.340e+00 -1.100e-01]\n",
      " [ 2.600e-01 -3.065e+01 -3.059e+01 -3.064e+01 -2.940e+01 -1.491e+01\n",
      "  -2.993e+01  1.500e-01]\n",
      " [ 5.900e-01 -2.261e+01 -2.261e+01 -2.960e+01 -1.448e+01 -2.527e+01\n",
      "  -1.447e+01  4.100e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 2.200e-01  1.800e-01  5.500e-01  9.100e-01  6.200e-01  9.400e-01\n",
      "   1.000e-02  1.700e-01]\n",
      " [ 8.600e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.064e+01 -2.256e+01]\n",
      " [-1.670e+00 -3.040e+01 -2.642e+01 -1.630e+00 -2.648e+01 -1.440e+00\n",
      "  -3.050e+01 -2.606e+01]\n",
      " [ 5.800e-01 -1.670e+00 -3.030e+01 -1.475e+01 -1.520e+00 -1.660e+00\n",
      "  -2.953e+01 -1.431e+01]\n",
      " [ 2.100e-01 -1.640e+00 -1.670e+00 -3.002e+01 -1.620e+00 -2.993e+01\n",
      "  -2.217e+01  3.400e-01]\n",
      " [ 2.700e-01 -3.037e+01 -1.660e+00 -2.947e+01 -1.540e+00 -1.540e+00\n",
      "  -2.221e+01 -1.468e+01]\n",
      " [ 2.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -2.945e+01 -1.310e+00\n",
      "  -8.500e-01  3.900e-01]\n",
      " [ 8.400e-01 -2.857e+01 -1.461e+01 -2.266e+01 -1.465e+01 -2.228e+01\n",
      "  -1.482e+01 -1.447e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > ^ > > > v █ \n",
      "^ ^ █ █ ^ █ v █ \n",
      "█ ^ < █ █ v < █ \n",
      "█ █ ^ < █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ < > > < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 26 Tot Reward: -287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 125 Tot Reward: -1053\n",
      "Episode: 3 - Tot Steps: 429 Tot Reward: -3242\n",
      "Episode: 4 - Tot Steps: 78 Tot Reward: -281\n",
      "Episode: 5 - Tot Steps: 162 Tot Reward: -626\n",
      "Episode: 6 - Tot Steps: 168 Tot Reward: -835\n",
      "Episode: 7 - Tot Steps: 125 Tot Reward: -386\n",
      "Episode: 8 - Tot Steps: 147 Tot Reward: -669\n",
      "Episode: 9 - Tot Steps: 98 Tot Reward: -359\n",
      "Episode: 10 - Tot Steps: 75 Tot Reward: -249\n",
      "Episode: 11 - Tot Steps: 121 Tot Reward: -614\n",
      "Episode: 12 - Tot Steps: 36 Tot Reward: -94\n",
      "Episode: 13 - Tot Steps: 39 Tot Reward: -126\n",
      "Episode: 14 - Tot Steps: 48 Tot Reward: -135\n",
      "Episode: 15 - Tot Steps: 192 Tot Reward: -1033\n",
      "Episode: 16 - Tot Steps: 47 Tot Reward: -250\n",
      "Episode: 17 - Tot Steps: 22 Tot Reward: -80\n",
      "Episode: 18 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 19 - Tot Steps: 57 Tot Reward: -231\n",
      "Episode: 20 - Tot Steps: 87 Tot Reward: -406\n",
      "Episode: 21 - Tot Steps: 56 Tot Reward: -346\n",
      "Episode: 22 - Tot Steps: 22 Tot Reward: -167\n",
      "Episode: 23 - Tot Steps: 66 Tot Reward: -240\n",
      "Episode: 24 - Tot Steps: 88 Tot Reward: -233\n",
      "Episode: 25 - Tot Steps: 21 Tot Reward: -79\n",
      "Episode: 26 - Tot Steps: 42 Tot Reward: -245\n",
      "Episode: 27 - Tot Steps: 34 Tot Reward: -150\n",
      "Episode: 28 - Tot Steps: 45 Tot Reward: -161\n",
      "Episode: 29 - Tot Steps: 33 Tot Reward: -149\n",
      "Episode: 30 - Tot Steps: 36 Tot Reward: -152\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 7.000e-02  7.600e-01  4.200e-01  5.300e-01  5.000e-01  6.000e-01\n",
      "   4.000e-02  5.800e-01]\n",
      " [ 3.700e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -2.218e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.660e+00 -1.660e+00 -1.670e+00 -1.650e+00\n",
      "  -1.660e+00 -2.269e+01]\n",
      " [ 1.400e-01 -1.670e+00 -3.007e+01 -2.963e+01 -1.560e+00 -2.956e+01\n",
      "  -1.660e+00 -1.436e+01]\n",
      " [ 2.100e-01 -1.640e+00 -1.670e+00 -3.060e+01 -2.253e+01 -1.600e+00\n",
      "  -1.470e+00 -2.212e+01]\n",
      " [ 3.100e-01 -3.045e+01 -1.650e+00 -1.670e+00 -1.465e+01 -1.540e+00\n",
      "  -2.958e+01 -3.068e+01]\n",
      " [ 2.600e-01 -1.670e+00 -2.959e+01 -1.670e+00 -2.233e+01 -1.290e+00\n",
      "  -1.480e+00  4.000e-01]\n",
      " [ 4.600e-01 -1.670e+00 -1.660e+00 -1.640e+00 -1.440e+00 -2.630e+01\n",
      "  -1.050e+00 -2.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.88   0.51   0.19   0.3    0.35   0.26   0.71   0.8 ]\n",
      " [  0.14  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.65]\n",
      " [ -1.67  -1.67  -1.66 -26.63 -30.62  -1.64 -29.51  -1.65]\n",
      " [  0.14  -1.67  -1.67  -1.64 -14.74 -28.4   -1.66  -1.44]\n",
      " [  0.06 -26.39 -29.38  -1.67  -1.31 -26.48  -1.54 -22.81]\n",
      " [  0.96  -1.67  -1.64 -30.16  -0.69 -22.41  -1.57  -0.88]\n",
      " [  0.61  -1.67  -1.67  -1.67  -1.67  -1.28 -26.48   0.94]\n",
      " [  0.76 -14.95 -28.65 -26.36 -14.62 -22.11 -22.22 -14.38]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 5.100e-01  1.000e-01  5.000e-02  5.700e-01  9.100e-01  7.700e-01\n",
      "   7.700e-01  1.500e-01]\n",
      " [ 3.900e-01 -1.670e+00 -3.064e+01 -3.014e+01 -1.670e+00 -3.061e+01\n",
      "  -1.660e+00 -1.441e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.650e+00 -1.486e+01 -2.946e+01 -1.620e+00\n",
      "  -1.660e+00 -1.450e+01]\n",
      " [ 3.400e-01 -3.048e+01 -1.670e+00 -1.640e+00 -2.238e+01 -1.640e+00\n",
      "  -3.010e+01 -1.451e+01]\n",
      " [ 4.100e-01 -1.630e+00 -3.036e+01 -1.670e+00 -1.495e+01 -1.600e+00\n",
      "  -1.470e+00 -2.235e+01]\n",
      " [ 3.000e-01 -1.670e+00 -1.630e+00 -1.670e+00 -1.000e+00 -2.937e+01\n",
      "  -1.250e+00 -4.700e-01]\n",
      " [ 7.800e-01 -3.066e+01 -3.062e+01 -3.033e+01 -2.843e+01 -2.525e+01\n",
      "  -2.936e+01  1.000e-02]\n",
      " [ 3.100e-01 -2.669e+01 -2.218e+01 -2.854e+01 -1.466e+01 -3.051e+01\n",
      "  -1.488e+01  4.100e-01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[  0.8    0.79   0.5    0.36   0.17   0.97   0.86   0.34]\n",
      " [  0.99  -1.67  -1.67  -1.67  -1.67  -1.67 -30.5  -14.55]\n",
      " [ -1.67 -30.51 -22.71  -1.66 -30.58  -1.61 -30.58 -14.59]\n",
      " [  0.42  -1.67 -30.5  -14.4   -1.5   -1.66 -26.47 -14.79]\n",
      " [  0.44  -1.63  -1.67 -29.29  -1.39 -29.44 -25.17 -25.07]\n",
      " [  0.78 -30.61  -1.62 -22.4   -1.03  -1.5  -29.66 -14.93]\n",
      " [  0.76  -1.67  -1.67  -1.67 -29.34  -1.21  -0.62   0.55]\n",
      " [  0.72 -26.55 -26.61 -14.83 -22.04 -14.88 -22.12   0.23]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > > ^ > > v █ \n",
      "^ ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ ^ v █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ < > ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 38 Tot Reward: -560\n",
      "Episode: 2 - Tot Steps: 62 Tot Reward: -729\n",
      "Episode: 3 - Tot Steps: 269 Tot Reward: -2183\n",
      "Episode: 4 - Tot Steps: 286 Tot Reward: -1620\n",
      "Episode: 5 - Tot Steps: 264 Tot Reward: -1279\n",
      "Episode: 6 - Tot Steps: 30 Tot Reward: -88\n",
      "Episode: 7 - Tot Steps: 156 Tot Reward: -620\n",
      "Episode: 8 - Tot Steps: 65 Tot Reward: -413\n",
      "Episode: 9 - Tot Steps: 98 Tot Reward: -475\n",
      "Episode: 10 - Tot Steps: 101 Tot Reward: -420\n",
      "Episode: 11 - Tot Steps: 66 Tot Reward: -269\n",
      "Episode: 12 - Tot Steps: 236 Tot Reward: -1222\n",
      "Episode: 13 - Tot Steps: 45 Tot Reward: -277\n",
      "Episode: 14 - Tot Steps: 98 Tot Reward: -475\n",
      "Episode: 15 - Tot Steps: 59 Tot Reward: -233\n",
      "Episode: 16 - Tot Steps: 71 Tot Reward: -303\n",
      "Episode: 17 - Tot Steps: 96 Tot Reward: -328\n",
      "Episode: 18 - Tot Steps: 67 Tot Reward: -270\n",
      "Episode: 19 - Tot Steps: 84 Tot Reward: -258\n",
      "Episode: 20 - Tot Steps: 30 Tot Reward: -88\n",
      "Episode: 21 - Tot Steps: 192 Tot Reward: -975\n",
      "Episode: 22 - Tot Steps: 35 Tot Reward: -35\n",
      "Episode: 23 - Tot Steps: 44 Tot Reward: -131\n",
      "Episode: 24 - Tot Steps: 33 Tot Reward: -149\n",
      "Episode: 25 - Tot Steps: 22 Tot Reward: -51\n",
      "Episode: 26 - Tot Steps: 30 Tot Reward: -117\n",
      "Episode: 27 - Tot Steps: 24 Tot Reward: -111\n",
      "Episode: 28 - Tot Steps: 34 Tot Reward: -150\n",
      "Episode: 29 - Tot Steps: 37 Tot Reward: -37\n",
      "Episode: 30 - Tot Steps: 25 Tot Reward: -141\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.53   0.7    0.38   0.08   0.5    0.6    0.24   0.52]\n",
      " [  0.19  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -22.71]\n",
      " [ -1.67  -1.67  -1.66  -1.65  -1.67  -1.65  -1.67 -14.46]\n",
      " [  0.15  -1.67 -30.58 -22.59  -1.66 -30.39  -1.66 -14.39]\n",
      " [  0.77  -1.66  -1.67 -30.61 -22.33  -1.66  -1.56 -22.77]\n",
      " [  0.65 -30.64  -1.66  -1.67 -29.51  -1.64 -30.3  -25.32]\n",
      " [  0.3   -1.67 -30.34  -1.67 -29.95  -1.1   -1.34   0.73]\n",
      " [  0.17  -1.66  -1.65  -1.67  -1.45 -14.44  -0.64  -0.16]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[ 7.600e-01  8.900e-01  9.200e-01  1.000e-02  4.000e-02  2.700e-01\n",
      "   6.000e-02  8.800e-01]\n",
      " [ 8.000e-02 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.670e+00 -1.650e+00]\n",
      " [-1.670e+00 -1.670e+00 -1.650e+00 -1.456e+01 -2.851e+01 -1.640e+00\n",
      "  -2.957e+01 -1.620e+00]\n",
      " [ 3.900e-01 -1.670e+00 -1.670e+00 -1.640e+00 -1.455e+01 -3.052e+01\n",
      "  -1.660e+00 -1.610e+00]\n",
      " [ 1.200e-01 -2.847e+01 -3.061e+01 -1.670e+00 -1.630e+00 -2.655e+01\n",
      "  -1.530e+00 -2.233e+01]\n",
      " [ 6.600e-01 -1.670e+00 -1.640e+00 -3.056e+01 -1.490e+00 -2.629e+01\n",
      "  -1.600e+00 -8.300e-01]\n",
      " [ 5.200e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.320e+00\n",
      "  -2.636e+01  9.100e-01]\n",
      " [ 8.900e-01 -1.482e+01 -2.262e+01 -1.479e+01 -1.483e+01 -1.472e+01\n",
      "  -1.480e+01 -1.446e+01]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[  0.94   0.72   0.62   0.36   0.53   0.99   0.21   0.49]\n",
      " [  0.09  -1.67 -30.59 -30.63  -1.67 -30.59  -1.66 -14.77]\n",
      " [ -1.67  -1.67  -1.64 -26.44 -30.52  -1.63  -1.66 -14.41]\n",
      " [  0.91 -30.65  -1.67  -1.65 -26.19  -1.64 -29.43 -17.89]\n",
      " [  0.93  -1.66 -30.06  -1.67 -14.82  -1.6   -1.5  -26.13]\n",
      " [  0.36  -1.67  -1.64  -1.67  -1.45 -29.23  -1.25  -0.55]\n",
      " [  0.11 -30.63 -30.63 -30.65 -28.4  -14.67 -26.09   0.52]\n",
      " [  0.68 -14.94 -22.47 -22.51 -14.85   0.45 -14.52 -14.48]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 9.900e-01  9.000e-01  7.300e-01  4.400e-01  2.200e-01  2.500e-01\n",
      "   6.300e-01  5.100e-01]\n",
      " [ 9.300e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.056e+01 -2.252e+01]\n",
      " [-1.670e+00 -3.060e+01 -2.964e+01 -1.660e+00 -2.945e+01 -1.640e+00\n",
      "  -3.033e+01 -2.270e+01]\n",
      " [ 1.900e-01 -1.670e+00 -3.005e+01 -2.931e+01 -1.650e+00 -1.660e+00\n",
      "  -3.005e+01 -1.443e+01]\n",
      " [ 1.900e-01 -1.660e+00 -1.670e+00 -3.003e+01 -1.600e+00 -3.058e+01\n",
      "  -3.401e+01 -3.053e+01]\n",
      " [ 8.500e-01 -3.064e+01 -1.630e+00 -3.022e+01 -1.470e+00 -1.500e+00\n",
      "  -2.823e+01 -1.477e+01]\n",
      " [ 1.000e-02 -1.670e+00 -1.670e+00 -1.670e+00 -2.231e+01 -1.140e+00\n",
      "  -6.300e-01  7.000e-02]\n",
      " [ 7.500e-01 -2.244e+01 -2.858e+01 -1.475e+01 -1.474e+01 -1.463e+01\n",
      "  -2.219e+01 -2.204e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ > ^ > > > v █ \n",
      "< v █ █ ^ █ v █ \n",
      "█ < v █ █ v < █ \n",
      "█ █ ^ v █ v █ █ \n",
      "█ v █ ^ █ > v █ \n",
      "█ < < ^ < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 257 Tot Reward: -3360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2 - Tot Steps: 127 Tot Reward: -1113\n",
      "Episode: 3 - Tot Steps: 88 Tot Reward: -697\n",
      "Episode: 4 - Tot Steps: 111 Tot Reward: -662\n",
      "Episode: 5 - Tot Steps: 80 Tot Reward: -370\n",
      "Episode: 6 - Tot Steps: 34 Tot Reward: -92\n",
      "Episode: 7 - Tot Steps: 33 Tot Reward: -236\n",
      "Episode: 8 - Tot Steps: 167 Tot Reward: -950\n",
      "Episode: 9 - Tot Steps: 63 Tot Reward: -440\n",
      "Episode: 10 - Tot Steps: 121 Tot Reward: -788\n",
      "Episode: 11 - Tot Steps: 181 Tot Reward: -964\n",
      "Episode: 12 - Tot Steps: 82 Tot Reward: -401\n",
      "Episode: 13 - Tot Steps: 222 Tot Reward: -1034\n",
      "Episode: 14 - Tot Steps: 203 Tot Reward: -1102\n",
      "Episode: 15 - Tot Steps: 76 Tot Reward: -511\n",
      "Episode: 16 - Tot Steps: 54 Tot Reward: -228\n",
      "Episode: 17 - Tot Steps: 74 Tot Reward: -480\n",
      "Episode: 18 - Tot Steps: 87 Tot Reward: -580\n",
      "Episode: 19 - Tot Steps: 137 Tot Reward: -978\n",
      "Episode: 20 - Tot Steps: 62 Tot Reward: -410\n",
      "Episode: 21 - Tot Steps: 47 Tot Reward: -279\n",
      "Episode: 22 - Tot Steps: 44 Tot Reward: -160\n",
      "Episode: 23 - Tot Steps: 110 Tot Reward: -806\n",
      "Episode: 24 - Tot Steps: 35 Tot Reward: -122\n",
      "Episode: 25 - Tot Steps: 44 Tot Reward: -305\n",
      "Episode: 26 - Tot Steps: 104 Tot Reward: -655\n",
      "Episode: 27 - Tot Steps: 40 Tot Reward: -214\n",
      "Episode: 28 - Tot Steps: 38 Tot Reward: -212\n",
      "Episode: 29 - Tot Steps: 21 Tot Reward: -108\n",
      "Episode: 30 - Tot Steps: 50 Tot Reward: -253\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[ 3.800e-01  4.200e-01  5.500e-01  3.700e-01  5.500e-01  7.600e-01\n",
      "   5.100e-01  8.700e-01]\n",
      " [ 8.500e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -1.660e+00 -2.213e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.670e+00 -1.660e+00 -1.670e+00 -1.620e+00\n",
      "  -1.660e+00 -2.263e+01]\n",
      " [ 5.800e-01 -1.670e+00 -3.065e+01 -2.623e+01 -1.650e+00 -3.048e+01\n",
      "  -1.660e+00 -2.637e+01]\n",
      " [ 3.400e-01 -1.670e+00 -1.670e+00 -3.065e+01 -3.032e+01 -1.650e+00\n",
      "  -1.490e+00 -2.260e+01]\n",
      " [ 2.000e-02 -3.066e+01 -1.660e+00 -1.670e+00 -1.477e+01 -1.610e+00\n",
      "  -2.956e+01 -2.907e+01]\n",
      " [ 3.000e-01 -1.670e+00 -3.050e+01 -1.670e+00 -2.950e+01 -1.400e+00\n",
      "  -1.490e+00  9.500e-01]\n",
      " [ 3.200e-01 -1.670e+00 -1.660e+00 -1.660e+00 -1.660e+00 -2.940e+01\n",
      "  -1.190e+00 -3.200e-01]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.69   0.38   0.68   0.62   0.04   0.84   0.07   0.52]\n",
      " [  0.78  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.49]\n",
      " [ -1.67  -1.67  -1.67 -26.68 -28.61  -1.59 -30.46  -1.65]\n",
      " [  0.14  -1.67  -1.67  -1.67 -28.43 -30.39  -1.66  -1.61]\n",
      " [  0.11 -30.41 -30.67  -1.67  -1.65 -30.54  -1.59 -26.31]\n",
      " [  0.75  -1.67  -1.66 -30.62  -1.53 -28.5   -1.59  -0.45]\n",
      " [  0.09  -1.67  -1.67  -1.67  -1.67  -1.4  -29.48   0.74]\n",
      " [  0.24 -14.77 -29.63 -26.7  -14.76 -26.46 -27.47 -15.2 ]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 5.600e-01  9.500e-01  3.500e-01  1.700e-01  3.000e-02  6.200e-01\n",
      "   7.300e-01  6.700e-01]\n",
      " [ 7.200e-01 -1.670e+00 -3.066e+01 -3.066e+01 -1.670e+00 -2.999e+01\n",
      "  -1.660e+00 -3.035e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.670e+00 -2.852e+01 -3.058e+01 -1.630e+00\n",
      "  -1.660e+00 -2.246e+01]\n",
      " [ 5.000e-01 -3.067e+01 -1.670e+00 -1.670e+00 -2.658e+01 -1.640e+00\n",
      "  -2.979e+01 -1.781e+01]\n",
      " [ 7.700e-01 -1.670e+00 -3.062e+01 -1.670e+00 -1.465e+01 -1.600e+00\n",
      "  -1.430e+00 -1.481e+01]\n",
      " [ 5.100e-01 -1.670e+00 -1.660e+00 -1.670e+00 -1.620e+00 -3.021e+01\n",
      "  -1.250e+00 -3.900e-01]\n",
      " [ 5.800e-01 -3.064e+01 -3.066e+01 -3.065e+01 -3.008e+01 -4.002e+01\n",
      "  -2.848e+01  9.600e-01]\n",
      " [ 3.700e-01 -2.963e+01 -1.469e+01 -2.844e+01 -2.646e+01 -3.267e+01\n",
      "  -2.835e+01 -1.469e+01]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 6.000e-01  6.000e-01  9.300e-01  7.000e-01  6.100e-01  3.800e-01\n",
      "   6.100e-01  4.600e-01]\n",
      " [ 6.600e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.048e+01 -2.256e+01]\n",
      " [-1.670e+00 -3.066e+01 -2.646e+01 -1.660e+00 -3.032e+01 -1.650e+00\n",
      "  -2.865e+01 -2.852e+01]\n",
      " [ 1.700e-01 -1.670e+00 -3.065e+01 -2.646e+01 -1.650e+00 -1.660e+00\n",
      "  -3.002e+01 -2.968e+01]\n",
      " [ 3.100e-01 -1.670e+00 -1.670e+00 -3.065e+01 -1.640e+00 -2.988e+01\n",
      "  -2.511e+01 -2.507e+01]\n",
      " [ 1.600e-01 -3.066e+01 -1.660e+00 -3.055e+01 -1.560e+00 -1.500e+00\n",
      "  -2.899e+01 -2.217e+01]\n",
      " [ 2.000e-02 -1.670e+00 -1.670e+00 -1.670e+00 -3.034e+01 -1.240e+00\n",
      "  -6.200e-01  2.000e-01]\n",
      " [ 8.100e-01 -2.657e+01 -2.665e+01 -2.859e+01 -2.680e+01 -2.940e+01\n",
      "  -2.616e+01 -2.597e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ < > > > > v █ \n",
      "> ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > < █ v █ █ \n",
      "█ < █ ^ █ > v █ \n",
      "█ ^ < < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n",
      "Maze to solve and Agent start position:\n",
      "\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ . . . . . . █ \n",
      "🤖. █ █ . █ . █ \n",
      "█ . . █ █ . . █ \n",
      "█ █ . . █ . █ █ \n",
      "█ . █ . █ . . █ \n",
      "█ . . . . █ . ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "Episode: 1 - Tot Steps: 139 Tot Reward: -1850\n",
      "Episode: 2 - Tot Steps: 103 Tot Reward: -1089\n",
      "Episode: 3 - Tot Steps: 232 Tot Reward: -1798\n",
      "Episode: 4 - Tot Steps: 184 Tot Reward: -1083\n",
      "Episode: 5 - Tot Steps: 206 Tot Reward: -1221\n",
      "Episode: 6 - Tot Steps: 97 Tot Reward: -851\n",
      "Episode: 7 - Tot Steps: 96 Tot Reward: -386\n",
      "Episode: 8 - Tot Steps: 184 Tot Reward: -1112\n",
      "Episode: 9 - Tot Steps: 67 Tot Reward: -415\n",
      "Episode: 10 - Tot Steps: 92 Tot Reward: -527\n",
      "Episode: 11 - Tot Steps: 92 Tot Reward: -382\n",
      "Episode: 12 - Tot Steps: 86 Tot Reward: -318\n",
      "Episode: 13 - Tot Steps: 160 Tot Reward: -1030\n",
      "Episode: 14 - Tot Steps: 71 Tot Reward: -303\n",
      "Episode: 15 - Tot Steps: 31 Tot Reward: -118\n",
      "Episode: 16 - Tot Steps: 163 Tot Reward: -1149\n",
      "Episode: 17 - Tot Steps: 191 Tot Reward: -1351\n",
      "Episode: 18 - Tot Steps: 36 Tot Reward: -239\n",
      "Episode: 19 - Tot Steps: 47 Tot Reward: -308\n",
      "Episode: 20 - Tot Steps: 64 Tot Reward: -354\n",
      "Episode: 21 - Tot Steps: 98 Tot Reward: -446\n",
      "Episode: 22 - Tot Steps: 66 Tot Reward: -269\n",
      "Episode: 23 - Tot Steps: 115 Tot Reward: -811\n",
      "Episode: 24 - Tot Steps: 32 Tot Reward: -148\n",
      "Episode: 25 - Tot Steps: 53 Tot Reward: -459\n",
      "Episode: 26 - Tot Steps: 50 Tot Reward: -166\n",
      "Episode: 27 - Tot Steps: 50 Tot Reward: -253\n",
      "Episode: 28 - Tot Steps: 40 Tot Reward: -359\n",
      "Episode: 29 - Tot Steps: 40 Tot Reward: -185\n",
      "Episode: 30 - Tot Steps: 77 Tot Reward: -338\n",
      "\n",
      "Q 함수 학습 과정:\n",
      "\n",
      "Q(y,x) for action: 0\n",
      "\n",
      "[[  0.41   0.75   0.69   0.96   0.45   0.37   0.86   0.33]\n",
      " [  0.3   -1.67  -1.67  -1.67  -1.67  -1.67  -1.67 -29.37]\n",
      " [ -1.67  -1.67  -1.67  -1.67  -1.67  -1.64  -1.67 -29.45]\n",
      " [  0.96  -1.67 -30.6  -30.12  -1.66 -30.52  -1.66 -28.53]\n",
      " [  0.15  -1.67  -1.67 -30.64 -28.54  -1.65  -1.54 -22.63]\n",
      " [  0.08 -30.58  -1.67  -1.67 -28.39  -1.64 -30.45 -17.81]\n",
      " [  0.79  -1.67 -30.66  -1.67 -30.43  -1.56  -1.48   0.35]\n",
      " [  0.19  -1.67  -1.62  -1.67  -1.59 -26.51  -1.21  -0.12]]\n",
      "\n",
      "Q(y,x) for action: 1\n",
      "\n",
      "[[  0.     0.17   0.69   0.12   0.72   0.29   0.88   0.68]\n",
      " [  0.47  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67  -1.67]\n",
      " [ -1.67  -1.67  -1.67 -22.53 -30.52  -1.66 -30.31  -1.66]\n",
      " [  0.14  -1.67  -1.67  -1.65 -26.36 -30.62  -1.66  -1.65]\n",
      " [  0.4  -30.37 -30.59  -1.67  -1.64 -29.48  -1.56 -28.43]\n",
      " [  0.49  -1.67  -1.67 -30.64  -1.63 -30.47  -1.58  -0.93]\n",
      " [  0.14  -1.67  -1.67  -1.67  -1.67  -1.47 -29.5    0.05]\n",
      " [  0.76 -29.66 -22.61 -22.59 -26.56 -26.24 -31.99 -14.69]]\n",
      "\n",
      "Q(y,x) for action: 2\n",
      "\n",
      "[[ 4.200e-01  3.000e-01  1.500e-01  2.400e-01  7.800e-01  6.100e-01\n",
      "   9.300e-01  8.000e-01]\n",
      " [ 7.400e-01 -1.670e+00 -3.067e+01 -3.066e+01 -1.670e+00 -3.064e+01\n",
      "  -1.670e+00 -2.827e+01]\n",
      " [-1.670e+00 -1.670e+00 -1.670e+00 -2.962e+01 -3.038e+01 -1.650e+00\n",
      "  -1.660e+00 -2.854e+01]\n",
      " [ 9.400e-01 -3.066e+01 -1.670e+00 -1.650e+00 -1.446e+01 -1.650e+00\n",
      "  -3.058e+01 -2.522e+01]\n",
      " [ 9.000e-01 -1.660e+00 -3.066e+01 -1.670e+00 -1.506e+01 -1.610e+00\n",
      "  -1.530e+00 -2.214e+01]\n",
      " [ 3.900e-01 -1.670e+00 -1.670e+00 -1.670e+00 -1.640e+00 -3.039e+01\n",
      "  -1.340e+00 -7.600e-01]\n",
      " [ 1.400e-01 -3.067e+01 -3.031e+01 -3.066e+01 -2.849e+01 -3.403e+01\n",
      "  -2.936e+01  2.400e-01]\n",
      " [ 6.400e-01 -2.657e+01 -1.485e+01 -2.842e+01 -2.648e+01 -3.560e+01\n",
      "  -2.240e+01  1.000e-02]]\n",
      "\n",
      "Q(y,x) for action: 3\n",
      "\n",
      "[[ 3.800e-01  1.000e-01  5.800e-01  3.100e-01  4.000e-01  1.100e-01\n",
      "   9.000e-01  7.400e-01]\n",
      " [ 3.000e-02 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00 -1.670e+00\n",
      "  -3.066e+01 -2.256e+01]\n",
      " [-1.670e+00 -3.067e+01 -2.962e+01 -1.660e+00 -2.847e+01 -1.640e+00\n",
      "  -3.064e+01 -2.863e+01]\n",
      " [ 9.000e-02 -1.670e+00 -2.841e+01 -2.660e+01 -1.650e+00 -1.660e+00\n",
      "  -3.057e+01 -1.462e+01]\n",
      " [ 1.800e-01 -1.660e+00 -1.670e+00 -3.064e+01 -1.640e+00 -2.657e+01\n",
      "  -3.415e+01 -3.244e+01]\n",
      " [ 1.400e-01 -3.066e+01 -1.670e+00 -3.047e+01 -1.590e+00 -1.540e+00\n",
      "  -2.971e+01 -2.240e+01]\n",
      " [ 4.000e-01 -1.670e+00 -1.670e+00 -1.670e+00 -3.044e+01 -1.340e+00\n",
      "  -8.600e-01  3.400e-01]\n",
      " [ 5.500e-01 -2.853e+01 -2.858e+01 -2.860e+01 -2.505e+01 -2.619e+01\n",
      "  -2.219e+01 -1.442e+01]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 Policy:\n",
      "\n",
      "█ █ █ █ █ █ █ █ \n",
      "█ < > > > > v █ \n",
      "v ^ █ █ ^ █ v █ \n",
      "█ > v █ █ v < █ \n",
      "█ █ > < █ v █ █ \n",
      "█ < █ v █ > v █ \n",
      "█ ^ > < < █ > ✔ \n",
      "█ █ █ █ █ █ █ █ \n",
      "\n",
      "\n",
      "\n",
      "최종적으로 학습된 정책(방향키를)보고 실행시킬지 여부를 결정하세요. 무한루프에 빠질 수도 있습니다.\n",
      "\n",
      "화살표의 방향이 처음부터 끝까지 이어지는 지 확인하세요\n",
      "\n",
      "======================================================\n",
      "\n",
      "입구를 찾을 수 없습니다.\n",
      "\n",
      "======================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "## epsilon값을 0.05~ 0.5까지 0.1씩 증가\n",
    "epsilon_list = [0.05, 0.1, 0.15, 0.20, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "epsilon_list_reward = []\n",
    "\n",
    "## epsilon_list를 하나씩 돌면서 값측정\n",
    "for i in epsilon_list:\n",
    "    ## reward 값을 반환받고, reward값은 음수이므로, 100을 더해서 값이 작을수록 좋은 것임을 나타냄\n",
    "    if __name__ == '__main__':\n",
    "        reward = main(n_episodes=30, alpha =0.5, gamma=0.4,\n",
    "             epsilon = i, result_screening = False)\n",
    "        reward = reward\n",
    "    ## reward에 하나씩 추가\n",
    "    epsilon_list_reward.append(reward)\n",
    "    \n",
    "plt.plot(epsilon_list, epsilon_list_reward, marker='o', linestyle='-')\n",
    "plt.title('epsilon - Reward')\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('Reward per epsilon')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b6a19",
   "metadata": {},
   "source": [
    "### 번외) 파라미터값 직접 지정해보기 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"강화학습에 대한 파라미터를 입력받습니다. 자료형에 맞춰서 입력값을 잘 넣어주세요!!\\n\")\n",
    "n_episodes = int(input(\"episode의 횟수를 입력(int) : \"))\n",
    "alpha = float(input(\"하나의 step당 학습률을 입력(float) : \"))\n",
    "gamma = float(input(\"미래의 보상이 현재의 보상보다 얼마나 중요한지(float) :\"))\n",
    "epsilon = float(input(\"epsilon 가중치 입력(float) :\"))\n",
    "show = bool(input(\"traing 모든 과정을 보시겠습니까?(True or False)\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(n_episodes, alpha, gamma,\n",
    "         epsilon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
